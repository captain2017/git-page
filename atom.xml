<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>zhisheng的博客</title>
  
  <subtitle>坑要一个个填，路要一步步走！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.54tianzhisheng.cn/"/>
  <updated>2020-03-01T01:35:04.000Z</updated>
  <id>http://www.54tianzhisheng.cn/</id>
  
  <author>
    <name>zhisheng</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Flink 能否动态更改 Checkpoint 配置</title>
    <link href="http://www.54tianzhisheng.cn/2020/02/29/flink-nacos-checkpoint/"/>
    <id>http://www.54tianzhisheng.cn/2020/02/29/flink-nacos-checkpoint/</id>
    <published>2020-02-28T16:00:00.000Z</published>
    <updated>2020-03-01T01:35:04.000Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间在社区邮件中看到有人提问是否可以动态开启 Checkpoint，昨天在钉钉群中又看到有个同学在问能够动态调整 Checkpoint 的时间，其实不仅仅是这些，在社区邮件和群里经常看到有问这块内容的问题，所以可以发现在 Flink 中其实关于 Checkpoint 相关的东西还是非常重要且解决起来比较麻烦，估计应该也困扰了不少人。</p><a id="more"></a><p>不过今天的话题不是在于去讨论 Checkpoint 的机制，因为前面两个问题都涉及到了动态的去配置 Checkpoint 的参数（是否开启和 Checkpoint 的时间间隔），而 zhisheng 我在前面通过两个视频讲解了 <a href="http://www.54tianzhisheng.cn/2020/02/23/flink-apollo/">Flink 如何与 Apollo 和 Nacos 整合去动态的更改作业配置</a>，所以私底下就有同学找我咨询是否可以动态的更改 Checkpoint 配置，我当时因为知道其实有些参数是一旦初始化了之后是改不了的，但是具体什么参数我也不难全部列举，所以只好回答那位同学说：以自己实测的结果为准哈。</p><p>所以这里我就给大家演示一下到底是否可以动态的更改 Checkpoint 配置，请看我在 B 站的视频：</p><p><a href="https://www.bilibili.com/video/av92655075/">https://www.bilibili.com/video/av92655075/</a></p><iframe height=900 width=1150 src="//player.bilibili.com/player.html?aid=92655075&cid=158192037&page=1" allowfullscreen="true"> </iframe><p>通过这个视频，虽然我是使用 Flink 和 Nacos 整合的，作业监听到了 Checkpoint 的配置做了修改，但是可以发现其实 Checkpoint 更改后其实是不生效的。</p><p>这里仅从个人的思考来解释一下：因为 Flink 是 Lazy Evaluation（延迟执行），当程序的 main 方法执行时，我们创建的 env 会依次进行属性的初始化配置，但是数据源加载数据和数据转换等算子不会立马执行，这些算子操作会被创建并添加到程序的执行计划中去，只有当执行环境 env 的 execute 方法被显示地触发执行时，整个程序才开始执行实际的操作（StreamGraph -&gt; JobGraph -&gt; ExecutionGraph），所以在程序执行 execute 方法后再修改 env 的配置其实就不起作用了。</p><p>另外给大家来看下邱从贤(负责 Flink State 相关)对能否动态配置 Checkpoint 的回答：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-03-01-011804.png" alt=""></p><p>相关的测试代码在: <a href="https://github.com/zhisheng17/flink-learning/blob/master/flink-learning-configration-center/flink-learning-configration-center-nacos">https://github.com/zhisheng17/flink-learning/blob/master/flink-learning-configration-center/flink-learning-configration-center-nacos</a></p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="hhttp://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前段时间在社区邮件中看到有人提问是否可以动态开启 Checkpoint，昨天在钉钉群中又看到有个同学在问能够动态调整 Checkpoint 的时间，其实不仅仅是这些，在社区邮件和群里经常看到有问这块内容的问题，所以可以发现在 Flink 中其实关于 Checkpoint 相关的东西还是非常重要且解决起来比较麻烦，估计应该也困扰了不少人。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Nacos" scheme="http://www.54tianzhisheng.cn/tags/Nacos/"/>
    
  </entry>
  
  <entry>
    <title>Flink 整合 Apollo，动态更新 Flink 作业配置</title>
    <link href="http://www.54tianzhisheng.cn/2020/02/23/flink-apollo/"/>
    <id>http://www.54tianzhisheng.cn/2020/02/23/flink-apollo/</id>
    <published>2020-02-22T16:00:00.000Z</published>
    <updated>2020-02-26T00:39:09.000Z</updated>
    
    <content type="html"><![CDATA[<p>本人自己录的视频，讲解 Flink 整和 Apollo，动态更新作业配置，无需重启作业！</p><a id="more"></a><p>在上一篇讲解 <a href="http://www.54tianzhisheng.cn/2020/02/22/flink-nacos/">Flink 与 Nacos 整合的视频</a> 中，讲过了常见的几种更新配置的方法，最常使用的可能就是通过广播流的方式，相信看完上个视频的，估计对整合 Nacos 做动态更新配置应该问题不大，zhisheng 我也觉得稍微简单，尤其 Nacos 搭建安装也比较简单。不知道大家公司有没有使用 Nacos 呢？我知道有的公司使用 Apollo 居多，所以后面就有读者问我能不能出个整合 Apollo 的视频，所以我趁着周末大晚上的时间就开始折腾了一番，本篇文章将给大家讲解与 Apollo 整合，动态的更新 Flink 配置。</p><p>Apollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。</p><p>因为它的自身架构原因，导致安装可能会比较复杂，需要安装好多个组件，个人觉得比 Nacos 复杂，幸好的是官方的文档比较详细，跟着安装步骤来说还是没有问题的。zhisheng 我是只在自己 Mac 电脑上面安装了一个单机版的，仅为测试使用。</p><p>快速上手的请参考该链接 <a href="https://github.com/nobodyiam/apollo-build-scripts">https://github.com/nobodyiam/apollo-build-scripts</a>，这样你就能够在几分钟内在本地环境部署、启动 Apollo 配置中心。另外还提供了 Quick Start 的 Docker 版本，如果你对 Docker 比较熟悉的话，那更方便了。</p><p>主要演示流程（安装 Apollo 和整合 Flink），本人录了个视频，更方便大家去实战操作，欢迎观看：</p><iframe height=900 width=1150 src="//player.bilibili.com/player.html?aid=91742999&cid=156618259&page=1" allowfullscreen="true"> </iframe><p>代码地址：<a href="https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-configration-center/flink-learning-configration-center-apollo">https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-configration-center/flink-learning-configration-center-apollo</a></p><p>注意引入 Apollo 的依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.ctrip.framework.apollo<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>apollo-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.5.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="hhttp://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本人自己录的视频，讲解 Flink 整和 Apollo，动态更新作业配置，无需重启作业！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Apollo" scheme="http://www.54tianzhisheng.cn/tags/Apollo/"/>
    
  </entry>
  
  <entry>
    <title>Flink 整合 Nacos，让 Flink 作业配置动态更新不再是难事</title>
    <link href="http://www.54tianzhisheng.cn/2020/02/22/flink-nacos/"/>
    <id>http://www.54tianzhisheng.cn/2020/02/22/flink-nacos/</id>
    <published>2020-02-21T16:00:00.000Z</published>
    <updated>2020-02-25T16:06:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>本人自己录的视频，讲解 Flink 整和 Nacos，动态更新作业配置，无需重启作业！</p><a id="more"></a><p>我们知道 Flink 作业的配置一般都是通过在作业启动的时候通过参数传递的，或者通过读取配置文件的参数，在作业启动后初始化了之后如果再想更新作业的配置一般有两种解决方法：</p><ul><li><p>改变启动参数或者改变配置文件，重启作业，让作业能够读取到修改后的配置</p></li><li><p>通过读取配置流（需要自定义 Source 读取配置），然后流和流连接起来</p></li></ul><p>这两种解决方法一般是使用的比较多，对于第一种方法，zhisheng 我本人其实是不太建议的，重启作业会带来很多影响，Flink 作业完整的重启流程应该是：当作业停掉的时候需要去做一次 Savepoint（相当于把作业的状态做一次完整的快照），启动的时候又需要将作业从 Savepoint 启动，整个流程如果状态比较大的话，做一次 Savepoint 和从 Savepoint 初始化的时间会比较久，然而流处理的场景下通常数据量都是比较大的，那么在这段时间内，可能会造成不少的数据堆积（可能分钟内就上千万或者更多），当作业启动后再去追这千万量级的数据，对作业来说压力自然会增大。</p><p>对于第二种方法也是一种用的很多的方式，自己也比较推荐，之前自己在社区直播的时候也有讲过类似的方案，但是今天我准备讲解另一种方法 —— 整合配置中心，没看见有人这么用过，我也算是第一个吃螃蟹的人了！说到配置中心，目前国内有 Apollo 和 Nacos，这里先来讲下和 Nacos 的整合，下面的实战操作请看我录制的视频。</p><iframe height=900 width=1150 src="//player.bilibili.com/player.html?aid=90742627&cid=154955963&page=1" allowfullscreen="true"> </iframe><p>代码地址：<a href="https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-configration-center/flink-learning-configration-center-nacos">https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-configration-center/flink-learning-configration-center-nacos</a></p><p>我本人安装的 Nacos 依赖是阿里的，因为自己本地编译了一份源码，所以可能会有这些依赖在自己本地的 .m2 目录中：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba.nacos<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>nacos-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba.nacos<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>nacos-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba.nacos<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>nacos-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>但是有些同学反馈说上面的依赖引入不上，一直下载不了，比如 nacos-core，这里建议去 <a href="https://mvnrepository.com/search?q=nacos-core">https://mvnrepository.com/search?q=nacos-core</a> 看一下第一个，然后引用试试。</p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="hhttp://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本人自己录的视频，讲解 Flink 整和 Nacos，动态更新作业配置，无需重启作业！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Nacos" scheme="http://www.54tianzhisheng.cn/tags/Nacos/"/>
    
  </entry>
  
  <entry>
    <title>Flink 1.10 新特性研究</title>
    <link href="http://www.54tianzhisheng.cn/2020/02/22/flink-1.10-release/"/>
    <id>http://www.54tianzhisheng.cn/2020/02/22/flink-1.10-release/</id>
    <published>2020-02-21T16:00:00.000Z</published>
    <updated>2020-02-22T13:34:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink 1.10 release 文档描述了一些比较重要的点，比如配置、操作、依赖、1.9 版本和 1.10 版本之间的区别，如果你准备将 Flink 升级到 1.10 版本，建议仔细看完下面的内容。</p><a id="more"></a><h3 id="集群和部署"><a href="#集群和部署" class="headerlink" title="集群和部署"></a>集群和部署</h3><ul><li><p>文件系统需要通过插件的方式加载</p></li><li><p>Flink 客户端根据配置的类加载策略加载，parent-first 和 child-first 两种方式</p></li><li><p>允许在所有的 TaskManager 上均匀地分布任务，需要在 <code>flink-conf.yaml</code> 配置文件中配置 <code>cluster.evenly-spread-out-slots: true</code> 参数</p></li><li><p>高可用存储目录做了修改，在 <code>HA_STORAGE_DIR/HA_CLUSTER_ID</code> 下，<code>HA_STORAGE_DIR</code> 路径通过 <code>high-availability.storageDir</code> 参数配置，<code>HA_CLUSTER_ID</code> 路径通过 <code>high-availability.cluster-id</code> 参数配置</p></li><li><p>当使用 <code>-yarnship</code> 命令参数时，资源目录和 jar 文件会被添加到 classpath 中</p></li><li><p>移除了 <code>--yn/--yarncontainer</code> 命令参数</p></li><li><p>移除了 <code>--yst/--yarnstreaming</code> 命令参数</p></li><li><p>Flink Mesos 会拒绝掉所有的过期请求</p></li><li><p>重构了 Flink 的调度程序，其目标是使调度策略在未来可以定制</p></li><li><p>支持 Java 11，当使用 Java 11 启动 Flink 时，会有些 WARNING 的日志提醒，注意：Cassandra、Hive、HBase 等 connector 没有使用 Java 11 测试过</p></li></ul><h3 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h3><ul><li>全新的 Task Executor 内存模型，会影响 standalone、YARN、Mesos、K8S 的部署，JobManager 的内存模型没有修改。如果你在没有调整的情况下，重用以前的 Flink 配置，则新的内存模型可能会导致 JVM 的计算内存参数不同，从而导致性能的变化。</li></ul><p>以下选项已经删除，不再起作用：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-02-21-074438.png" alt=""></p><p>以下选项已经替换成其他的选项：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-02-21-074623.png" alt=""></p><ul><li><p>RocksDB State Backend 内存可以控制，用户可以调整 RocksDB 的写/读内存比率 <code>state.backend.rocksdb.memory.write-buffer-ratio</code>（默认情况下 0.5）和为索引/过滤器保留的内存部分 <code>state.backend.rocksdb.memory.high-prio-pool-ratio</code>（默认情况下0.1）</p></li><li><p>细粒度的算子（Operator）资源管理，配置选项 <code>table.exec.resource.external-buffer-memory</code>，<code>table.exec.resource.hash-agg.memory</code>，<code>table.exec.resource.hash-join.memory</code>，和 <code>table.exec.resource.sort.memory</code> 已被弃用</p></li></ul><h3 id="Table-API-和-SQL"><a href="#Table-API-和-SQL" class="headerlink" title="Table API 和 SQL"></a>Table API 和 SQL</h3><ul><li><p>将 ANY 类型重命名为 RAW 类型，该标识符 raw 现在是保留关键字，在用作 SQL 字段或函数名称时必须转义</p></li><li><p>重命名 Table Connector 属性，以便编写 DDL 语句时提供更好的用户体验，比如 Kafka Connector 属性 <code>connector.properties</code> 和 <code>connector.specific-offsets</code>、Elasticsearch Connector 属性 <code>connector.hosts</code></p></li><li><p>之前与临时表和视图进行交互的方法已经被弃用，目前使用 createTemporaryView()</p></li><li><p>移除了 ExternalCatalog API（ExternalCatalog、SchematicDescriptor、MetadataDescriptor、StatisticsDescriptor），建议使用新的 Catalog API</p></li></ul><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><ul><li><p>ConfigOptions 如果无法将配置的值解析成所需要的类型，则会抛出 IllegalArgumentException 异常，之前是会返回默认值</p></li><li><p>增加默认的重启策略延迟时间（fixed-delay 和 failure-rate 已经默认是 1s，之前是 0）</p></li><li><p>简化集群级别的重启策略配置，现在集群级别的重启策略仅由 restart-strategy 配置和是否开启 Checkpoint 确定</p></li><li><p>默认情况下禁用内存映射的 BoundedBlockingSubpartition</p></li><li><p>移除基于未认证的网络流量控制</p></li><li><p>移除 HighAvailabilityOptions 中的 HA_JOB_DELAY 配置</p></li></ul><h3 id="状态（State）"><a href="#状态（State）" class="headerlink" title="状态（State）"></a>状态（State）</h3><ul><li><p>默认开启 TTL 的状态后台清理</p></li><li><p>弃用 <code>StateTtlConfig#Builder#cleanupInBackground()</code></p></li><li><p>使用 RocksDBStateBackend 时，默认将计时器存储在 RocksDB 中，之前是存储在堆内存（Heap）中</p></li><li><p><code>StateTtlConfig#TimeCharacteristic</code> 已经被移除，目前使用 <code>StateTtlConfig#TtlTimeCharacteristic</code></p></li><li><p>新增 <code>MapState#isEmpty()</code> 方法来检查 MapState 是否为空，该方法比使用 <code>mapState.keys().iterator().hasNext()</code> 的速度快 40%</p></li><li><p>RocksDB 升级，发布了自己的 FRocksDB（基于 RocksDB 5.17.2 版本），主要是因为高版本的 RocksDB 在某些情况下性能会下降</p></li><li><p>默认禁用 RocksDB 日志记录，需要启用的话需要利用 RocksDBOptionsFactory 创建 DBOptions 实例，并通过 setInfoLogLevel 方法设置 INFO_LEVEL</p></li><li><p>优化从 RocksDB Savepoint 恢复的机制，以前如果从包含大型 KV 对的 RocksDB Savepoint 恢复时，用户可能会遇到 OOM。现在引入了可配置的内存限制，RocksDBWriteBatchWrapper 默认值为 2MB。RocksDB的WriteBatch 将在达到内存限制之前刷新。可以在 <code>flink-conf.yml</code> 中修改 <code>state.backend.rocksdb.write-batch-size</code> 配置</p></li></ul><h3 id="PyFlink"><a href="#PyFlink" class="headerlink" title="PyFlink"></a>PyFlink</h3><ul><li>不再支持 Python2</li></ul><h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><ul><li>InfluxdbReporter 会跳过 Inf 和 NaN（InfluxDB 不支持的类型，比如 <code>Double.POSITIVE_INFINITY</code>, <code>Double.NEGATIVE_INFINITY</code>, <code>Double.NaN</code>）</li></ul><h3 id="连接器（Connectors）"><a href="#连接器（Connectors）" class="headerlink" title="连接器（Connectors）"></a>连接器（Connectors）</h3><ul><li>改变 Kinesis 连接器的 License</li></ul><h3 id="接口更改"><a href="#接口更改" class="headerlink" title="接口更改"></a>接口更改</h3><ul><li><p><code>ExecutionConfig＃getGlobalJobParameters()</code> 不再返回 null</p></li><li><p>MasterTriggerRestoreHook 中的 triggerCheckpoint 方法必须时非阻塞的</p></li><li><p>HA 服务的客户端/服务器端分离，HighAvailabilityServices 已分离成客户端 ClientHighAvailabilityServices 和集群端 HighAvailabilityServices</p></li><li><p><code>HighAvailabilityServices#getWebMonitorLeaderElectionService()</code> 标记过期</p></li><li><p>LeaderElectionService 接口做了更改</p></li><li><p>弃用 Checkpoint 锁</p></li><li><p>弃用 OptionsFactory 和 ConfigurableOptionsFactory 接口</p></li></ul><p>参考：<a href="https://github.com/apache/flink/blob/master/docs/release-notes/flink-1.10.zh.md">https://github.com/apache/flink/blob/master/docs/release-notes/flink-1.10.zh.md</a></p><hr><p>看了下官方的这份新版本的介绍，感觉还缺少很多新功能的介绍，比如：</p><ul><li>在 1.10 版本中把 Blink 版本的哪些功能整合过来了</li><li>竟然没有写 Flink 对原生 Kubernetes 的集成</li><li>PyFlink 的介绍是认真的吗？</li><li>对 Hive 的生产级别集成，完全没有提及呀</li><li>Table API/SQL 优化点讲得不太多</li></ul><p>可能因为篇幅的问题，还有很多特性都没有讲解出来，得我们自己去找源码学习！</p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="hhttp://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink 1.10 release 文档描述了一些比较重要的点，比如配置、操作、依赖、1.9 版本和 1.10 版本之间的区别，如果你准备将 Flink 升级到 1.10 版本，建议仔细看完下面的内容。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Nacos" scheme="http://www.54tianzhisheng.cn/tags/Nacos/"/>
    
  </entry>
  
  <entry>
    <title>Flink Checkpoint 问题排查实用指南</title>
    <link href="http://www.54tianzhisheng.cn/2020/02/20/flink-checkpoint/"/>
    <id>http://www.54tianzhisheng.cn/2020/02/20/flink-checkpoint/</id>
    <published>2020-02-19T16:00:00.000Z</published>
    <updated>2020-02-20T01:36:42.000Z</updated>
    
    <content type="html"><![CDATA[<p>在 Flink 中，状态可靠性保证由 Checkpoint 支持，当作业出现 failover 的情况下，Flink 会从最近成功的 Checkpoint 恢复。</p><a id="more"></a><p>作者：邱从贤（山智）<br>转载自：<a href="">https://www.jianshu.com/p/fc100f85a0fb</a></p><p>在实际情况中，我们可能会遇到 Checkpoint 失败，或者 Checkpoint 慢的情况，本文会统一聊一聊 Flink 中 Checkpoint 异常的情况（包括失败和慢），以及可能的原因和排查思路。</p><h3 id="1-Checkpoint-流程简介"><a href="#1-Checkpoint-流程简介" class="headerlink" title="1. Checkpoint 流程简介"></a>1. Checkpoint 流程简介</h3><p>首先我们需要了解 Flink 中 Checkpoint 的整个流程是怎样的，在了解整个流程之后，我们才能在出问题的时候，更好的进行定位分析。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-02-20-012549.jpg" alt=""></p><p>从上图我们可以知道，Flink 的 Checkpoint 包括如下几个部分：</p><ul><li>JM trigger checkpoint</li><li>Source 收到 trigger checkpoint 的 PRC，自己开始做 snapshot，并往下游发送 barrier</li><li>下游接收 barrier（需要 barrier 都到齐才会开始做 checkpoint）</li><li>Task 开始同步阶段 snapshot</li><li>Task 开始异步阶段 snapshot</li><li>Task snapshot 完成，汇报给 JM</li></ul><p>上面的任何一个步骤不成功，整个 checkpoint 都会失败。</p><h3 id="2-Checkpoint-异常情况排查"><a href="#2-Checkpoint-异常情况排查" class="headerlink" title="2 Checkpoint 异常情况排查"></a>2 Checkpoint 异常情况排查</h3><h4 id="2-1-Checkpoint-失败"><a href="#2-1-Checkpoint-失败" class="headerlink" title="2.1 Checkpoint 失败"></a>2.1 Checkpoint 失败</h4><p>可以在 Checkpoint 界面看到如下图所示，下图中 Checkpoint 10423 失败了。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-02-20-012649.jpg" alt=""></p><p>点击 Checkpoint 10423 的详情，我们可以看到类系下图所示的表格（下图中将 operator 名字截取掉了）。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-02-20-012705.jpg" alt=""></p><p>上图中我们看到三行，表示三个 operator，其中每一列的含义分别如下：</p><ul><li>其中 Acknowledged 一列表示有多少个 subtask 对这个 Checkpoint 进行了 ack，从图中我们可以知道第三个 operator 总共有 5 个 subtask，但是只有 4 个进行了 ack；</li><li>第二列 Latest Acknowledgement 表示该 operator 的所有 subtask 最后 ack 的时间；</li><li>End to End Duration 表示整个 operator 的所有 subtask 中完成 snapshot 的最长时间；</li><li>State Size 表示当前 Checkpoint 的 state 大小 – 主要这里如果是增量 checkpoint 的话，则表示增量大小；</li><li>Buffered During Alignment 表示在 barrier 对齐阶段积攒了多少数据，如果这个数据过大也间接表示对齐比较慢）；</li></ul><p>Checkpoint 失败大致分为两种情况：Checkpoint Decline 和 Checkpoint Expire。</p><h5 id="2-1-1-Checkpoint-Decline"><a href="#2-1-1-Checkpoint-Decline" class="headerlink" title="2.1.1 Checkpoint Decline"></a>2.1.1 Checkpoint Decline</h5><p>我们能从 jobmanager.log 中看到类似下面的日志</p><p>Decline checkpoint 10423 by task 0b60f08bf8984085b59f8d9bc74ce2e1 of job 85d268e6fbc19411185f7e4868a44178. 其中<br>10423 是 checkpointID，0b60f08bf8984085b59f8d9bc74ce2e1 是 execution id，85d268e6fbc19411185f7e4868a44178 是 job id，我们可以在 jobmanager.log 中查找 execution id，找到被调度到哪个 taskmanager 上，类似如下所示：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2019-09-02 16:26:20,972 INFO  [jobmanager-future-thread-61] org.apache.flink.runtime.executiongraph.ExecutionGraph        - XXXXXXXXXXX (100/289) (87b751b1fd90e32af55f02bb2f9a9892) switched from SCHEDULED to DEPLOYING.</span><br><span class="line">2019-09-02 16:26:20,972 INFO  [jobmanager-future-thread-61] org.apache.flink.runtime.executiongraph.ExecutionGraph        - Deploying XXXXXXXXXXX (100/289) (attempt #0) to slot container_e24_1566836790522_8088_04_013155_1 on hostnameABCDE</span><br></pre></td></tr></table></figure><p>从上面的日志我们知道该 execution 被调度到 hostnameABCDE 的 container_e24_1566836790522_8088_04_013155_1 slot 上，接下来我们就可以到 container container_e24_1566836790522_8088_04_013155 的 taskmanager.log 中查找 Checkpoint 失败的具体原因了。</p><p>另外对于 Checkpoint Decline 的情况，有一种情况我们在这里单独抽取出来进行介绍：Checkpoint Cancel。</p><p>当前 Flink 中如果较小的 Checkpoint 还没有对齐的情况下，收到了更大的 Checkpoint，则会把较小的 Checkpoint 给取消掉。我们可以看到类似下面的日志：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$taskNameWithSubTaskAndID: Received checkpoint barrier for checkpoint 20 before completing current checkpoint 19. Skipping current checkpoint.</span><br></pre></td></tr></table></figure><p>这个日志表示，当前 Checkpoint 19 还在对齐阶段，我们收到了 Checkpoint 20 的 barrier。然后会逐级通知到下游的 task checkpoint 19 被取消了，同时也会通知 JM 当前 Checkpoint 被 decline 掉了。</p><p>在下游 task 收到被 cancelBarrier 的时候，会打印类似如下的日志：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">DEBUG</span><br><span class="line">$taskNameWithSubTaskAndID: Checkpoint 19 canceled, aborting alignment.</span><br><span class="line"></span><br><span class="line">或者</span><br><span class="line"></span><br><span class="line">DEBUG</span><br><span class="line">$taskNameWithSubTaskAndID: Checkpoint 19 canceled, skipping alignment.</span><br><span class="line"></span><br><span class="line">或者</span><br><span class="line"></span><br><span class="line">WARN</span><br><span class="line">$taskNameWithSubTaskAndID: Received cancellation barrier for checkpoint 20 before completing current checkpoint 19. Skipping current checkpoint.</span><br></pre></td></tr></table></figure><p>上面三种日志都表示当前 task 接收到上游发送过来的 barrierCancel 消息，从而取消了对应的 Checkpoint。</p><h5 id="2-1-2-Checkpoint-Expire"><a href="#2-1-2-Checkpoint-Expire" class="headerlink" title="2.1.2 Checkpoint Expire"></a>2.1.2 Checkpoint Expire</h5><p>如果 Checkpoint 做的非常慢，超过了 timeout 还没有完成，则整个 Checkpoint 也会失败。当一个 Checkpoint 由于超时而失败是，会在 jobmanager.log 中看到如下的日志：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Checkpoint 1 of job 85d268e6fbc19411185f7e4868a44178  expired before completing.</span><br></pre></td></tr></table></figure><p>表示 Chekpoint 1 由于超时而失败，这个时候可以可以看这个日志后面是否有类似下面的日志：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Received late message for now expired checkpoint attempt 1 from 0b60f08bf8984085b59f8d9bc74ce2e1 of job 85d268e6fbc19411185f7e4868a44178.</span><br></pre></td></tr></table></figure><p>可以按照 2.1.1 中的方法找到对应的 taskmanager.log 查看具体信息。</p><blockquote><p>下面的日志如果是 DEBUG 的话，我们会在开始处标记 DEBUG</p></blockquote><p>我们按照下面的日志把 TM 端的 snapshot 分为三个阶段，开始做 snapshot 前，同步阶段，异步阶段：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DEBUG</span><br><span class="line">Starting checkpoint (6751) CHECKPOINT on task taskNameWithSubtasks (4/4)</span><br></pre></td></tr></table></figure><p>这个日志表示 TM 端 barrier 对齐后，准备开始做 Checkpoint。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">DEBUG</span><br><span class="line">2019-08-06 13:43:02,613 DEBUG org.apache.flink.runtime.state.AbstractSnapshotStrategy       - DefaultOperatorStateBackend snapshot (FsCheckpointStorageLocation &#123;fileSystem=org.apache.flink.core.fs.SafetyNetWrapperFileSystem@70442baf, checkpointDirectory=xxxxxxxx, sharedStateDirectory=xxxxxxxx, taskOwnedStateDirectory=xxxxxx, metadataFilePath=xxxxxx, reference=(default), fileStateSizeThreshold=1024&#125;, synchronous part) in thread Thread[Async calls on Source: xxxxxx</span><br><span class="line">_source -&gt; Filter (27/70),5,Flink Task Threads] took 0 ms.</span><br></pre></td></tr></table></figure><p>上面的日志表示当前这个 backend 的同步阶段完成，共使用了 0 ms。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DEBUG</span><br><span class="line">DefaultOperatorStateBackend snapshot (FsCheckpointStorageLocation &#123;fileSystem=org.apache.flink.core.fs.SafetyNetWrapperFileSystem@7908affe, checkpointDirectory=xxxxxx, sharedStateDirectory=xxxxx, taskOwnedStateDirectory=xxxxx,  metadataFilePath=xxxxxx, reference=(default), fileStateSizeThreshold=1024&#125;, asynchronous part) in thread Thread[pool-48-thread-14,5,Flink Task Threads] took 369 ms</span><br></pre></td></tr></table></figure><p>上面的日志表示异步阶段完成，异步阶段使用了 369 ms</p><p>在现有的日志情况下，我们通过上面三个日志，定位 snapshot 是开始晚，同步阶段做的慢，还是异步阶段做的慢。然后再按照情况继续进一步排查问题。</p><h4 id="2-2-Checkpoint-慢"><a href="#2-2-Checkpoint-慢" class="headerlink" title="2.2 Checkpoint 慢"></a>2.2 Checkpoint 慢</h4><p>在 2.1 节中，我们介绍了 Checkpoint 失败的排查思路，本节会分情况介绍 Checkpoint 慢的情况。</p><p>Checkpoint 慢的情况如下：比如 Checkpoint interval 1 分钟，超时 10 分钟，Checkpoint 经常需要做 9 分钟（我们希望 1 分钟左右就能够做完），而且我们预期 state size 不是非常大。</p><p>对于 Checkpoint 慢的情况，我们可以按照下面的顺序逐一检查。</p><h5 id="2-2-0-Source-Trigger-Checkpoint-慢"><a href="#2-2-0-Source-Trigger-Checkpoint-慢" class="headerlink" title="2.2.0 Source Trigger Checkpoint 慢"></a>2.2.0 Source Trigger Checkpoint 慢</h5><p>这个一般发生较少，但是也有可能，因为 source 做 snapshot 并往下游发送 barrier 的时候，需要抢锁（这个现在社区正在进行用 mailBox 的方式替代当前抢锁的方式，详情参考[1])。如果一直抢不到锁的话，则可能导致 Checkpoint 一直得不到机会进行。如果在 Source 所在的 taskmanager.log 中找不到开始做 Checkpoint 的 log，则可以考虑是否属于这种情况，可以通过 jstack 进行进一步确认锁的持有情况。</p><h5 id="2-2-1-使用增量-Checkpoint"><a href="#2-2-1-使用增量-Checkpoint" class="headerlink" title="2.2.1 使用增量 Checkpoint"></a>2.2.1 使用增量 Checkpoint</h5><p>现在 Flink 中 Checkpoint 有两种模式，全量 Checkpoint 和 增量 Checkpoint，其中全量 Checkpoint 会把当前的 state 全部备份一次到持久化存储，而增量 Checkpoint，则只备份上一次 Checkpoint 中不存在的 state，因此增量 Checkpoint 每次上传的内容会相对更好，在速度上会有更大的优势。</p><p>现在 Flink 中仅在 RocksDBStateBackend 中支持增量 Checkpoint，如果你已经使用 RocksDBStateBackend，可以通过开启增量 Checkpoint 来加速，具体的可以参考 [2]。</p><h5 id="2-2-2-作业存在反压或者数据倾斜"><a href="#2-2-2-作业存在反压或者数据倾斜" class="headerlink" title="2.2.2 作业存在反压或者数据倾斜"></a>2.2.2 作业存在反压或者数据倾斜</h5><p>我们知道 task 仅在接受到所有的 barrier 之后才会进行 snapshot，如果作业存在反压，或者有数据倾斜，则会导致全部的 channel 或者某些 channel 的 barrier 发送慢，从而整体影响 Checkpoint 的时间，这两个可以通过如下的页面进行检查：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-02-20-013106.jpg" alt=""></p><p>上图中我们选择了一个 task，查看所有 subtask 的反压情况，发现都是 high，表示反压情况严重，这种情况下会导致下游接收 barrier 比较晚。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-02-20-013126.jpg" alt=""></p><p>上图中我们选择其中一个 operator，点击所有的 subtask，然后按照 Records Received/Bytes Received/TPS 从大到小进行排序，能看到前面几个 subtask 会比其他的 subtask 要处理的数据多。</p><p>如果存在反压或者数据倾斜的情况，我们需要首先解决反压或者数据倾斜问题之后，再查看 Checkpoint 的时间是否符合预期。</p><h5 id="2-2-2-Barrier-对齐慢"><a href="#2-2-2-Barrier-对齐慢" class="headerlink" title="2.2.2 Barrier 对齐慢"></a>2.2.2 Barrier 对齐慢</h5><p>从前面我们知道 Checkpoint 在 task 端分为 barrier 对齐（收齐所有上游发送过来的 barrier），然后开始同步阶段，再做异步阶段。如果 barrier 一直对不齐的话，就不会开始做 snapshot。</p><p>barrier 对齐之后会有如下日志打印：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DEBUG</span><br><span class="line">Starting checkpoint (6751) CHECKPOINT on task taskNameWithSubtasks (4/4)</span><br></pre></td></tr></table></figure><p>如果 taskmanager.log 中没有这个日志，则表示 barrier 一直没有对齐，接下来我们需要了解哪些上游的 barrier 没有发送下来，如果你使用 At Least Once 的话，可以观察下面的日志：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DEBUG</span><br><span class="line">Received barrier for checkpoint 96508 from channel 5</span><br></pre></td></tr></table></figure><p>表示该 task 收到了 channel 5 来的 barrier，然后看对应 Checkpoint，再查看还剩哪些上游的 barrier 没有接受到，对于 ExactlyOnce 暂时没有类似的日志，可以考虑自己添加，或者 jmap 查看。</p><h5 id="2-2-3-主线程太忙，导致没机会做-snapshot"><a href="#2-2-3-主线程太忙，导致没机会做-snapshot" class="headerlink" title="2.2.3 主线程太忙，导致没机会做 snapshot"></a>2.2.3 主线程太忙，导致没机会做 snapshot</h5><p>在 task 端，所有的处理都是单线程的，数据处理和 barrier 处理都由主线程处理，如果主线程在处理太慢（比如使用 RocksDBBackend，state 操作慢导致整体处理慢），导致 barrier 处理的慢，也会影响整体 Checkpoint 的进度，在这一步我们需要能够查看某个 PID 对应 hotmethod，这里推荐两个方法：</p><ul><li>多次连续 jstack，查看一直处于 RUNNABLE 状态的线程有哪些；</li><li>使用工具 AsyncProfile dump 一份火焰图，查看占用 CPU 最多的栈；</li></ul><p>如果有其他更方便的方法当然更好，也欢迎推荐。</p><h5 id="2-2-4-同步阶段做的慢"><a href="#2-2-4-同步阶段做的慢" class="headerlink" title="2.2.4 同步阶段做的慢"></a>2.2.4 同步阶段做的慢</h5><p>同步阶段一般不会太慢，但是如果我们通过日志发现同步阶段比较慢的话，对于非 RocksDBBackend 我们可以考虑查看是否开启了异步 snapshot，如果开启了异步 snapshot 还是慢，需要看整个 JVM 在干嘛，也可以使用前一节中的工具。对于 RocksDBBackend 来说，我们可以用 iostate 查看磁盘的压力如何，另外可以查看 tm 端 RocksDB 的 log 的日志如何，查看其中 SNAPSHOT 的时间总共开销多少。</p><p>RocksDB 开始 snapshot 的日志如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2019/09/10-14:22:55.734684 7fef66ffd700 [utilities/checkpoint/checkpoint_impl.cc:83] Started the snapshot process -- creating snapshot in directory /tmp/flink-io-87c360ce-0b98-48f4-9629-2cf0528d5d53/XXXXXXXXXXX/chk-92729</span><br></pre></td></tr></table></figure><p>snapshot 结束的日志如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2019/09/10-14:22:56.001275 7fef66ffd700 [utilities/checkpoint/checkpoint_impl.cc:145] Snapshot DONE. All is good</span><br></pre></td></tr></table></figure><p>#####2.2.6 异步阶段做的慢</p><p>对于异步阶段来说，tm 端主要将 state 备份到持久化存储上，对于非 RocksDBBackend 来说，主要瓶颈来自于网络，这个阶段可以考虑观察网络的 metric，或者对应机器上能够观察到网络流量的情况（比如 iftop)。</p><p>对于 RocksDB 来说，则需要从本地读取文件，写入到远程的持久化存储上，所以不仅需要考虑网络的瓶颈，还需要考虑本地磁盘的性能。另外对于 RocksDBBackend 来说，如果觉得网络流量不是瓶颈，但是上传比较慢的话，还可以尝试考虑开启多线程上传功能[3]。</p><h3 id="3-总结"><a href="#3-总结" class="headerlink" title="3 总结"></a>3 总结</h3><p>在第二部分内容中，我们介绍了官方编译的包的情况下排查一些 Checkpoint 异常情况的主要场景，以及相应的排查方法，如果排查了上面所有的情况，还是没有发现瓶颈所在，则可以考虑添加更详细的日志，逐步将范围缩小，然后最终定位原因。</p><p>上文提到的一些 DEBUG 日志，如果 flink dist 包是自己编译的话，则建议将 Checkpoint 整个步骤内的一些 DEBUG 改为 INFO，能够通过日志了解整个 Checkpoint 的整体阶段，什么时候完成了什么阶段，也在 Checkpoint 异常的时候，快速知道每个阶段都消耗了多少时间。</p><h3 id="参考内容"><a href="#参考内容" class="headerlink" title="参考内容"></a>参考内容</h3><p>[1]、<a href="https://issues.apache.org/jira/browse/FLINK-12477">Change threading-model in StreamTask to a mailbox-based approach</a><br>[2]、<a href="https://mp.weixin.qq.com/s/rIgrAscMIJLPpfKytmp4Mw">增量 checkpoint 原理介绍</a><br>[3]、<a href="https://issues.apache.org/jira/browse/FLINK-11008">RocksDBStateBackend 多线程上传 State</a></p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在 Flink 中，状态可靠性保证由 Checkpoint 支持，当作业出现 failover 的情况下，Flink 会从最近成功的 Checkpoint 恢复。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Apache Flink 1.10.0 重磅发布，新特性解读</title>
    <link href="http://www.54tianzhisheng.cn/2020/02/11/flink-1.10/"/>
    <id>http://www.54tianzhisheng.cn/2020/02/11/flink-1.10/</id>
    <published>2020-02-10T16:00:00.000Z</published>
    <updated>2020-02-15T14:10:12.000Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Flink 社区迎来了激动人心的两位数位版本号，Flink 1.10.0 正式宣告发布！</p><a id="more"></a><p>作为 Flink 社区迄今为止规模最大的一次版本升级，Flink 1.10 容纳了超过 200 位贡献者对超过 1200 个 issue 的开发实现，包含对 Flink 作业的整体性能及稳定性的显著优化、对原生 Kubernetes 的初步集成以及对 Python 支持（PyFlink）的重大优化。</p><p>Flink 1.10 同时还标志着对 Blink 的整合宣告完成，随着对 Hive 的生产级别集成及对 TPC-DS 的全面覆盖，Flink 在增强流式 SQL 处理能力的同时也具备了成熟的批处理能力。本篇博客将对此次版本升级中的主要新特性及优化、值得注意的重要变化以及使用新版本的预期效果逐一进行介绍。</p><p>新版本的二进制发布包和源码包已经可以在最新的 Flink 官网<a href="https://flink.apache.org/downloads.html">下载页面</a>找到。更多细节请参考完整的版本<a href="https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12315522&amp;version=12345845">更新日志</a>以及最新的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/">用户文档</a>。</p><h2 id="新特性及优化"><a href="#新特性及优化" class="headerlink" title="新特性及优化"></a>新特性及优化</h2><h3 id="内存管理及配置优化"><a href="#内存管理及配置优化" class="headerlink" title="内存管理及配置优化"></a>内存管理及配置优化</h3><p>Flink 目前的 TaskExecutor 内存模型存在着一些缺陷，导致优化资源利用率比较困难，例如：</p><ul><li>流和批处理内存占用的配置模型不同；</li><li>流处理中的 RocksDB state backend 需要依赖用户进行复杂的配置。</li></ul><p>为了让内存配置变的对于用户更加清晰、直观，Flink 1.10 对 TaskExecutor 的内存模型和配置逻辑进行了较大的改动 <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-49%3A+Unified+Memory+Configuration+for+TaskExecutors">FLIP-49</a>。这些改动使得 Flink 能够更好地适配所有部署环境（例如 Kubernetes, Yarn, Mesos），让用户能够更加严格的控制其内存开销。</p><h4 id="Managed-内存扩展"><a href="#Managed-内存扩展" class="headerlink" title="Managed 内存扩展"></a>Managed 内存扩展</h4><p>Managed 内存的范围有所扩展，还涵盖了 RocksDB state backend 使用的内存。尽管批处理作业既可以使用堆内内存也可以使用堆外内存，使用 RocksDB state backend 的流处理作业却只能利用堆外内存。因此为了让用户执行流和批处理作业时无需更改集群的配置，我们规定从现在起 managed 内存只能在堆外。</p><h4 id="简化-RocksDB-配置"><a href="#简化-RocksDB-配置" class="headerlink" title="简化 RocksDB 配置"></a>简化 RocksDB 配置</h4><p>此前，配置像 RocksDB 这样的堆外 state backend 需要进行大量的手动调试，例如减小 JVM 堆空间、设置 Flink 使用堆外内存等。现在，Flink 的开箱配置即可支持这一切，且只需要简单地改变 managed 内存的大小即可调整 RocksDB state backend 的内存预算。 </p><p>另一个重要的优化是，Flink 现在可以限制 RocksDB 的 native 内存占用（<a href="https://issues.apache.org/jira/browse/FLINK-7289">FLINK-7289</a>），以避免超过总的内存预算——这对于 Kubernetes 等容器化部署环境尤为重要。关于如何开启、调试该特性，请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/state/large_state_tuning.html#tuning-rocksdb">RocksDB 调试</a>。</p><blockquote><p>注：FLIP-49 改变了集群的资源配置过程，因此从以前的 Flink 版本升级时可能需要对集群配置进行调整。详细的变更日志及调试指南请<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/memory/mem_setup.html">参考文档</a></p></blockquote><h3 id="统一的作业提交逻辑"><a href="#统一的作业提交逻辑" class="headerlink" title="统一的作业提交逻辑"></a>统一的作业提交逻辑</h3><p>在此之前，提交作业是由执行环境负责的，且与不同的部署目标（例如 Yarn, Kubernetes, Mesos）紧密相关。这导致用户需要针对不同环境保留多套配置，增加了管理的成本。</p><p>在 Flink 1.10 中，作业提交逻辑被抽象到了通用的 Executor 接口（<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-73%3A+Introducing+Executors+for+job+submission">FLIP-73</a>）。新增加的 ExecutorCLI （<a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=133631524">FLIP-81</a>）引入了为任意<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/cli.html#deployment-targets">执行目标</a>指定配置参数的统一方法。此外，随着引入 JobClient（<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-74%3A+Flink+JobClient+API">FLINK-74</a>）负责获取 JobExecutionResult，获取作业执行结果的逻辑也得以与作业提交解耦。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-02-15-120628.jpg" alt=""></p><p>上述改变向用户提供了统一的 Flink 入口，使得在 Apache Beam 或 Zeppelin notebooks 等下游框架中以编程方式使用 Flink 变的更加容易。对于需要在多种不同环境使用 Flink 的用户而言，新的基于配置的执行过程同样显著降低了冗余代码量以及维护开销。</p><h3 id="原生-Kubernetes-集成（Beta）"><a href="#原生-Kubernetes-集成（Beta）" class="headerlink" title="原生 Kubernetes 集成（Beta）"></a>原生 Kubernetes 集成（Beta）</h3><p>对于想要在容器化环境中尝试 Flink 的用户来说，想要在 Kubernetes 上部署和管理一个 Flink standalone 集群，首先需要对容器、算子及像 kubectl 这样的环境工具有所了解。</p><p>在 Flink 1.10 中，我们推出了初步的支持 session 模式的主动 Kubernetes 集成（<a href="https://jira.apache.org/jira/browse/FLINK-9953">FLINK-9953</a>）。其中，“主动”指 Flink ResourceManager (K8sResMngr) 原生地与 Kubernetes 通信，像 Flink 在 Yarn 和 Mesos 上一样按需申请 pod。用户可以利用 namespace，在多租户环境中以较少的资源开销启动 Flink。这需要用户提前配置好 RBAC 角色和有足够权限的服务账号。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-02-15-120748.jpg" alt=""></p><p>正如在统一的作业提交逻辑一节中提到的，Flink 1.10 将命令行参数映射到了统一的配置。因此，用户可以参阅 Kubernetes 配置选项，在命令行中使用以下命令向 Kubernetes 提交 Flink 作业。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/flink run -d -e kubernetes-session -Dkubernetes.cluster-id=&lt;ClusterId&gt; examples/streaming/WindowJoin.jar</span><br></pre></td></tr></table></figure><p>如果你希望第一时间尝试这一特性，欢迎参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/deployment/native_kubernetes.html">相关文档</a>、试用并与社区分享你的反馈意见。</p><h3 id="Table-API-SQL-生产可用的-Hive-集成"><a href="#Table-API-SQL-生产可用的-Hive-集成" class="headerlink" title="Table API/SQL: 生产可用的 Hive 集成"></a>Table API/SQL: 生产可用的 Hive 集成</h3><p>Flink 1.9 推出了预览版的 Hive 集成。该版本允许用户使用 SQL DDL 将 Flink 特有的元数据持久化到 Hive Metastore、调用 Hive 中定义的 UDF 以及读、写 Hive 中的表。Flink 1.10 进一步开发和完善了这一特性，带来了全面兼容 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/hive/#supported-hive-versions">Hive 主要版本</a>的生产可用的 Hive 集成。</p><h4 id="Batch-SQL-原生分区支持"><a href="#Batch-SQL-原生分区支持" class="headerlink" title="Batch SQL 原生分区支持"></a>Batch SQL 原生分区支持</h4><p>此前，Flink 只支持写入未分区的 Hive 表。在 Flink 1.10 中，Flink SQL 扩展支持了 INSERT OVERWRITE 和 PARTITION 的语法（<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-63%3A+Rework+table+partition+support">FLIP-63</a>），允许用户写入 Hive 中的静态和动态分区。</p><ul><li>写入静态分区</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT &#123; INTO | OVERWRITE &#125; TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...)] select_statement1 FROM from_statement;</span><br></pre></td></tr></table></figure><ul><li>写入动态分区</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT &#123; INTO | OVERWRITE &#125; TABLE tablename1 select_statement1 FROM from_statement;</span><br></pre></td></tr></table></figure><p>对分区表的全面支持，使得用户在读取数据时能够受益于分区剪枝，减少了需要扫描的数据量，从而大幅提升了这些操作的性能。</p><h4 id="其他优化"><a href="#其他优化" class="headerlink" title="其他优化"></a>其他优化</h4><p>除了分区剪枝，Flink 1.10 的 Hive 集成还引入了许多<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/hive/read_write_hive.html#optimizations">数据读取</a>方面的优化，例如：</p><ul><li>投影下推：Flink 采用了投影下推技术，通过在扫描表时忽略不必要的域，最小化 Flink 和 Hive 表之间的数据传输量。这一优化在表的列数较多时尤为有效。</li><li>LIMIT 下推：对于包含 LIMIT 语句的查询，Flink 在所有可能的地方限制返回的数据条数，以降低通过网络传输的数据量。</li><li>读取数据时的 ORC 向量化： 为了提高读取 ORC 文件的性能，对于 Hive 2.0.0 及以上版本以及非复合数据类型的列，Flink 现在默认使用原生的 ORC 向量化读取器。</li></ul><h4 id="将可插拔模块作为-Flink-内置对象（Beta）"><a href="#将可插拔模块作为-Flink-内置对象（Beta）" class="headerlink" title="将可插拔模块作为 Flink 内置对象（Beta）"></a>将可插拔模块作为 Flink 内置对象（Beta）</h4><p>Flink 1.10 在 Flink table 核心引入了通用的可插拔模块机制，目前主要应用于系统内置函数（<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-68%3A+Extend+Core+Table+System+with+Pluggable+Modules">FLIP-68</a>）。通过模块，用户可以扩展 Flink 的系统对象，例如像使用 Flink 系统函数一样使用 Hive 内置函数。新版本中包含一个预先实现好的 HiveModule，能够支持多个 Hive 版本，当然用户也可以选择编写自己的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/modules.html">可插拔模块</a>。</p><h3 id="其他-Table-API-SQL-优化"><a href="#其他-Table-API-SQL-优化" class="headerlink" title="其他 Table API/SQL 优化"></a>其他 Table API/SQL 优化</h3><h4 id="SQL-DDL-中的-watermark-和计算列"><a href="#SQL-DDL-中的-watermark-和计算列" class="headerlink" title="SQL DDL 中的 watermark 和计算列"></a>SQL DDL 中的 watermark 和计算列</h4><p>Flink 1.10 在 SQL DDL 中增加了针对流处理定义时间属性及产生 watermark 的语法扩展（<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-66%3A+Support+Time+Attribute+in+SQL+DDL">FLIP-66</a>）。这使得用户可以在用 DDL 语句创建的表上进行基于时间的操作（例如窗口）以及<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/sql/create.html#create-table">定义 watermark 策略</a>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE table_name (</span><br><span class="line"></span><br><span class="line">WATERMARK FOR columnName AS &lt;watermark_strategy_expression&gt;</span><br><span class="line"></span><br><span class="line">) WITH (</span><br><span class="line">...</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="其他-SQL-DDL-扩展"><a href="#其他-SQL-DDL-扩展" class="headerlink" title="其他 SQL DDL 扩展"></a>其他 SQL DDL 扩展</h4><p>Flink 现在严格区分临时/持久、系统/目录函数（<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-57%3A+Rework+FunctionCatalog">FLIP-57</a>）。这不仅消除了函数引用中的歧义，还带来了确定的函数解析顺序（例如，当存在命名冲突时，比起目录函数、持久函数 Flink 会优先使用系统函数、临时函数）。</p><p>在 FLIP-57 的基础上，我们扩展了 SQL DDL 的语法，支持创建目录函数、临时函数以及临时系统函数（<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-79+Flink+Function+DDL+Support">FLIP-79</a>）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CREATE [TEMPORARY|TEMPORARY SYSTEM] FUNCTION</span><br><span class="line"></span><br><span class="line">[IF NOT EXISTS] [catalog_name.][db_name.]function_name</span><br><span class="line"></span><br><span class="line">AS identifier [LANGUAGE JAVA|SCALA]</span><br></pre></td></tr></table></figure><p>关于目前完整的 Flink SQL DDL 支持，请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/sql/">最新的文档</a>。</p><blockquote><p>注：为了今后正确地处理和保证元对象（表、视图、函数）上的行为一致性，Flink 废弃了 Table API 中的部分对象申明方法，以使留下的方法更加接近标准的 SQL DDL（<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-64%3A+Support+for+Temporary+Objects+in+Table+module">FLIP-64</a>）。</p></blockquote><h4 id="批处理完整的-TPC-DS-覆盖"><a href="#批处理完整的-TPC-DS-覆盖" class="headerlink" title="批处理完整的 TPC-DS 覆盖"></a>批处理完整的 TPC-DS 覆盖</h4><p>TPC-DS 是广泛使用的业界标准决策支持 benchmark，用于衡量基于 SQL 的数据处理引擎性能。Flink 1.10 端到端地支持所有 TPC-DS 查询（<a href="https://issues.apache.org/jira/browse/FLINK-11491">FLINK-11491</a>），标志着 Flink SQL 引擎已经具备满足现代数据仓库及其他类似的处理需求的能力。</p><h3 id="PyFlink-支持原生用户自定义函数（UDF）"><a href="#PyFlink-支持原生用户自定义函数（UDF）" class="headerlink" title="PyFlink: 支持原生用户自定义函数（UDF）"></a>PyFlink: 支持原生用户自定义函数（UDF）</h3><p>作为 Flink 全面支持 Python 的第一步，在之前版本中我们发布了预览版的 PyFlink。在新版本中，我们专注于让用户在 Table API/SQL 中注册并使用自定义函数（UDF，另 UDTF / UDAF 规划中）（<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-58%3A+Flink+Python+User-Defined+Stateless+Function+for+Table">FLIP-58</a>）。</p><p><img src="https://flink.apache.org/img/blog/2020-02-11-release-1.10.0/flink_1.10_pyflink.gif" alt=""></p><p>如果你对这一特性的底层实现（基于 Apache Beam 的可移植框架）感兴趣，请参考 FLIP-58 的 Architecture 章节以及 <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-78%3A+Flink+Python+UDF+Environment+and+Dependency+Management">FLIP-78</a>。这些数据结构为支持 Pandas 以及今后将 PyFlink 引入到 DataStream API 奠定了基础。</p><p>从 Flink 1.10 开始，用户只要执行以下命令就可以轻松地通过 pip 安装 PyFlink：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install apache-flink</span><br></pre></td></tr></table></figure><h2 id="重要变更"><a href="#重要变更" class="headerlink" title="重要变更"></a>重要变更</h2><ul><li>FLINK-10725：Flink 现在可以使用 Java 11 编译和运行。</li><li>FLINK-15495：SQL 客户端现在默认使用 Blink planner，向用户提供最新的特性及优化。Table API 同样计划在下个版本中从旧的 planner 切换到 Blink planner，我们建议用户现在就开始尝试和熟悉 Blink planner。</li><li>FLINK-13025：新的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/connectors/elasticsearch.html#elasticsearch-connector">Elasticsearch sink connector</a> 全面支持 Elasticsearch 7.x 版本。</li><li>FLINK-15115：Kafka 0.8 和 0.9 的 connector 已被标记为废弃并不再主动支持。如果你还在使用这些版本或有其他相关问题，请通过 @dev 邮件列表联系我们。</li><li>FLINK-14516：非基于信用的网络流控制已被移除，同时移除的还有配置项“taskmanager.network.credit.model”。今后，Flink 将总是使用基于信用的网络流控制。</li><li>FLINK-12122：在 Flink 1.5.0 中，<a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=65147077">FLIP-6</a> 改变了 slot 在 TaskManager 之间的分布方式。要想使用此前的调度策略，既尽可能将负载分散到所有当前可用的 TaskManager，用户可以在 flink-conf.yaml 中设置 “cluster.evenly-spread-out-slots: true”。</li><li>FLINK-11956：s3-hadoop 和 s3-presto 文件系统不再使用类重定位加载方式，而是使用插件方式加载，同时无缝集成所有认证提供者。我们强烈建议其他文件系统也只使用插件加载方式，并将陆续移除重定位加载方式。</li><li>Flink 1.9 推出了新的 Web UI，同时保留了原来的 Web UI 以备不时之需。截至目前，我们没有收到关于新的 UI 存在问题的反馈，因此社区投票决定在 Flink 1.10 中移除旧的 Web UI。</li></ul><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、实战、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Apache Flink 社区迎来了激动人心的两位数位版本号，Flink 1.10.0 正式宣告发布！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Flink 视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新</title>
    <link href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/"/>
    <id>http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/</id>
    <published>2019-12-30T16:00:00.000Z</published>
    <updated>2020-02-15T05:25:08.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><a id="more"></a><h3 id="Flink-专栏"><a href="#Flink-专栏" class="headerlink" title="Flink 专栏"></a>Flink 专栏</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><p>专栏大纲：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-055430.jpg" alt=""></p><h2 id="Flink-学习项目代码"><a href="#Flink-学习项目代码" class="headerlink" title="Flink 学习项目代码"></a>Flink 学习项目代码</h2><p><a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>麻烦路过的各位亲给这个项目点个 star，太不易了，写了这么多，算是对我坚持下来的一种鼓励吧！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-05-25-124027.jpg" alt=""></p><h2 id="本项目结构"><a href="#本项目结构" class="headerlink" title="本项目结构"></a>本项目结构</h2><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-23-125710.jpg" alt=""></p><h2 id="How-to-build"><a href="#How-to-build" class="headerlink" title="How to build"></a>How to build</h2><p>Maybe your Maven conf file <code>settings.xml</code> mirrors can add aliyun central mirror :</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">id</span>&gt;</span>alimaven<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>aliyun maven<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://maven.aliyun.com/repository/central<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br></pre></td></tr></table></figure><p>then you can run the following command :</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn clean package -Dmaven.test.skip=true</span><br></pre></td></tr></table></figure><p>you can see following result if build success.</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-27-121923.jpg" alt=""></p><h2 id="Change"><a href="#Change" class="headerlink" title="Change"></a>Change</h2><p>2019/09/06 将该项目的 Flink 版本升级到 1.9.0，有一些变动，Flink 1.8.0 版本的代码经群里讨论保存在分支 <a href="https://github.com/zhisheng17/flink-learning/tree/feature/flink-1.8.0">feature/flink-1.8.0</a> 以便部分同学需要。</p><p>2019/06/08 新增 Flink 四本电子书籍的 PDF，在 books 目录下：</p><ul><li><p><a href="https://github.com/zhisheng17/flink-learning/blob/master/books/Introduction_to_Apache_Flink_book.pdf">Introduction_to_Apache_Flink_book.pdf</a>    这本书比较薄，处于介绍阶段，国内有这本的翻译书籍</p></li><li><p><a href="https://github.com/zhisheng17/flink-learning/blob/master/books/Learning_Apache_Flink.pdf">Learning Apache Flink.pdf</a>    这本书比较基础，初学的话可以多看看</p></li><li><p><a href="https://github.com/zhisheng17/flink-learning/blob/master/books/Stream_Processing_with_Apache_Flink.pdf">Stream Processing with Apache Flink.pdf</a>    这本书是 Flink PMC 写的</p></li><li><p><a href="https://github.com/zhisheng17/flink-learning/blob/master/books/Streaming_System.pdf">Streaming System.pdf</a>  这本书评价不是一般的高</p></li></ul><p>2019/06/09 新增流处理引擎相关的 Paper，在 paper 目录下：</p><ul><li><a href="https://github.com/zhisheng17/flink-learning/blob/master/paper/paper.md">流处理引擎相关的 Paper</a></li></ul><h2 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h2><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="https://t.zsxq.com/uniY7mm">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><h3 id="Flink-源码项目结构"><a href="#Flink-源码项目结构" class="headerlink" title="Flink 源码项目结构"></a>Flink 源码项目结构</h3><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-23-125756.jpg" alt=""></p><h2 id="学习资料"><a href="#学习资料" class="headerlink" title="学习资料"></a>学习资料</h2><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号了。<br>你可以加我的微信：<strong>yuanblog_tzs</strong>，然后回复关键字：<strong>Flink</strong> 即可无条件获取到，转载请联系本人获取授权，违者必究。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-23-124320.jpg" alt=""></p><p>有人要问知识星球里面更新什么内容？值得加入吗？</p><p>目前知识星球内已更新的系列文章：</p><h3 id="大数据重磅炸弹"><a href="#大数据重磅炸弹" class="headerlink" title="大数据重磅炸弹"></a>大数据重磅炸弹</h3><p>1、<a href="https://t.zsxq.com/fqfuVRR​">《大数据重磅炸弹——实时计算引擎 Flink》开篇词</a></p><p>2、、<a href="https://t.zsxq.com/emMBaQN​">你公司到底需不需要引入实时计算引擎？</a></p><p>3、<a href="https://t.zsxq.com/eM3ZRf2">一文让你彻底了解大数据实时计算框架 Flink</a> ​</p><p>4、<a href="https://t.zsxq.com/eAyRz7Y">别再傻傻的分不清大数据框架Flink、Blink、Spark Streaming、Structured Streaming和Storm之间的区别了</a>​</p><p>5、<a href="https://t.zsxq.com/iaMJAe6​">Flink 环境准备看这一篇就够了</a>  </p><p>6、<a href="https://t.zsxq.com/iaMJAe6​">一文讲解从 Flink 环境安装到源码编译运行</a></p><p>7、<a href="https://t.zsxq.com/eaIIiAm">通过 WordCount 程序教你快速入门上手 Flink</a>  ​</p><p>8、<a href="https://t.zsxq.com/Vnq72jY​">Flink 如何处理 Socket 数据及分析实现过程</a>  </p><p>9、<a href="https://t.zsxq.com/BiyvFUZ​">Flink job 如何在 Standalone、YARN、Mesos、K8S 上部署运行？</a></p><p>10、<a href="https://t.zsxq.com/fufUBiA">Flink 数据转换必须熟悉的算子（Operator）</a></p><p>11、<a href="https://t.zsxq.com/r7aYB2V">Flink 中 Processing Time、Event Time、Ingestion Time 对比及其使用场景分析</a> </p><p>12、<a href="https://t.zsxq.com/byZbyrb">如何使用 Flink Window 及 Window 基本概念与实现原理</a></p><p>13、<a href="https://t.zsxq.com/VzNBi2r">如何使用 DataStream API 来处理数据？</a></p><p>14、<a href="https://t.zsxq.com/Iub6IQf">Flink WaterMark 详解及结合 WaterMark 处理延迟数据</a></p><h3 id="源码系列"><a href="#源码系列" class="headerlink" title="源码系列"></a>源码系列</h3><p>1、<a href="https://t.zsxq.com/UZfaYfE">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="https://t.zsxq.com/zZZjaYf">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="https://t.zsxq.com/zV7MnuJ">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="https://t.zsxq.com/QZVRZJA">Flink 源码解析 —— standalonesession 模式启动流程</a></p><p>5、<a href="https://t.zsxq.com/u3fayvf">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="https://t.zsxq.com/MnQRByb">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="https://t.zsxq.com/YJ2Zrfi">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="https://t.zsxq.com/qnMFEUJ">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="https://t.zsxq.com/naaMf6y">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="https://t.zsxq.com/qRFIm6I">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="https://t.zsxq.com/2VRrbuf">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="https://t.zsxq.com/RZbu7yN">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="https://t.zsxq.com/zV7MnuJ">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="https://t.zsxq.com/zV7MnuJ">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="https://t.zsxq.com/ynQNbeM">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="https://t.zsxq.com/JaQfeMf">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="https://t.zsxq.com/f6eAu3J">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>除了《从1到100深入学习Flink》源码学习这个系列文章，《从0到1学习Flink》的案例文章也会优先在知识星球更新，让大家先通过一些 demo 学习 Flink，再去深入源码学习！</p><p>如果学习 Flink 的过程中，遇到什么问题，可以在里面提问，我会优先解答，这里做个抱歉，自己平时工作也挺忙，微信的问题不能做全部做一些解答，<br>但肯定会优先回复给知识星球的付费用户的，庆幸的是现在星球里的活跃氛围还是可以的，有不少问题通过提问和解答的方式沉淀了下来。</p><p>1、<a href="https://t.zsxq.com/62rZV7q">为何我使用 ValueState 保存状态 Job 恢复是状态没恢复？</a></p><p>2、<a href="https://t.zsxq.com/yF2rjmY">flink中watermark究竟是如何生成的，生成的规则是什么，怎么用来处理乱序数据</a></p><p>3、<a href="https://t.zsxq.com/uzFIeiq">消费kafka数据的时候，如果遇到了脏数据，或者是不符合规则的数据等等怎么处理呢？</a></p><p>4、<a href="https://t.zsxq.com/Nz7QZBY">在Kafka 集群中怎么指定读取/写入数据到指定broker或从指定broker的offset开始消费？</a></p><p>5、<a href="https://t.zsxq.com/7UVBeMj">Flink能通过oozie或者azkaban提交吗？</a></p><p>6、<a href="https://t.zsxq.com/mUzRbY7">jobmanager挂掉后，提交的job怎么不经过手动重新提交执行？</a></p><p>7、<a href="https://t.zsxq.com/Nju7EuV">使用flink-web-ui提交作业并执行 但是/opt/flink/log目录下没有日志文件 请问关于flink的日志（包括jobmanager、taskmanager、每个job自己的日志默认分别存在哪个目录 ）需要怎么配置？</a></p><p>8、<a href="https://t.zsxq.com/6muRz3j">通过flink 仪表盘提交的jar 是存储在哪个目录下？</a></p><p>9、<a href="https://t.zsxq.com/uvFQvFu">从Kafka消费数据进行etl清洗，把结果写入hdfs映射成hive表，压缩格式、hive直接能够读取flink写出的文件、按照文件大小或者时间滚动生成文件</a></p><p>10、<a href="https://t.zsxq.com/ubIY33f">flink jar包上传至集群上运行，挂掉后，挂掉期间kafka中未被消费的数据，在重新启动程序后，是自动从checkpoint获取挂掉之前的kafka offset位置，自动消费之前的数据进行处理，还是需要某些手动的操作呢？</a></p><p>11、<a href="https://t.zsxq.com/UfA2rBy">flink 启动时不自动创建 上传jar的路径，能指定一个创建好的目录吗</a></p><p>12、<a href="https://t.zsxq.com/zBMnIA6">Flink sink to es 集群上报 slot 不够，单机跑是好的，为什么？</a></p><p>13、<a href="https://t.zsxq.com/qrZBAQJ">Fllink to elasticsearch如何创建索引文档期时间戳？</a></p><p>14、<a href="https://t.zsxq.com/J2JiIMv">blink有没有api文档或者demo，是否建议blink用于生产环境。</a></p><p>15、<a href="https://t.zsxq.com/ZVVrjuv">flink的Python api怎样？bug多吗？</a></p><p>16、<a href="https://t.zsxq.com/zbybQNf">Flink VS Spark Streaming VS Storm VS Kafka Stream </a></p><p>17、<a href="https://t.zsxq.com/Zf6meAm">你们做实时大屏的技术架构是什么样子的？flume→kafka→flink→redis，然后后端去redis里面捞数据，酱紫可行吗？</a></p><p>18、<a href="https://t.zsxq.com/YniI2JQ">做一个统计指标的时候，需要在Flink的计算过程中多次读写redis，感觉好怪，星主有没有好的方案？</a></p><p>19、<a href="https://t.zsxq.com/fYZZfYf">Flink 使用场景大分析，列举了很多的常用场景，可以好好参考一下</a></p><p>20、<a href="https://t.zsxq.com/I6eEqR7">将kafka中数据sink到mysql时，metadata的数据为空，导入mysql数据不成功？？？</a></p><p>21、<a href="https://t.zsxq.com/62rZV7q">使用了ValueState来保存中间状态，在运行时中间状态保存正常，但是在手动停止后，再重新运行，发现中间状态值没有了，之前出现的键值是从0开始计数的，这是为什么？是需要实现CheckpointedFunction吗？</a></p><p>22、<a href="https://t.zsxq.com/mQ7YbQJ">flink on yarn jobmanager的HA需要怎么配置。还是说yarn给管理了</a></p><p>23、<a href="https://t.zsxq.com/q3VvB6U">有两个数据流就行connect，其中一个是实时数据流（kafka 读取)，另一个是配置流。由于配置流是从关系型数据库中读取，速度较慢，导致实时数据流流入数据的时候，配置信息还未发送，这样会导致有些实时数据读取不到配置信息。目前采取的措施是在connect方法后的flatmap的实现的在open 方法中，提前加载一次配置信息，感觉这种实现方式不友好，请问还有其他的实现方式吗？</a></p><p>24、<a href="https://t.zsxq.com/7UVBeMj">Flink能通过oozie或者azkaban提交吗？</a></p><p>25、<a href="https://t.zsxq.com/mUzRbY7">不采用yarm部署flink，还有其他的方案吗？ 主要想解决服务器重启后，flink服务怎么自动拉起？ jobmanager挂掉后，提交的job怎么不经过手动重新提交执行？</a></p><p>26、<a href="https://t.zsxq.com/bYnimQv">在一个 Job 里将同份数据昨晚清洗操作后，sink 到后端多个地方（看业务需求），如何保持一致性？（一个sink出错，另外的也保证不能插入）</a></p><p>27、<a href="https://t.zsxq.com/YvBAyrV">flink sql任务在某个特定阶段会发生tm和jm丢失心跳，是不是由于gc时间过长呢，</a></p><p>28、<a href="https://t.zsxq.com/fayf2Vv">有这样一个需求，统计用户近两周进入产品详情页的来源（1首页大搜索，2产品频道搜索，3其他），为php后端提供数据支持，该信息在端上报事件中，php直接获取有点困难。 我现在的解决方案 通过flink滚动窗口（半小时），统计用户半小时内3个来源pv，然后按照日期序列化，直接写mysql。php从数据库中解析出来，再去统计近两周占比。 问题1，这个需求适合用flink去做吗？ 问题2，我的方案总感觉怪怪的，有没有好的方案？</a></p><p>29、<a href="https://t.zsxq.com/ZFiY3VZ">一个task slot  只能同时运行一个任务还是多个任务呢？如果task  slot运行的任务比较大，会出现OOM的情况吗？</a></p><p>30、<a href="https://t.zsxq.com/Yn2JqB6">你们怎么对线上flink做监控的，如果整个程序失败了怎么自动重启等等</a></p><p>31、<a href="https://t.zsxq.com/YFMFeaA">flink cep规则动态解析有接触吗？有没有成型的框架？</a></p><p>32、<a href="https://t.zsxq.com/VZvRrjm">每一个Window都有一个watermark吗？window是怎么根据watermark进行触发或者销毁的？</a></p><p>33、<a href="https://t.zsxq.com/R3ZZJUF"> CheckPoint与SavePoint的区别是什么？</a></p><p>34、<a href="https://t.zsxq.com/Aa62Bim">flink可以在算子中共享状态吗？或者大佬你有什么方法可以共享状态的呢？</a></p><p>35、<a href="https://t.zsxq.com/ayFmmMF">运行几分钟就报了，看taskmager日志，报的是 failed elasticsearch bulk request null，可是我代码里面已经做过空值判断了呀 而且也过滤掉了，flink版本1.7.2 es版本6.3.1</a></p><p>36、<a href="https://t.zsxq.com/Yzzzb2b">这种情况，我们调并行度 还是配置参数好</a></p><p>37、<a href="https://t.zsxq.com/AqBUR3f">大家都用jdbc写，各种数据库增删查改拼sql有没有觉得很累，ps.set代码一大堆，还要计算每个参数的位置</a></p><p>38、<a href="https://t.zsxq.com/AqBUR3f">关于datasource的配置，每个taskmanager对应一个datasource?还是每个slot? 实际运行下来，每个slot中datasorce线程池只要设置1就行了，多了也用不到?</a></p><p>39、<a href="https://t.zsxq.com/AqBUR3f">kafka现在每天出现数据丢失，现在小批量数据，一天200W左右, kafka版本为 1.0.0，集群总共7个节点，TOPIC有十六个分区，单条报文1.5k左右</a></p><p>40、<a href="https://t.zsxq.com/AqBUR3f">根据key.hash的绝对值 对并发度求模，进行分组，假设10各并发度，实际只有8个分区有处理数据，有2个始终不处理，还有一个分区处理的数据是其他的三倍，如截图</a></p><p>41、<a href="https://t.zsxq.com/AqBUR3f">flink每7小时不知道在处理什么， CPU 负载 每7小时，有一次高峰，5分钟内平均负载超过0.8，如截图</a></p><p>42、<a href="https://t.zsxq.com/M3fIMbu">有没有Flink写的项目推荐？我想看到用Flink写的整体项目是怎么组织的，不单单是一个单例子</a></p><p>43、<a href="https://t.zsxq.com/yv7EQFA">Flink 源码的结构图</a></p><p>44、<a href="https://t.zsxq.com/vBAYNJq">我想根据不同业务表（case when）进行不同的redis sink（hash ，set），我要如何操作？</a></p><p>45、<a href="https://t.zsxq.com/b2zbUJa">这个需要清理什么数据呀，我把hdfs里面的已经清理了 启动还是报这个</a></p><p>46、<a href="https://t.zsxq.com/QjQFmQr">  在流处理系统，在机器发生故障恢复之后，什么情况消息最多会被处理一次？什么情况消息最少会被处理一次呢？</a></p><p>47、<a href="https://t.zsxq.com/zbQNfuJ">我检查点都调到5分钟了，这是什么问题</a></p><p>48、<a href="https://t.zsxq.com/ZrjEauN">reduce方法后 那个交易时间 怎么不是最新的，是第一次进入的那个时间，</a></p><p>49、<a href="https://t.zsxq.com/VJyr3bM">Flink  on Yarn 模式，用yarn session脚本启动的时候，我在后台没有看到到Jobmanager，TaskManager，ApplicationMaster这几个进程，想请问一下这是什么原因呢？因为之前看官网的时候，说Jobmanager就是一个jvm进程，Taskmanage也是一个JVM进程</a></p><p>50、<a href="https://t.zsxq.com/VJyr3bM">Flink  on Yarn的时候得指定 多少个TaskManager和每个TaskManager slot去运行任务，这样做感觉不太合理，因为用户也不知道需要多少个TaskManager适合，Flink 有动态启动TaskManager的机制吗。</a></p><p>51、<a href="https://t.zsxq.com/UBmUJMv">参考这个例子，Flink 零基础实战教程：如何计算实时热门商品 | Jark’s Blog， 窗口聚合的时候，用keywindow，用的是timeWindowAll，然后在aggregate的时候用aggregate(new CustomAggregateFunction(), new CustomWindowFunction())，打印结果后，发现窗口中一直使用的重复的数据，统计的结果也不变，去掉CustomWindowFunction()就正常了 ？ 非常奇怪</a></p><p>52、<a href="https://t.zsxq.com/naQb6aI">用户进入产品预定页面（端埋点上报），并填写了一些信息（端埋点上报），但半小时内并没有产生任何订单，然后给该类用户发送一个push。 1. 这种需求适合用flink去做吗？2. 如果适合，说下大概的思路</a></p><p>53、<a href="https://t.zsxq.com/AUf2VNz">业务场景是实时获取数据存redis，请问我要如何按天、按周、按月分别存入redis里？（比方说过了一天自动换一个位置存redis）</a></p><p>54、<a href="https://t.zsxq.com/UJ6Y7m2">有人 AggregatingState 的例子吗, 感觉官方的例子和 官网的不太一样?</a></p><p>55、<a href="https://t.zsxq.com/r3BaAY3">flink-jdbc这个jar有吗？怎么没找到啊？1.8.0的没找到，1.6.2的有</a></p><p>56、<a href="https://t.zsxq.com/jiybIee">现有个关于savepoint的问题，操作流程为，取消任务时设置保存点，更新任务，从保存点启动任务；现在遇到个问题，假设我中间某个算子重写，原先通过state编写，有用定时器，现在更改后，采用窗口，反正就是实现方式完全不一样；从保存点启动就会一直报错，重启，原先的保存点不能还原，此时就会有很多数据重复等各种问题，如何才能保证数据不丢失，不重复等，恢复到停止的时候，现在想到的是记下kafka的偏移量，再做处理，貌似也不是很好弄，有什么解决办法吗</a></p><p>57、<a href="https://t.zsxq.com/eMJmiQz">需要在flink计算app页面访问时长，消费Kafka计算后输出到Kafka。第一条log需要等待第二条log的时间戳计算访问时长。我想问的是，flink是分布式的，那么它能否保证执行的顺序性？后来的数据有没有可能先被执行？</a></p><p>58、<a href="https://t.zsxq.com/Y7e6aIu">我公司想做实时大屏，现有技术是将业务所需指标实时用spark拉到redis里存着，然后再用一条spark streaming流计算简单乘除运算，指标包含了各月份的比较。请问我该如何用flink简化上述流程？</a></p><p>59、<a href="https://t.zsxq.com/QbIayJ6">flink on yarn 方式，这样理解不知道对不对，yarn-session这个脚本其实就是准备yarn环境的，执行run任务的时候，根据yarn-session初始化的yarnDescription 把 flink 任务的jobGraph提交到yarn上去执行</a></p><p>60、<a href="https://t.zsxq.com/VFMRbYN">同样的代码逻辑写在单独的main函数中就可以成功的消费kafka ，写在一个spring boot的程序中，接受外部请求，然后执行相同的逻辑就不能消费kafka。你遇到过吗？能给一些查问题的建议，或者在哪里打个断点，能看到为什么消费不到kafka的消息呢？</a></p><p>61、<a href="https://t.zsxq.com/QNvjI6Q">请问下flink可以实现一个流中同时存在订单表和订单商品表的数据 两者是一对多的关系  能实现得到 以订单表为主 一个订单多个商品 这种需求嘛</a></p><p>62、<a href="https://t.zsxq.com/6ie66EE">在用中间状态的时候，如果中间一些信息保存在state中，有没有必要在redis中再保存一份，来做第三方的存储。</a></p><p>63、<a href="https://t.zsxq.com/bm6mYjI">能否出一期flink state的文章。什么场景下用什么样的state？如，最简单的，实时累加update到state。</a></p><p>64、<a href="https://t.zsxq.com/II6AEe2">flink的双流join博主有使用的经验吗？会有什么常见的问题吗</a></p><p>65、<a href="https://t.zsxq.com/V7EmUZR">窗口触发的条件问题</a></p><p>66、<a href="https://t.zsxq.com/JY3NJam">flink 定时任务怎么做？有相关的demo么？</a></p><p>67、<a href="https://t.zsxq.com/7YZ3Fuz">流式处理过程中数据的一致性如何保证或者如何检测</a></p><p>68、<a href="https://t.zsxq.com/nEEQvzR">重启flink单机集群，还报job not found 异常。</a></p><p>69、<a href="https://t.zsxq.com/qJyvzNj">kafka的数据是用 org.apache.kafka.common.serialization.ByteArraySerialize序列化的，flink这边消费的时候怎么通过FlinkKafkaConsumer创建DataStream<String>？</a></p><p>70、<a href="https://t.zsxq.com/byvnaEi">现在公司有一个需求，一些用户的支付日志，通过sls收集，要把这些日志处理后，结果写入到MySQL，关键这些日志可能连着来好几条才是一个用户的，因为发起请求，响应等每个环节都有相应的日志，这几条日志综合处理才能得到最终的结果，请问博主有什么好的方法没有？</a></p><p>71、<a href="https://t.zsxq.com/qfie6qR">flink 支持hadoop 主备么？ hadoop主节点挂了 flink 会切换到hadoop 备用节点？</a></p><p>72、<a href="https://t.zsxq.com/ZVZzZv7">请教大家: 实际 flink 开发中用 scala 多还是 java多些？ 刚入手 flink 大数据 scala 需要深入学习么？</a></p><p>73、<a href="https://t.zsxq.com/Qzbi6yn">我使用的是flink是1.7.2最近用了split的方式分流，但是底层的SplitStream上却标注为Deprecated，请问是官方不推荐使用分流的方式吗？</a></p><p>74、<a href="https://t.zsxq.com/Auf2NVR">KeyBy 的正确理解，和数据倾斜问题的解释</a></p><p>75、<a href="https://t.zsxq.com/3vnIm62">用flink时，遇到个问题 checkpoint大概有2G左右， 有背压时，flink会重启有遇到过这个问题吗</a></p><p>76、<a href="https://t.zsxq.com/URzVBIm">flink使用yarn-session方式部署，如何保证yarn-session的稳定性，如果yarn-session挂了，需要重新部署一个yarn-session，如何恢复之前yarn-session上的job呢，之前的checkpoint还能使用吗？</a></p><p>77、<a href="https://t.zsxq.com/MjyN7Uf">我想请教一下关于sink的问题。我现在的需求是从Kafka消费Json数据，这个Json数据字段可能会增加，然后将拿到的json数据以parquet的格式存入hdfs。现在我可以拿到json数据的schema，但是在保存parquet文件的时候不知道怎么处理。一是flink没有专门的format parquet，二是对于可变字段的Json怎么处理成parquet比较合适？</a></p><p>78、<a href="https://t.zsxq.com/6qBqVvZ">flink如何在较大的数据量中做去重计算。</a></p><p>79、<a href="https://t.zsxq.com/Eqjyju7">flink能在没有数据的时候也定时执行算子吗？</a></p><p>80、<a href="https://t.zsxq.com/i2zVfIi">使用rocksdb状态后端，自定义pojo怎么实现序列化和反序列化的，有相关demo么？</a></p><p>81、<a href="https://t.zsxq.com/vRJujAi">check point 老是失败，是不是自定义的pojo问题？到本地可以，到hdfs就不行，网上也有很多类似的问题 都没有一个很好的解释和解决方案</a></p><p>82、<a href="https://t.zsxq.com/MVFmuB6">cep规则如图，当start事件进入时，时间00:00:15，而后进入end事件，时间00:00:40。我发现规则无法命中。请问within 是从start事件开始计时？还是跟window一样根据系统时间划分的？如果是后者，请问怎么配置才能从start开始计时？</a></p><p>83、<a href="https://t.zsxq.com/EybM3vR">Flink聚合结果直接写Mysql的幂等性设计问题</a></p><p>84、<a href="https://t.zsxq.com/62VzNRF">Flink job打开了checkpoint，用的rocksdb，通过观察hdfs上checkpoint目录，为啥算副本总量会暴增爆减</a></p><p>85、<a href="">Flink 提交任务的 jar包可以指定路径为 HDFS 上的吗</a></p><p>86、<a href="https://t.zsxq.com/VfimieI">在flink web Ui上提交的任务，设置的并行度为2，flink是stand alone部署的。两个任务都正常的运行了几天了，今天有个地方逻辑需要修改，于是将任务cancel掉(在命令行cancel也试了)，结果taskmanger挂掉了一个节点。后来用其他任务试了，也同样会导致节点挂掉</a></p><p>87、<a href="https://t.zsxq.com/nee6qRv">一个配置动态更新的问题折腾好久（配置用个静态的map变量存着，有个线程定时去数据库捞数据然后存在这个map里面更新一把），本地 idea 调试没问题，集群部署就一直报 空指针异常。下游的算子使用这个静态变量map去get key在集群模式下会出现这个空指针异常，估计就是拿不到 map</a></p><p>88、<a href="https://t.zsxq.com/3bEUZfQ">批量写入MySQL，完成HBase批量写入</a></p><p>89、<a href="https://t.zsxq.com/Zb6AM3V">用flink清洗数据，其中要访问redis，根据redis的结果来决定是否把数据传递到下流，这有可能实现吗？</a></p><p>90、<a href="https://t.zsxq.com/RbeYZvb">监控页面流处理的时候这个发送和接收字节为0。</a></p><p>91、<a href="https://t.zsxq.com/MN7iuZf">sink到MySQL，如果直接用idea的话可以运行，并且成功，大大的代码上面用的FlinkKafkaConsumer010，而我的Flink版本为1.7，kafka版本为2.12，所以当我用FlinkKafkaConsumer010就有问题，于是改为<br>    FlinkKafkaConsumer就可以直接在idea完成sink到MySQL，但是为何当我把该程序打成Jar包，去运行的时候，就是报FlinkKafkaConsumer找不到呢</a></p><p>92、<a href="https://t.zsxq.com/e2VNN7Y">SocketTextStreamWordCount中输入中文统计不出来，请问这个怎么解决，我猜测应该是需要修改一下代码，应该是这个例子默认统计英文</a></p><p>93、<a href="https://t.zsxq.com/RVRn6AE"> Flink 应用程序本地 ide 里面运行的时候并行度是怎么算的？</a></p><p>94、<a href="https://t.zsxq.com/rzbIQBi"> 请问下flink中对于窗口的全量聚合有apply和process两种 他们有啥区别呢</a></p><p>95、<a href="https://t.zsxq.com/UJIubub">不知道大大熟悉Hbase不，我想直接在Hbase中查询某一列数据，因为有重复数据，所以想使用distinct统计实际数据量，请问Hbase中有没有类似于sql的distinct关键字。如果没有，想实现这种可以不？</a></p><p>96、<a href="https://t.zsxq.com/VFaQn2j"> 来分析一下现在Flink,Kafka方面的就业形势，以及准备就业该如何准备的这方面内容呢？</a></p><p>97、<a href="https://t.zsxq.com/Zn2FEQZ"> 大佬知道flink的dataStream可以转换为dataSet吗？因为数据需要11分钟一个批次计算五六个指标，并且涉及好几步reduce，计算的指标之间有联系，用Stream卡住了。</a></p><p>98、<a href="https://t.zsxq.com/aIqjmQN">1.如何在同一窗口内实现多次的聚合，比如像spark中的这样2.多个实时流的jion可以用window来处理一批次的数据吗？</a></p><p>99、<a href="https://t.zsxq.com/ZNvb2FM">写的批处理的功能，现在本机跑是没问题的，就是在linux集群上出现了问题，就是不知道如果通过本地调用远程jar包然后传参数和拿到结果参数返回本机</a></p><p>100、<a href="https://t.zsxq.com/femmiqf">我用standalone开启一个flink集群，上传flink官方用例Socket Window WordCount做测试，开启两个parallelism能正常运行，但是开启4个parallelism后出现错误</a></p><p>101、<a href="https://t.zsxq.com/YZ3vbY3"> 有使用AssignerWithPunctuatedWatermarks 的案例Demo吗？网上找了都是AssignerWithPeriodicWatermarks的，不知道具体怎么使用？</a></p><p>102、<a href="https://t.zsxq.com/uzFyVJe"> 有一个datastream(从文件读取的)，然后我用flink sql进行计算，这个sql是一个加总的运算，然后通过retractStreamTableSink可以把文件做sql的结果输出到文件吗？这个输出到文件的接口是用什么呢？</a></p><p>103、<a href="https://t.zsxq.com/6QNNrZz"> 为啥split这个流设置为过期的</a></p><p>104、<a href="https://t.zsxq.com/Q7YNRBE"> 需要使用flink table的水印机制控制时间的乱序问题，这种场景下我就使用水印+窗口了，我现在写的demo遇到了问题，就是在把触发计算的窗口table（WindowedTable）转换成table进行sql操作时发现窗口中的数据还是乱序的，是不是flink table的WindowedTable不支持水印窗口转table-sql的功能</a></p><p>105、<a href="https://t.zsxq.com/Jmayrbi"> Flink 对 SQL 的重视性</a></p><p>106、<a href="https://t.zsxq.com/ZrZfa2Z"> flink job打开了checkpoint，任务跑了几个小时后就出现下面的错，截图是打出来的日志，有个OOM，又遇到过的没？</a></p><p>107、<a href="https://t.zsxq.com/emaAeyj"> 本地测试是有数据的，之前该任务放在集群也是有数据的，可能提交过多次，现在读不到数据了 group id 也换过了， 只能重启集群解决么？</a></p><p>108、<a href="https://t.zsxq.com/ayBa6am">使用flink清洗数据存到es中，直接在flatmap中对处理出来的数据用es自己的ClientInterface类直接将数据存入es当中，不走sink，这样的处理逻辑是不是会有问题。</a></p><p>108、<a href="https://t.zsxq.com/QNvbE62"> flink从kafka拿数据（即增量数据）与存量数据进行内存聚合的需求，现在有一个方案就是程序启动的时候先用flink table将存量数据加载到内存中创建table中，然后将stream的增量数据与table的数据进行关联聚合后输出结束，不知道这种方案可行么。目前个人认为有两个主要问题：1是增量数据stream转化成append table后不知道能与存量的table关联聚合不，2是聚合后输出的结果数据是否过于频繁造成网络传输压力过大</a></p><p>109、<a href="https://t.zsxq.com/yzjAQ7a"> 设置时间时间特性有什么区别呢,  分别在什么场景下使用呢?两种设置时间延迟有什么区别呢 , 分别在什么场景下使用</a></p><p>110、<a href="https://t.zsxq.com/qRrJEaa"> flink从rabbitmq中读取数据，设置了rabbitmq的CorrelationDataId和checkpoint为EXACTLY_ONCE；如果flink完成一次checkpoint后，在这次checkpoint之前消费的数据都会从mq中删除。如果某次flink停机更新，那就会出现mq中的一些数据消费但是处于Unacked状态。在flink又重新开启后这批数据又会重新消费。那这样是不是就不能保证EXACTLY_ONCE了</a></p><p>111、<a href="https://t.zsxq.com/mAqn2RF">1. 在Flink checkpoint 中, 像 operator的状态信息 是在设置了checkpoint 之后自动的进行快照吗 ?2. 上面这个和我们手动存储的 Keyed State 进行快照(这个应该是增量快照)</a></p><p>112、<a href="https://t.zsxq.com/E2BeQ3f">现在有个实时商品数，交易额这种统计需求，打算用 flink从kafka读取binglog日志进行计算，但binglog涉及到insert和update这种操作时 怎么处理才能统计准确，避免那种重复计算的问题？</a></p><p>113、<a href="https://t.zsxq.com/vjIeyFI">我这边用flink做实时监控，功能很简单，就是每条消息做keyby然后三分钟窗口，然后做些去重操作，触发阈值则报警，现在问题是同一个时间窗口同一个人的告警会触发两次，集群是三台机器，standalone cluster，初步结果是三个算子里有两个收到了同样的数据</a></p><p>114、<a href="https://t.zsxq.com/unq3FIa">在使用WaterMark的时候，默认是每200ms去设置一次watermark，那么每个taskmanager之间，由于得到的数据不同，所以往往产生的最大的watermark不同。 那么这个时候，是各个taskmanager广播这个watermark，得到全局的最大的watermark，还是说各个taskmanager都各自用自己的watermark。主要没看到广播watermark的源码。不知道是自己观察不仔细还是就是没有广播这个变量。</a></p><p>115、<a href="https://t.zsxq.com/AeUnAyN">现在遇到一个需求，需要在job内部定时去读取redis的信息，想请教flink能实现像普通程序那样的定时任务吗？</a></p><p>116、<a href="https://t.zsxq.com/z7uZbY3">有个触发事件开始聚合，等到数量足够，或者超时则sink推mq 环境 flink 1.6 用了mapState 记录触发事件 1 数据足够这个OK 2 超时state ttl 1.6支持，但是问题来了，如何在超时时候增加自定义处理？</a></p><p>117、<a href="https://t.zsxq.com/R7UjeUF">请问impala这种mpp架构的sql引擎，为什么稳定性比较差呢？</a></p><p>118、<a href="https://t.zsxq.com/q7myfAQ">watermark跟并行度相关不是，过于全局了，期望是keyby之后再针对每个keyed stream 打watermark，这个有什么好的实践呢？</a></p><p>119、<a href="https://t.zsxq.com/rB6yfeA">请问如果把一个文件的内容读取成datastream和dataset，有什么区别吗？？他们都是一条数据一条数据的被读取吗？</a></p><p>120、<a href="https://t.zsxq.com/j2j6EyJ">有没有kylin相关的资料，或者调优的经验？</a></p><p>121、<a href="https://t.zsxq.com/iMjmQVV">flink先从jdbc读取配置表到流中，另外从kafka中新增或者修改这个配置，这个场景怎么把两个流一份配置流？我用的connect,接着发不成广播变量，再和实体流合并，但在合并时报Exception in thread “main” java.lang.IllegalArgumentException</a></p><p>122、<a href="https://t.zsxq.com/RFQNFIa">Flink  exactly-once，kafka版本为0.11.0 ，sink基于FlinkKafkaProducer011 每五分钟一次checkpoint，但是checkpoint开始后系统直接卡死，at-lease-once 一分钟能完成的checkpoint， 现在十分钟无法完成没进度还是0， 不知道哪里卡住了</a></p><p>123、<a href="https://t.zsxq.com/NJq3rj2">flink的状态是默认存在于内存的(也可以设置为rocksdb或hdfs)，而checkpoint里面是定时存放某个时刻的状态信息，可以设置hdfs或rocksdb是这样理解的吗？</a></p><p>124、<a href="https://t.zsxq.com/NJq3rj2">Flink异步IO中，下图这两种有什么区别？为啥要加 CompletableFuture.supplyAsync，不太明白？</a></p><p>125、<a href="https://t.zsxq.com/NJq3rj2">flink的状态是默认存在于内存的(也可以设置为rocksdb或hdfs)，而checkpoint里面是定时存放某个时刻的状态信息，可以设置hdfs或rocksdb是这样理解的吗？</a></p><p>126、<a href="https://t.zsxq.com/rniUrjm">有个计算场景，从kafka消费两个数据源，两个数据结构都有时间段概念，计算需要做的是匹配两个时间段，匹配到了，就生成一条新的记录。请问使用哪个工具更合适，flink table还是cep？请大神指点一下 我这边之前的做法，将两个数据流转为table.两个table over window后join成新的表。结果job跑一会就oom.</a></p><p>127、<a href="https://t.zsxq.com/vRZ7qJ2">一个互联网公司，或者一个业务系统，如果想做一个全面的监控要怎么做？有什么成熟的方案可以参考交流吗？有什么有什么度量指标吗？</a></p><p>128、<a href="https://t.zsxq.com/3vfyJau">怎么深入学习flink,或者其他大数据组件，能为未来秋招找一份大数据相关（计算方向）的工作增加自己的竞争力？</a></p><p>129、<a href="https://t.zsxq.com/VBIunun">oppo的实时数仓，其中明细层和汇总层都在kafka中，他们的关系库的实时数据也抽取到kafka的ods，那么在构建数仓的，需要join 三四个大业务表，业务表会变化，那么是大的业务表是从kafka的ods读取吗？实时数仓，多个大表join可以吗</a></p><p>130、<a href="https://t.zsxq.com/vnaURzj">Tuple类型有什么方法转换成json字符串吗？现在的场景是，结果在存储到sink中时希望存的是json字符串，这样应用程序获取数据比较好转换一点。如果Tuple不好转换json字符串，那么应该以什么数据格式存储到sink中</a></p><p>140、<a href="https://t.zsxq.com/J6eAmYb">端到端的数据保证，是否意味着中间处理程序中断，也不会造成该批次处理失败的消息丢失，处理程序重新启动之后，会再次处理上次未处理的消息</a></p><p>141、<a href="https://t.zsxq.com/7qBMrBe">关于flink datastream window相关的。比如我现在使用滚动窗口，统计一周内去重用户指标，按照正常watermark触发计算，需要等到当前周的window到达window的endtime时，才会触发，这样指标一周后才能产出结果。我能不能实现一小时触发一次计算，每次统计截止到当前时间，window中所有到达元素的去重数量。</a></p><p>142、<a href="https://t.zsxq.com/uJqzBIe">FLIP-16 Loop Fault Tolerance 是讲现在的checkpoint机制无法在stream loop的时候容错吗？现在这个问题解决了没有呀？</a></p><p>143、<a href="https://t.zsxq.com/uZnmQzv">现在的需求是，统计各个key的今日累计值，一分钟输出一次。如，各个用户今日累计点击次数。这种需求用datastream还是table API方便点？</a></p><p>144、<a href="https://t.zsxq.com/BqnYRN7">本地idea可以跑的工程，放在standalone集群上，总报错，报错截图如下，大佬请问这是啥原因</a></p><p>145、<a href="https://t.zsxq.com/7MJujMb">比如现在用k8s起了一个flink集群，这时候数据源kafka或者hdfs会在同一个集群上吗，还是会单独再起一个hdfs/kafka集群</a></p><p>146、<a href="https://t.zsxq.com/6U7QFMj">flink kafka sink 的FlinkFixedPartitioner 分配策略，在并行度小于topic的partitions时，一个并行实例固定的写消息到固定的一个partition，那么就有一些partition没数据写进去？</a></p><p>147、<a href="https://t.zsxq.com/fmq3fYF">基于事件时间，每五分钟一个窗口，五秒钟滑动一次，同时watermark的时间同样是基于事件事件时间的，延迟设为1分钟，假如数据流从12：00开始，如果12：07-12：09期间没有产生任何一条数据，即在12：07-12：09这段间的数据流情况为···· （12：07:00，xxx）,(12:09:00,xxx)······，那么窗口[12:02:05-12:07:05]，[12:02:10-12:07:10]等几个窗口的计算是否意味着只有等到，12：09：00的数据到达之后才会触发</a></p><p>148、<a href="https://t.zsxq.com/MRvv3ZV">使用flink1.7，当消费到某条消息(protobuf格式)，报Caused by: org.apache.kafka.common.KafkaException: Record batch for partition Notify-18 at offset 1803009 is invalid, cause: Record is corrupt 这个异常。 如何设置跳过已损坏的消息继续消费下一条来保证业务不终断？ 我看了官网kafka connectors那里，说在DeserializationSchema.deserialize(…)方法中返回null，flink就会跳过这条消息，然而依旧报这个异常</a></p><p>149、<a href="https://t.zsxq.com/MRJeAuj">是否可以抽空总结一篇Flink 的 watermark 的原理案例？一直没搞明白基于事件时间处理时的数据乱序和数据迟到底咋回事</a></p><p>150、<a href="https://t.zsxq.com/2rJyNrF">flink中rpc通信的原理，与几个类的讲解，有没有系统详细的文章样，如有求分享，谢谢</a></p><p>151、<a href="https://t.zsxq.com/bM3ZZRf">Flink中如何使用基于事件时间处理，但是又不使用Watermarks? 我在会话窗口中使用遇到一些问题，图一是基于处理时间的，测试结果session是基于keyby(用户)的，图二是基于事件时间的，不知道是我用法不对还是怎么的，测试结果发现并不是基于keyby(用户的)，而是全局的session。不知道怎么修改？</a></p><p>152、<a href="https://t.zsxq.com/BMVzzzB">flink实时计算平台，yarn模式日志收集怎么做，为什么会checkpoint失败，报警处理，后需要做什么吗？job监控怎么做</a></p><p>153、<a href="https://t.zsxq.com/237EAay">有flink与jstorm的在不同应用场景下, 性能比较的数据吗? 从网络上能找大部分都是flink与storm的比较. 在jstorm官网上有一份比较的图表, 感觉参考意义不大, 应该是比较早的flink版本.</a></p><p>154、<a href="https://t.zsxq.com/J6eAmYb">为什么使用SessionWindows.withGap窗口的话，State存不了东西呀，每次加1 ，拿出来都是null, 我换成 TimeWindow就没问题。</a></p><p>155、<a href="https://t.zsxq.com/y3nYZrf">请问一下，flink datastream流处理怎么统计去重指标？  官方文档中只看到批处理有distinct概念。</a></p><p>156、<a href="https://t.zsxq.com/qRjqFY3">好全的一篇文章，对比分析 Flink，Spark Streaming，Storm 框架</a></p><p>157、<a href="https://t.zsxq.com/Eau7qNB">关于 structured_streaming 的 paper</a></p><p>158、<a href="https://t.zsxq.com/rFYbEeq">zookeeper集群切换领导了，flink集群项目重启了就没有数据的输入和输出了，这个该从哪方面入手解决？</a></p><p>159、<a href="https://t.zsxq.com/nEAaYNF">我想请教下datastream怎么和静态数据join呢</a></p><p>160、<a href="https://t.zsxq.com/IAAeiA6">时钟问题导致收到了明天的数据，这时候有什么比较好的处理方法？看到有人设置一个最大的跳跃阈值，如果当前数据时间 - 历史最大时间 超过阈值就不更新。如何合理的设计水印，有没有一些经验呢？</a></p><p>161、<a href="https://t.zsxq.com/EuJ2RRf">大佬们flink怎么定时查询数据库？</a></p><p>162、<a href="https://t.zsxq.com/vzZBmYB">现在我们公司有个想法，就是提供一个页面，在页面上选择source sink 填写上sql语句，然后后台生成一个flink的作业，然后提交到集群。功能有点类似于华为的数据中台，就是页面傻瓜式操作。后台能自动根据相应配置得到结果。请问拘你的了解，可以实现吗？如何实现？有什么好的思路。现在我无从下手</a></p><p>163、<a href="https://t.zsxq.com/VRFIMfy">请教一下 flink on yarn 的 ha机制</a></p><p>164、<a href="https://t.zsxq.com/FAiiEyr">在一般的流处理以及cep, 都可以对于eventtime设置watermark, 有时可能需要设置相对大一点的值, 这内存压力就比较大, 有没有办法不应用jvm中的内存, 而用堆外内存, 或者其他缓存, 最好有cache机制, 这样可以应对大流量的峰值.</a></p><p>165、<a href="https://t.zsxq.com/YnI2F66">请教一个flink sql的问题。我有两个聚合后的流表A和B，A和Bjoin得到C表。在设置state TTL 的时候是直接对C表设置还是，对A表和B表设置比较好？</a></p><p>166、<a href="https://t.zsxq.com/unyneEU">spark改写为flink，会不会很复杂，还有这两者在SQL方面的支持差别大吗？</a></p><p>167、<a href="https://t.zsxq.com/RfyZFUR">请问flink allowedLateness导致窗口被多次fire，最终数据重复消费，这种问题怎么处理，数据是写到es中</a></p><p>168、<a href="https://t.zsxq.com/bIAEyFe">设置taskmanager.numberOfTaskSlots: 4的时候没有问题，但是cpu没有压上去，只用了30%左右，于是设置了taskmanager.numberOfTaskSlots: 8，但是就报错误找不到其中一个自定义的类，然后kafka数据就不消费了。为什么？cpu到多少合适？slot是不是和cpu数量一致是最佳配置？kafka分区数多少合适，是不是和slot,parallesim一致最佳？</a></p><p>169、<a href="https://t.zsxq.com/BUNfYnY">需求是根据每条日志切分出需要9个字段，有五个指标再根据9个字段的不同组合去做计算。  第一个方法是：我目前做法是切分的9个字段开5分钟大小1分钟计算一次的滑动窗口窗口，进行一次reduce去重，然后再map取出需要的字段，然后过滤再开5分钟大小1分钟计算一次的滑动窗口窗口进行计算保存结果，这个思路遇到的问题是上一个滑动窗口会每一分钟会计算5分钟数据，到第二个窗口划定的5分钟范围的数据会有好多重复，这个思路会造成数据重复。 第二个方法是：切分的9个字段开5分钟大小1分钟计算一次的滑动窗口窗口，再pross方法里完成所有的过滤，聚合计算，但是再高峰期每分钟400万条数据，这个思路担心在高峰期flink计算不过来</a></p><p>170、<a href="https://t.zsxq.com/aAqBEY7">a,b,c三个表，a和c有eventtime，a和c直接join可以，a和b join后再和c join 就会报错，这是怎么回事呢</a></p><p>171、<a href="https://t.zsxq.com/zZNNRzr">自定义的source是这样的（图一所示） 使用的时候是这样的（图二所示），为什么无论 sum.print().setParallelism(2)（图2所示）的并行度设置成几最后结果都是这样的</a></p><p>172、<a href="https://t.zsxq.com/i6Mz7Yj">刚接触flink，如有问的不合适的地方，请见谅。 1、为什么说flink是有状态的计算？ 2、这个状态是什么？3、状态存在哪里</a></p><p>173、<a href="https://t.zsxq.com/vNjAIMN">这边用flink 1.8.1的版本，采用flink on yarn，hadoop版本2.6.0。代码是一个简单的滚动窗口统计函数，但启动的时候报错，如下图片。  （2）然后我把flink版本换成1.7.1，重新提交到2.6.0的yarn平台，就能正常运行了。 （3）我们测试集群hadoop版本是3.0，我用flink 1.8.1版本将这个程序再次打包，提交到3.0版本的yarn平台，也能正常运行。 貌似是flink 1.8.1版本与yarn 2.6.0版本不兼容造成的这个问题</a></p><p>174、<a href="https://t.zsxq.com/2rVbm6Y">StateBackend我使用的是MemoryStateBackend， State是怎么释放内存的，例如我在函数中用ValueState存储了历史状态信息。但是历史状态数据我没有手动释放，那么程序会自动释放么？还是一直驻留在内存中</a></p><p>175、<a href="https://t.zsxq.com/3bIEAyv">请问老师是否可以提供一些Apachebeam的学习资料 谢谢</a></p><p>176、<a href="https://t.zsxq.com/yFEyZVB">flink 的 DataSet或者DataStream支持索引查询以及删除吗，像spark rdd，如果不支持的话，该转换成什么</a></p><p>177、<a href="https://t.zsxq.com/VNrn6iI">关于flink的状态，能否把它当做数据库使用，类似于内存数据库，在处理过程中存业务数据。如果是数据库可以算是分布式数据库吗?是不是使用rocksdb这种存储方式才算是?支持的单库大小是不是只是跟本地机器的磁盘大小相关?如果使用硬盘存储会不会效率性能有影响</a></p><p>178、<a href="https://t.zsxq.com/yfmiUvf">我这边做了个http sink，想要批量发送数据，不过现在只能用数量控制发送，但最后的几个记录没法触发发送动作，想问下有没有什么办法</a></p><p>179、<a href="https://t.zsxq.com/vNvrfmE">请问下如何做定时去重计数，就是根据时间分窗口，窗口内根据id去重计数得出结果，多谢。试了不少办法，没有简单直接办法</a></p><p>180、<a href="https://t.zsxq.com/rzZbQFA">我有个job使用了elastic search sink. 设置了批量5000一写入，但是看es监控显示每秒只能插入500条。是不是bulkprocessor的currentrequest为0有关</a></p><p>181、<a href="https://t.zsxq.com/aIur7ai">有docker部署flink的资料吗</a></p><p>182、<a href="https://t.zsxq.com/VjQjqF6">在说明KeyBy的StreamGraph执行过程时，keyBy的ID为啥是6？  根据前面说，ID是一个静态变量，每取一次就递增1，我觉得应该是3啊，是我理解错了吗</a></p><p>183、<a href="https://t.zsxq.com/BEmAIQv">有没计划出Execution Graph的远码解析</a></p><p>184、<a href="https://t.zsxq.com/vVjiYJQ">可以分享下物理执行图怎样划分task，以及task如何执行，还有他们之间数据如何传递这块代码嘛？</a></p><p>185、<a href="https://t.zsxq.com/FyNJQbQ">Flink源码和这个学习项目的结构图</a></p><p>186、<a href="https://t.zsxq.com/qrjmmaU">请问flink1.8，如何做到动态加载外部udf-jar包呢？</a></p><p>187、<a href="https://t.zsxq.com/ZFQjQnm">同一个Task Manager中不同的Slot是怎么交互的，比如：source处理完要传递给map的时候，如果在不同的Slot中，他们的内存是相互隔离，是怎么交互的呢？  我猜是通过序列化和反序列化对象，并且通过网络来进行交互的</a></p><p>188、<a href="https://t.zsxq.com/YBQFufi">你们有没有这种业务场景。flink从kafka里面取数据，每一条数据里面有mongdb表A的id,这时我会在map的时候采用flink的异步IO连接A表，然后查询出A表的字段1，再根据该字段1又需要异步IO去B表查询字段2，然后又根据字段2去C表查询字段3…..像这样的业务场景，如果多来几种逻辑，我应该用什么方案最好呢</a></p><p>189、<a href="https://t.zsxq.com/vnufYFY">今天本地运行flink程序，消费socket中的数据，连续只能消费两条，第三条flink就消费不了了</a></p><p>190、<a href="https://t.zsxq.com/me6EmM3">源数据经过过滤后分成了两条流，然后再分别提取事件时间和水印，做时间窗口，我测试时一条流没有数据，另一条的数据看日志到了窗口操作那边就没走下去，貌似窗口一直没有等到触发</a></p><p>191、<a href="https://t.zsxq.com/fubQrvj">有做flink cep的吗，有资料没？</a></p><p>192、<a href="https://t.zsxq.com/fEQVjAe">麻烦问一下 BucketingSink跨集群写，如果任务运行在hadoop A集群，从kafka读取数据处理后写到Hadoo B集群，即使把core-site.xml和hdfs-site.xml拷贝到代码resources下，路径使用hdfs://hadoopB/xxx，会提示ava.lang.RuntimeException: Error while creating FileSystem when initializing the state of the BucketingSink.，跨集群写这个问题  flink不支持吗？</a></p><p>193、<a href="https://t.zsxq.com/fIMVJ2J">想咨询下，如何对flink中的datastream和dataset进行数据采样</a></p><p>194、<a href="https://t.zsxq.com/7MVjyzz">一个flink作业经常发生oom，可能是什么原因导致的。  处理流程只有15+字段的解析，redis数据读取等操作，TM配置10g。  业务会在夜间刷数据，qps能打到2500左右~</a></p><p>195、<a href="https://t.zsxq.com/jA2NVnU">我看到flink 1.8的状态过期仅支持Processing Time，那么如果我使用的是Event time那么状态就不会过期吗</a></p><p>196、<a href="https://t.zsxq.com/BQv33Rb">请问我想每隔一小时统计一个属性从当天零点到当前时间的平均值，这样的时间窗该如何定义？</a></p><p>197、<a href="https://t.zsxq.com/nEAiIea">flink任务里面反序列化一个类，报ClassNotFoundException，可是包里面是有这个类的，有遇到这种情况吗？</a></p><p>198、<a href="https://t.zsxq.com/RnayrVn">在构造StreamGraph，类似PartitionTransformmation 这种类型的 transform，为什么要添加成一个虚拟节点，而不是一个实际的物理节点呢？</a></p><p>199、<a href="https://t.zsxq.com/A2fYNFA">flink消费kafka的数据写入到hdfs中，我采用了BucketingSink 这个sink将operator出来的数据写入到hdfs文件上，并通过在hive中建外部表来查询这个。但现在有个问题，处于in-progress的文件，hive是无法识别出来该文件中的数据，可我想能在hive中实时查询进来的数据，且不想产生很多的小文件，这个该如何处理呢</a></p><p>200、<a href="https://t.zsxq.com/7AurJU3">采用Flink单机集群模式一个jobmanager和两个taskmanager，机器是单机是24核，现在做个简单的功能从kafka的一个topic转满足条件的消息到另一个topic，topic的分区是30，我设置了程序默认并发为30，现在每秒消费2w多数据，不够快，请问可以怎么提高job的性能呢？</a></p><p>201、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metric 源码分析</a></p><p>202、<a href="https://t.zsxq.com/iAi6QRb">请问怎么理解官网的这段话？按官网的例子，难道只keyby之后才有keyed state，才能托管Flink存储状态么？source和map如果没有自定义operator state的话，状态是不会被保存的？</a></p><p>203、<a href="https://t.zsxq.com/3rbeuju">想用Flink做业务监控告警，并要能够支持动态添加CEP规则，问下可以直接使用Flink CEP还是siddhi CEP? 有没有相关的资料学习下？谢谢！</a></p><p>204、<a href="https://t.zsxq.com/eYJUbm6">请问一下，有没有关于水印，触发器的Java方面的demo啊</a></p><p>205、<a href="https://t.zsxq.com/QvbAqVB">老师，最近我们线上偶尔出现这种情况，就是40个并行度，其他有一个并行度CheckPoint一直失败，其他39个并行度都是毫秒级别就可以CheckPoint成功，这个怎么定位问题呢？还有个问题 CheckPoint的时间分为三部分 Checkpoint Duration (Async）和 Checkpoint Duration (Sync），还有个 end to end 减去同步和异步的时间，这三部分 分别指代哪块？如果发现这三者中的任意一个步骤时间长，该怎么去优化</a></p><p>206、<a href="https://t.zsxq.com/JaUZvbY">我这边有个场景很依赖消费出来的数据的顺序。在源头侧做了很多处理，将kafka修改成一个分区等等很多尝试，最后消费出来的还是乱序的。能不能在flink消费的时候做处理，来保证处理的数据的顺序。</a></p><p>207、<a href="https://t.zsxq.com/iQfaAeu">有一个类似于实时计算今天的pv，uv需求，采用source-&gt;keyby-&gt;window-&gt;trigger-&gt;process后，在process里采用ValueState计算uv  ,问题是 这个window内一天的所有数据是都会缓存到flink嘛？ 一天的数据量如果大点，这样实现就有问题了，  这个有其他的实现思路嘛？</a></p><p>208、<a href="https://t.zsxq.com/f6eAu3J">Flink 注解源码解析</a></p><p>209、<a href="https://t.zsxq.com/IuRJYne">如何监控 Flink 的 TaskManager 和 JobManager</a></p><p>210、<a href="https://t.zsxq.com/v7yfEIq">问下，在真实流计算过程中，并行度的设置，是与 kafka topic的partition数一样的吗？</a></p><p>211、<a href="https://t.zsxq.com/Zf2F6mM">Flink的日志 如果自己做平台封装在自己的界面中 请问job Manger 和 taskManger 还有用户自己的程序日志 怎么获取呢 有api还是自己需要利用flume 采集到ELK？</a></p><p>212、<a href="https://t.zsxq.com/72VzBEy">我想问下一般用Flink统计pv uv是怎么做的？uv存到redis? 每个uv都存到redis，会不会撑爆？</a></p><p>213、<a href="https://t.zsxq.com/zBmm2fq">Flink的Checkpoint 机制，在有多个source的时候，barrier n 的流将被暂时搁置，从其他流接收的记录将不会被处理，但是会放进一个输入缓存input buffer。如果被缓存的record大小超出了input buffer会怎么样？不可能一直缓存下去吧，如果其中某一条就一直没数据的话，整个过程岂不是卡死了？</a></p><p>214、<a href="https://t.zsxq.com/ZnIAi2j">公司想实时展示订单数据，汇总金额，并需要和前端交互，实时生成数据需要告诉前端，展示成折线图，这种场景的技术选型是如何呢？包括数据的存储，临时汇总数据的存储，何种形式告诉前端</a></p><p>215、<a href="https://t.zsxq.com/7EIeEyJ">请问下checkpoint中存储了哪些东西？</a></p><p>216、<a href="https://t.zsxq.com/euvFaYz">我这边有个需求是实时计算当前车辆与前车距离，用经纬度求距离。大概6000台车，10秒一条经纬度数据。gps流与自己join的地方在进行checkpoint的时候特别缓，每次要好几分钟。checkpoint 状态后端是rocksDB。有什么比较好的方案吗？自己实现一个类似last_value的函数取车辆最新的经纬再join，或者弄个10秒的滑动窗口输出车辆最新的经纬度再进行join，这样可行吗？</a></p><p>217、<a href="https://t.zsxq.com/YRnEUFe">flink在启动的时候能不能指定一个时间点从kafka里面恢复数据呢</a></p><p>218、<a href="https://t.zsxq.com/7QJEEyr">我们线上有个问题，很多业务都去读某个hive表，但是当这个hive表正在写数据的时候，偶尔出现过 读到表里数据为空的情况，这个问题怎么解决呢？</a></p><p>219、<a href="https://t.zsxq.com/yVnaYR7">使用 InfluxDB 和 Grafana 搭建监控 Flink 的平台</a></p><p>220、<a href="https://t.zsxq.com/uvFU7aY">flink消费kafka两个不同的topic,然后进行join操作，如果使用事件时间，两个topic都要设置watermaker吗，如果只设置了topic  A的watermaker,topic B的不设置会有什么影响吗？</a></p><p>221、<a href="https://t.zsxq.com/NNFYJMn">请教一个问题，我的Flink程序运行一段时间就会报这个错误，定位好多天都没有定位到。checkpoint 时间是5秒，20秒都不行。Caused by: java.io.IOException: Could not flush and close the file system output stream to hdfs://HDFSaaaa/flink/PointWideTable_OffTest_Test2/1eb66edcfccce6124c3b2d6ae402ec39/chk-355/1005127c-cee3-4099-8b61-aef819d72404 in order to obtain the stream state handle</a></p><p>222、<a href="https://t.zsxq.com/yvRNFEI">Flink的反压机制相比于Storm的反压机制有什么优势呢？问题2: Flink的某一个节点发生故障，是否会影响其他节点的正常工作？还是会通过Checkpoint容错机制吗把任务转移到其他节点去运行呢？</a></p><p>223、<a href="https://t.zsxq.com/ZJmiqZz">我在验证checkpoint的时候遇到给问题，不管是key state 还是operator state，默认和指定uid是可以的恢复state数据的，当指定uidHash时候无法恢复state数据，麻烦大家给解答一样。我操作state是实现了CheckpointedFunction接口，覆写snapshotState和initializeState，再这两个方法里操作的，然后让程序定时抛出异常，观察发现指定uidHash后snapshotState()方法里context.isRestored()为false，不太明白具体是什么原因</a></p><p>224、<a href="https://t.zsxq.com/mYV37qF">kafka 中的每条数据需要和 es 中的所有数据(动态增加)关联，关联之后会做一些额外的操作，这个有什么比较可行的方案？</a></p><p>225、<a href="https://t.zsxq.com/buFeyZr">flink消费kafka数据，设置1分钟checkpoint一次，假如第一次checkpoint完成以后，还没等到下一次checkpoint，程序就挂了，kafka offset还是第一次checkpoint记录的offset,那么下次重新启动程序，岂不是多消费数据了？那flink的 exactly one消费语义是怎么样的？</a></p><p>226、<a href="https://t.zsxq.com/Znyja62">程序频繁发生Heartbeat of TaskManager with id container_e36_1564049750010_5829_01_000024 timed out. 心跳超时，一天大概10次左右。是内存没给够吗？还是网络波动引起的</a></p><p>227、<a href="https://t.zsxq.com/AA6ma2Z">有没有性能优化方面的指导文章？</a></p><p>228、<a href="https://t.zsxq.com/a2N37a6">flink消费kafka是如何监控消费是否正常的，有啥好办法？</a></p><p>229、<a href="https://t.zsxq.com/m2FeeMf">我按照官方的wordcount案例写了一个例子，然后在main函数中起了一个线程，原本是准备定时去更新某些配置，准备测试一下是否可行，所以直接在线程函数中打印一条语句测试是否可行。现在测试的结果是不可行，貌似这个线程根本就没有执行，请问这是什么原因呢？   按照理解，JobClient中不是反射类执行main函数吗， 执行main函数的时候为什么没有执行这个线程的打印函数呢？</a></p><p>230、<a href="https://t.zsxq.com/EyFUb6m">请问我想保留最近多个完成的checkpoint数据，是通过设置 state.checkpoints.num-retained 吗？要怎么使用？</a></p><p>231、<a href="https://t.zsxq.com/rFeIAeA">有没有etl实时数仓相关案例么？比如二十张事实表流join</a></p><p>232、<a href="https://t.zsxq.com/n2RFmyN">为什么我扔到flink 的stream job，立刻就finished</a></p><p>233、<a href="https://t.zsxq.com/iqJiyvN">有没有在flink上机器学习算法的一些例子啊，除了官网提供的flink exampke里的和flink ml里已有的</a></p><p>234、<a href="https://t.zsxq.com/uB6aUzZ">如果我想扩展sql的关键词，比如添加一些数据支持，有什么思路，现在想的感觉都要改calcite（刚碰flink感觉难度太大了）</a></p><p>235、<a href="https://t.zsxq.com/2BEeu3Z">我想实现统计每5秒中每个类型的次数，这个现在不输出，问题出在哪儿啊</a></p><p>236、<a href="https://t.zsxq.com/VBA6IUR">我用flink往hbase里写数据，有那种直接批量写hfile的方式的demo没</a></p><p>237、<a href="https://t.zsxq.com/IieMFMB">请问怎么监控Kafka消费是否延迟，是否出现消息积压？你有demo吗？这种是用Springboot自己写一个监控，还是咋整啊？</a></p><p>238、<a href="https://t.zsxq.com/j2fM3BM">请问有计算pv uv的例子吗</a></p><p>239、<a href="https://t.zsxq.com/Rb2Z7uB">通过控制流动态修改window算子窗口类型和长度要怎么写</a></p><p>240、<a href="https://t.zsxq.com/UVbaQfM">flink的远程调试能出一版么？网上资料坑的多</a></p><p>241、<a href="https://t.zsxq.com/AYVjAuB">企业里，Flink开发，java用得多，还是scala用得多？</a></p><p>242、<a href="https://t.zsxq.com/j6QfMzf">flink的任务运行在yarn的环境上，在yarn的resourcemanager在进行主备切换时，所有的flink任务都失败了，而MR的任务可以正常运行。报错信息如下：AM is not registered for known application attempt: appattempt_1565306391442_89321_000001 or RM had restarted after AM registered . AM should re-register<br>     请问这是什么原因，该如何处理呢？</a></p><p>243、<a href="https://t.zsxq.com/IUVZjUv">请教一个分布式问题，比如在Flink的多个TaskManager上统计指标count，TM1有两条数据，TM2有一条数据，程序是怎么计算出来是3呢？原理是怎么样的</a></p><p>244、<a href="https://t.zsxq.com/7MFEQR3">现在公司部分sql查询oracle数据特别的慢，因为查询条件很多想问一下有什么方法，例如基于大数据组件可以加快查询速度的吗？</a></p><p>245、<a href="https://t.zsxq.com/Mfa6aQB">想咨询下有没有做过flink同步配置做自定义计算的系统？或者有没有什么好的建议？业务诉求是希望业务用户可以自助配置计算规则做流式计算</a></p><p>246、<a href="https://t.zsxq.com/z3bunyN">我这边有个实时同步数据的任务，白天运行的时候一直是正常的，一到凌晨2点多之后就没有数据sink进mysql。晚上会有一些离线任务和一些dataX任务同步数据到mysql。但是任务一切都是正常的，ck也很快20ms，数据也是正常消费。看了yarn上的日志，没有任何error。自定义的sink里面也设置了日志打印，但是log里没有。这种如何快速定位问题。</a></p><p>247、<a href="https://t.zsxq.com/Y3fe6Mn">有没有flink处理异常数据的案例资料</a></p><p>248、<a href="https://t.zsxq.com/I2Z7Ybm">flink中如何传递一个全局变量</a></p><p>249、<a href="https://t.zsxq.com/iIUZrju">台4核16G的Flink taskmanager配一个单独的Yarn需要一台啥样的服务器？其他功能都不需要就一个调度的东西？</a></p><p>250、<a href="https://t.zsxq.com/m6I2BEE">side-output 的分享</a></p><p>251、<a href="https://t.zsxq.com/amURFme">使用 InfluxDB + Grafana 监控flink能否配置告警。是不是prometheus更强大点？</a></p><p>252、<a href="https://t.zsxq.com/rZfyZvn">我们线上遇到一个问题，带状态的算子没有指定 uid，现在代码必须改，那个带状态的算子 不能正常恢复了，有解吗？通过某种方式能获取到系统之前自动生成的uid吗？</a></p><p>253、<a href="https://t.zsxq.com/uZz3Z7Q">tableEnv.registerDataStream(“Orders”, ds, “user, product, amount, proctime.proctime, rowtime.rowtime”);请问像这样把流注册成表的时候，这两个rowtime分别是什么意思</a></p><p>254、<a href="https://t.zsxq.com/yBiEyf2">我想问一下 flink on yarn session 模式下提交任务官网给的例子是 flink run -c xxx.MainClass job.jar 这里是怎么知道 yarn 上的哪个是 flink 的 appid 呢？</a></p><p>255、<a href="https://t.zsxq.com/yBeyfqv">Flink Netty Connector 这个有详细的使用例子？ 通过Netty建立的source能直接回复消息吗？还是只能被动接受消息？</a></p><p>256、<a href="https://t.zsxq.com/FIEia6M">请问flink sqlclient 提交的作业可以用于生产环境吗？</a></p><p>257、<a href="https://t.zsxq.com/ZBIaUvF">flink批处理写回mysql是否没法用tableEnv.sqlUpdate(“insert into t2 select * from t1”)？作为sink表的t2要如何注册？查跟jdbc相关的就两个TableSink，JDBCAppendTableSink用于BatchTableSink，JDBCUpertTablSink用于StreamTableSink。前者只接受insert into  values语法。所以我是先通过select from查询获取到DataSet再JDBCAppendTableSink.emitDataSet(ds)实现的，但这样达不到sql rule any目标</a></p><p>258、<a href="https://t.zsxq.com/aq3BIU7">请问在stream模式下，flink的计算结果在不落库的情况下，可以通过什么restful api获取计算结果吗</a></p><p>259、<a href="https://t.zsxq.com/NbYnAYF">现在我有场景，需要把一定的消息发送给kafka topic指定的partition，该怎么搞？</a></p><p>260、<a href="https://t.zsxq.com/YfmAMfm">请问我的job作业在idea上运行正常 提交到生产集群里提示Caused by: java.lang.NoSuchMethodError: org.apache.flink.api.java.ClosureCleaner.clean(Ljava/lang/Object;Z)V请问如何解决</a></p><p>261、<a href="https://t.zsxq.com/72n6MVb">遇到一个很奇怪的问题，在使用streamingSQL时，发现timestamp在datastream的时候还是正常的，在注册成表print出来的时候就少了八小时，大佬知道是什么原因么？</a></p><p>262、<a href="https://t.zsxq.com/RjQFmIQ">请问将flink的产生的一些记录日志异步到kafka中，需要如何配置，配置后必须要重启集群才会生效吗</a></p><p>263、<a href="https://t.zsxq.com/Q7u3vzR">星主你好，问下flink1.9对维表join的支持怎么样了？有文档吗</a></p><p>264、<a href="https://t.zsxq.com/aEEA66M">请问下 flink slq： SELECT city_name as city_name, count(1) as total, max(create_time) as create_time FROM * 。代码里面设置窗口为： retractStream.timeWindowAll(Time.minutes(5))一个global窗口，数据写入hdfs   结果数据重复 ，存在两条完全重复的数据如下 常州、2283、 1566230703）：请问这是为什么</a></p><p>265、<a href="https://t.zsxq.com/YNrfyrj">我用rocksdb存储checkpoint，线上运行一段时间发展checkpoint占用空间越来越大，我是直接存本地磁盘上的，怎么样能让它自动清理呢？</a></p><p>266、<a href="https://t.zsxq.com/aAaqFYn">flink应该在哪个用户下启动呢，是root的还是在其他的用户呢</a></p><p>267、<a href="https://t.zsxq.com/2nUBIAI">link可以读取lzo的文件吗</a></p><p>268、<a href="https://t.zsxq.com/beIY7mY">怎么快速从es里面便利数据？我们公司现在所有的数据都存在Es里面的;我发现每次从里面scan数据的时候特别慢;你那有没有什么好的办法？</a></p><p>269、<a href="https://t.zsxq.com/fYnYrR7">如果想让数据按照其中一个假如f0进行分区，然后每一个分区做处理的时候并行度都是1怎么设置呢</a></p><p>270、<a href="https://t.zsxq.com/nQFYrBm">近在写算子的过程中,使用scala语言写flink比较快,而且在process算子中实现ontime方式时,可以使用scala中的listbuff来输出一个top3的记录;那么到了java中,只能用ArrayList将flink中的ListState使用get()方法取出之后放在ArrayList吗?</a></p><p>271、<a href="https://t.zsxq.com/eyRRv7q">请问老师能否出一些1.9版本维表join的例子 包括async和维表缓存？</a></p><p>272、<a href="https://t.zsxq.com/aMRzjMb">flink kaka source设置为从组内消费，有个问题是第一次启动任务，我发现kafka中的历史数据不会被消费，而是从当前的数据开始消费，而第二次启动的时候才会从组的offset开始消费，有什么办法可以让第一次启动任务的时候可以消费kafka中的历史数据吗</a></p><p>273、<a href="https://t.zsxq.com/3ZjiEMv">1.使用flink定时处理离线数据，有时间戳字段，如何求出每分钟的最大值，类似于流处理窗口那样，2如果想自己实现批流统一，有什么好的合并方向吗？比如想让流处理使用批处理的一个算子。</a></p><p>274、<a href="https://t.zsxq.com/AIYnEQN">flink怎么实现流式数据批量对待？流的数据是自定义的source，读取的redis多个Hash表，需要控制批次的概念</a></p><p>275、<a href="https://t.zsxq.com/yJuFEYb">有人说不推荐在一个task中开多个线程，这个你怎么看？</a></p><p>276、<a href="https://t.zsxq.com/3f6YBmu">想做一个运行在hbase+es架构上的sql查询方案，flink sql能做吗，或者有没有其他的解决方案或者思路？</a></p><p>277、<a href="https://t.zsxq.com/jIAqVnm">正在紧急做第一个用到Flink的项目，咨询一下，Flink 1.8.1写入ES7就是用自带的Sink吗？有没有例子分享一下，我搜到的都是写ES6的。这种要求我知道不适合提，主要是急，自己试几下没成功。T T</a></p><p>278、<a href="https://t.zsxq.com/2fAiuzf">手动停止任务后，已经保存了最近一次保存点，任务重新启动后，如何使用上一次检查点？</a></p><p>279、<a href="https://t.zsxq.com/BIiImQN">批处理使用流环境（为了使用窗口），那如何确定批处理结束，就是我的任务可以知道批文件读取完事，并且处理完数据后关闭任务，如果不能，那批处理如何实现窗口功能</a></p><p>280、<a href="https://t.zsxq.com/Mjyzj66">如果限制只能在window 内进行去重，数据量还比较大，有什么好的方法吗？</a></p><p>281、<a href="https://t.zsxq.com/yv7Ujme">端到端exactly once有没有出文章</a></p><p>282、<a href="https://t.zsxq.com/IqNZFey">流怎么动态加？，流怎么动态删除？，参数怎么动态修改 （广播</a></p><p>283、<a href="https://t.zsxq.com/r7AqvBq">自定义的source数据源实现了有批次的概念，然后Flink将这个一个批次流注册为多个表join操作，有办法知道这个sql什么时候计算完成了？</a></p><p>284、<a href="https://t.zsxq.com/rvJiyf6">编译 Flink 报错，群主遇到过没，什么原因</a></p><p>285、[我现在是flink on yarn用zookeeper做HA现在在zk里查看检查点信息，为什么里面的文件是ip，而不是路径呢？我该如何拿到那个路径。</p><pre><code>- 排除rest api 方式获取，因为任务关了restapi就没了-排除history server，有点不好用](https://t.zsxq.com/nufIaey)</code></pre><p>286、<a href="https://t.zsxq.com/Fy3RfE6">在使用streamfilesink消费kafka之后进行hdfs写入的时候，当直接关闭flink程序的时候，下次再启动程序消费写入hdfs的时候，文件又是从part-0-0开始，这样就跟原来写入的冲突了，该文件就一直处于ingress状态。</a></p><p>287、<a href="https://t.zsxq.com/myNF2zj">现在有一个实时数据分析的需求，数据量不大，但要求sink到mysql，因为是实时更新的，我现在能想到的处理方法就是每次插入一条数据的时候，先从mysql读数据，如果有这条，就执行update，没有的话就insert，但是这样的话每写一条数据就有两次交互了。想问一下老师有没有更好的办法，或者flink有没有内置的api可以执行这种不确定是更新还是插入的操作</a></p><p>288、<a href="https://t.zsxq.com/ZFiMzrF">Flink设置了checkpoint，job manage会定期删除check point数据，但是task manage不删除，这个是什么原因</a></p><p>289、<a href="https://t.zsxq.com/z3RzJUV">请教一下使用rocksdb作为statebackend ，在哪里可以监控rocksdb io 内存指标呢</a></p><p>290、<a href="https://t.zsxq.com/AUjE2ZR">状态的使用场景，以及用法能出个文章不，这块不太了解</a></p><p>291、<a href="https://t.zsxq.com/aaynii6">请问一下  Flink 1.9  SQL API中distinct count 是如何实现高效的流式去重的？</a></p><p>292、<a href="https://t.zsxq.com/mmEyVJA">在算子内如何获取当前算子并行度以及当前是第几个task</a></p><p>293、<a href="https://t.zsxq.com/fIqNF6y">有没有flink1.9结合hive的demo。kafka到hive</a></p><p>294、<a href="https://t.zsxq.com/ne6UZrB">能给讲讲apache calcite吗</a></p><p>295、<a href="https://t.zsxq.com/VbUVFMr">请问一下像这种窗口操作，怎么保证程序异常重启后保持数据的状态呢？</a></p><p>296、<a href="https://t.zsxq.com/EMZFyZz">请问一下，我在使用kafkasource的时候，把接过来的Jsonstr转化成自定义的一个类型，用的是gson. fromJson（jsonstr,classOf[Entity]）报图片上的错误了，不知道怎么解决，在不转直接打印的情况下是没问题的</a></p><p>297、<a href="https://t.zsxq.com/IEieI6a">DataStream读数据库的表，做多表join，能设置时间窗口么，一天去刷一次。流程序会一直拉数据，数据库扛不住了</a></p><p>298、<a href="https://t.zsxq.com/IemmiY7">请问一下flink支持多路径通配读取吗？例如路径：s3n://pekdc2-deeplink-01/Kinesis/firehose/2019/07/03/<em>/</em>  ，通配读取找不到路径。是否需要特殊设置</a></p><p>299、<a href="https://t.zsxq.com/QvZFUNN">flink yarn环境部署 但是把容器的url地址删除。就会跳转到的hadoop的首页。怎么屏蔽hadoop的yarn首页地址呢？要不暴露这个地址用户能看到所有任务很危险</a></p><p>300、<a href="https://t.zsxq.com/2JiubeM">flink sql怎么写一个流，每秒输出当前时间呢</a></p><p>301、<a href="https://t.zsxq.com/bQ33BmM">因为想通过sql弄一个数据流。哈哈 另外想问一个问题，我把全局设置为根据处理时间的时间窗口，那么我在processAllWindowFunction里面要怎么知道进来的每个元素的处理时间是多少呢？这个元素进入这个时间窗口的依据是什么</a></p><p>302、<a href="https://t.zsxq.com/rB6ybYF">如何实现一个设备上报的数据存储到同一个hdfs文件中？</a></p><p>303、<a href="https://t.zsxq.com/MVfeeiu">我自己写的kafka生产者测试，数据格式十分简单（key,i）key是一个固定的不变的字符串，i是自增的，flink consumer这边我开了checkpoint. 并且是exactly once，然后程序很简单，就是flink读取kafka的数据然后直接打印出来，我发现比如我看到打印到key，10的时候我直接关掉程序，然后重新启动程序，按理来说应当是从上次的offset继续消费，也就是key,11，但实际上我看到的可能是从key，9开始，然后依次递增，这是是不是说明是重复消费了，那exactly one需要怎么样去保障？</a></p><p>304、<a href="https://t.zsxq.com/meqzJme">假设有一个数据源在源源不断的产生数据，到Flink的反压来到source端的时候，由于Flink处理数据的速度跟不上数据源产生数据的速度，<br>     问题1: 这个时候在Flink的source端会怎么处理呢？是将处理不完的数据丢弃还是进行缓存呢？<br>     问题2: 如果是缓存，怎么进行缓存呢？</a></p><p>305、<a href="https://t.zsxq.com/2fEeMny">一个stream 在sink多个时，这多个sink是串行 还是并行的。</a></p><p>306、<a href="https://t.zsxq.com/NJY76uf">我想在流上做一个窗口，触发窗口的条件是固定的时间间隔或者数据量达到预切值，两个条件只要有一个满足就触发，除了重写trigger在，还有什么别的方法吗？</a></p><p>307、<a href="https://t.zsxq.com/A6UN7eE">使用rocksdb作为状态后端，对于使用sql方式对时间字段进行group by，以达到去窗口化，但是这样没办法对之前的数据清理，导致磁盘空间很大，对于这种非编码方式，有什么办法设置ttl，清理以前的数据吗</a></p><p>308、<a href="https://t.zsxq.com/a2fUnEM">请问什么时间窗为什么会有TimeWindow{start=362160000, end=362220000}<br>     和 TimeWindow{start=1568025300000, end=1568025360000}这两种形式，我都用的是一分钟的TumblingEventTimeWindows，为什么会出现不同的情况？</a></p><p>309、<a href="https://t.zsxq.com/Y3jqjuj">比如我统计一天的订单量。但是某个数据延迟一天才到达。比如2019.08.01这一天订单量应该是1000，但是有个100的单据迟到了，在2019.08.02才到达，那么导致2019.08.01这一天统计的是900.后面怎么纠正这个错误的结果呢</a></p><p>310、<a href="https://t.zsxq.com/zJaMNne">flink streaming 模式下只使用堆内内存么</a></p><p>311、<a href="https://t.zsxq.com/EmMrvVb">如果考虑到集群的迁移，状态能迁移吗</a></p><p>312、<a href="https://t.zsxq.com/6EUFeqr">我们现在有一个业务场景，数据上报的值是这样的格式（时间，累加值），我们需要这样的格式数据（时间，当前值）。当前值=累加值-前一个数据的累加值。flink如何做到呢，有考虑过state机制，但是服务宕机后，state就被清空了</a></p><p>313、<a href="https://t.zsxq.com/y7U7Mzf">Flink  On  k8s 与 Flink on  Yarn相比的优缺点是什么？那个更适合在生产环境中使用呢</a></p><p>314、<a href="https://t.zsxq.com/zVNbaYn">有没有datahub链接flink的 连接器呀</a></p><p>315、<a href="https://t.zsxq.com/FQRNJ2j">单点resourcemanager 挂了，对任务会产生什么影响呢</a></p><p>316、<a href="https://t.zsxq.com/rnemUN3">flink监控binlog,跟另一张维表做join后，sink到MySQL的最终表。对于最终表的增删改操作，需要定义不同的sink么？</a></p><p>317、<a href="https://t.zsxq.com/JaaQFqB">请问窗口是在什么时候合并的呢？例如：数据进入windowoperator的processElement，如果不是sessionwindow，是否会进行窗口合并呢？</a></p><p>318、<a href="https://t.zsxq.com/AqNFM33">Flink中一条流能参与多路计算，并多处输出吗？他们之前会不会相互影响？</a></p><p>319、<a href="https://t.zsxq.com/nUzbiYj">keyBy算子定义是将一个流拆分成不相交的分区，每个分区包含具有相同的key的元素。我不明白的地方是: keyBy怎么设置分区数，是给这个算子设置并行度吗？ 分区数和slot数量是什么关系？</a></p><p>320、<a href="https://t.zsxq.com/66URfQb">动态cep-pattern，能否详细说下？滴滴方案未公布，您贴出来的几张图片是基于1.7的。或者有什么想法也可以讲解下，谢谢了</a></p><p>321、<a href="https://t.zsxq.com/maEQ3NR">问题1：使用常驻型session ./bin/yarn-session.sh -n 10 -s 3 -d启动，这个时候分配的资源是yarn 队列里面的, flink提交任务 flink run xx.jar,  其余机器是怎样获取到flink需要运行时的环境的，因为我只在集群的一台机器上有flink 安装包。</a></p><p>322、<a href="https://t.zsxq.com/YjEYjQz">flink task manager中slot间的内存隔离，cpu隔离是怎么实现的？flink 设计slot的概念有什么意义，为什么不像spark executor那样，内部没有做隔离？</a></p><p>323、<a href="https://t.zsxq.com/nuzvVzZ">spark和kafka集成，direct模式，spark的一个分区对应kafka的一个主题的一个分区。那flink和kafka集成的时候，怎么消费kafka的数据，假设kafka某个主题5个partition</a></p><p>324、<a href="https://t.zsxq.com/27u3ZZf">./bin/flink run -m yarn-cluster 执行的flink job ，作业自己打印的日志通过yarn application的log查看不了，只有集群自身的日志，程序中logger.info打印日志存放在哪，还是我打包的方式问题，打日志用的是slf4j。</a></p><p>325、<a href="https://t.zsxq.com/miuzFY3">在物联网平台中，需要对每个key下的数据做越限判断，由于每个key的越限值是不同的，越限值配置在实时数据库中。<br>     若将越限值加载到state中，由于key的量很大（大概3亿左右），会导致state太大，可能造成内存溢出。若在处理数据时从实时数据库中读取越限值，由于网络IO开销，可能造成实时性下降。请问该如何处理？谢谢</a></p><p>326、<a href="https://t.zsxq.com/amURvZR">如果我一个flink程序有多个window操作，时间戳和watermark是不是每个window都需要分配，还有就是事件时间是不是一定要在数据源中就存在某个字段</a></p><p>327、<a href="https://t.zsxq.com/eqFuBYz">有没有flink1.9刚支持的用ddl链接kafka并写入hbase的资料，我们公司想把离线的数仓逐渐转成实时的，写sql对于我们来说上手更快一些，就想找一些这方面的资料学习一下。</a></p><p>328、<a href="https://t.zsxq.com/yVvR3V3">flink1.9 进行了数据类型的转化时发生了不匹配的问题，  目前使用的Type被弃用，推荐使用是datatypes 类型，但是之前使用的Type类型的方法 对应的schema typeinformation 目前跟datatypes的返回值不对应，请问下  该怎么去调整适配？</a></p><p>329、<a href="https://t.zsxq.com/6AIQnEi">link中处理数据其中一条出了异常都会导致整个job挂掉?有没有方法(除了异常捕获)让这条数据记录错误日志就行 下面的数据接着处理呢? 粗略看过一些容错处理，是关于程度挂了重启后从检查点拉取数据，但是如果这条数据本身就问提(特别生产上，这样就导致job直接挂了，影响有点大)，那应该怎么过滤掉这条问题数据呢(异常捕获是最后的方法</a></p><p>330、<a href="https://t.zsxq.com/RBmi2vB">我在一个做日报的统计中使用rabbitmq做数据源，为什么rabbitmq中的数据一直处于unacked状态，每分钟触发一次窗口计算，并驱逐计算过的元素，我在测试环境数据都能ack,但是一到生产环境就不行了，也没有报错，有可能是哪里出了问题啊</a></p><p>331、<a href="https://t.zsxq.com/fuNfuBi">我们目前数据流向是这样的，kafka source ，etl，redis sink 。这样chk 是否可以保证端到端语义呢？</a></p><p>332、<a href="https://t.zsxq.com/mIeMzvf">1.在通过 yarn-session 提交 flink job 的时候。flink-core, flink-clients, flink-scala, flink-streaming-scala, scala-library, flink-connector-kafka-0.10 那些应该写 provided scope，那些应该写 compile scope，才是正确、避免依赖冲突的姿势？<br>    2.flink-dist_2.11-1.8.0.jar 究竟包含了哪些依赖？（这个文件打包方式不同于 springboot，无法清楚看到有哪些 jar 依赖）</a></p><p>333、<a href="https://t.zsxq.com/AQzj6Qv">Flink 中使用 count window 会有这样的问题就是，最后有部分数据一直没有达到 count 的值，然后窗口就一直不触发，这里看到个思路，可以将 time window + count window 组合起来</a></p><p>334、<a href="https://t.zsxq.com/VvR3Bai">flink流处理时，注册一个流数据为Table后，该流的历史数据也会一直在Table里面么？为什么每次来新数据，历史处理过得数据会重新被执行？</a></p><p>335、<a href="https://t.zsxq.com/jMfyNZv">available是变化数据，除了最新的数据被插入数据库，之前处理过数据又重新执行了几次</a></p><p>336、<a href="https://t.zsxq.com/m6Yrv7Q">这里两天在研究flink的广播变量，发现一个问题，DataSet数据集中获取广播变量，获取的内存地址是一样的（一台机器维护一个广播数据集）。在DataStream中获取广播变量就成了一个task维护一个数据集。（可能是我使用方式有问题）  所以想请教下星主，DataStream中获取一个画面变量可以如DataSet中一台机器维护一个数据吗？</a></p><p>337、<a href="https://t.zsxq.com/nqzZrbq">Flink程序开启checkpoint 机制后，用yarn命令多次killed以后，ckeckpoint目录下有多个job id，再次开辟资源重新启动程序，程序如何找到上一次jobid目录下，而不是找到其他的jobid目录下？默认是最后一个还是需要制定特定的jobid？</a></p><p>338、<a href="https://t.zsxq.com/RNzfQ7e">发展昨天的数据重复插入问题，是把kafka里进来的数据流registerDataStream注册为Table做join时，打印表的长度发现，数据会一直往表里追加，怎样才能来一条处理一条，不往上追加呀</a></p><p>339、<a href="https://t.zsxq.com/AqRvNNj">flink1.9 sql 有没有类似分区表那样的处理方式呢？我们现在有一个业务是1个source，但是要分别计算5分钟，10分钟，15分钟的数据。</a></p><p>340、<a href="https://t.zsxq.com/q3feIuv">我刚弄了个服务器，在启动基础的命令时候发现task没有启动起来，导致web页是三个0，我看了log也没有报错信息，请问您知道可能是什么问题吗？</a></p><p>241、<a href="https://t.zsxq.com/EIiyjeU">我自定义了个 Sink extends RichSinkFunction，有了 field： private transient Object lock;<br>     这个 lock 我直接初始化  private transient Object lock = new Object(); 就不行，在 invoke 里 使用lock时空指针，如果lock在 自定义 Sink 的 构造器初始化也不行。但是在 open 方法里初始化就可以，为什么？能解释一下 执行原理吗？如果一个slot 运行着5个 sink实例，那么 这个sink对象会new 5个还是1个？</a></p><p>342、<a href="https://t.zsxq.com/aMNnIy3">请问Kafka的broker 个数怎么估算？</a></p><p>343、<a href="https://t.zsxq.com/BU7iqbi">flink on yarn如何远程调试</a></p><p>344、<a href="https://t.zsxq.com/F6U7YbY">目前有个需求：就是源数据是dataA、dataB、DataC通过kafka三个topic获取，然后进行合并。<br>     但是有有几个问题，目前不知道怎么解决：<br>     dataA=”id:10001,info:<strong><em>,date:2019-08-01 12:23:33,entry1:1,entryInfo1:</em></strong>“<br>     dataB=”id:10001,org:<strong><em>,entry:1”  dataC=”id:10001,location:</em></strong>“<br>     (1) 如何将三个流合并？ (1) 数据中dataA是有时间的，但是dataB和dataC中都没有时间戳，那么如何解决eventTime及迟到乱序的问题？帮忙看下，谢谢</a></p><p>345、<a href="https://t.zsxq.com/JmIqfaE">我flink从kafka读json数据，在反序列化后中文部分变成了一串问号，请问如何做才能使中文正常</a></p><p>346、<a href="https://t.zsxq.com/3BMZfAM">我有好几个Flink程序（独立jar），在线业务数据分析时都会用到同样的一批MySQL中的配置数据(5千多条)，现在的实现方法是每一个程序都是独立把这些配置数据装到内存中，便于快速使用，但现在感觉有些浪费资源和结构不够美观，请问这类情况有什么其他的解决方案吗？谢谢</a></p><p>347、<a href="https://t.zsxq.com/RFMjYZn">Flink  checkpoint  选 RocksDBStateBackend 还是 FsStatebackEnd ，我们目前是任务执行一段时间之后 任务就会被卡死。</a></p><p>348、<a href="https://t.zsxq.com/uVv7uJU">flink on k8s的高可用、扩缩容这块目前还有哪些问题？</a></p><p>349、<a href="https://t.zsxq.com/zFq3fqb">有个问题问一下，是这样的现在Kafka4个分区每秒钟生产4000多到5000条日志数据，但是在消费者FLINK这边接收我只开了4个solt接收，这边只是接收后做切分存储，现在出现了延迟现象，我不清楚是我这边处切分慢了还是Flink接收kafka的数据慢了？Flink UI界面显示这两个背压高</a></p><p>等等等，还有很多，复制粘贴的我手累啊 😂</p><p>另外里面还会及时分享 Flink 的一些最新的资料（包括数据、视频、PPT、优秀博客，持续更新，保证全网最全，因为我知道 Flink 目前的资料还不多）</p><p><a href="https://t.zsxq.com/AybAimM">关于自己对 Flink 学习的一些想法和建议</a></p><p><a href="https://t.zsxq.com/iaEiyB2">Flink 全网最全资料获取，持续更新，点击可以获取</a></p><p>再就是星球用户给我提的一点要求：不定期分享一些自己遇到的 Flink 项目的实战，生产项目遇到的问题，是如何解决的等经验之谈！</p><p>1、<a href="https://t.zsxq.com/Zz3ny3V">如何查看自己的 Job 执行计划并获取执行计划图</a></p><p>2、<a href="https://t.zsxq.com/AIAQrnq">当实时告警遇到 Kafka 千万数据量堆积该咋办？</a></p><p>3、<a href="https://t.zsxq.com/QnYjy7M">如何在流数据中比两个数据的大小？多种解决方法</a></p><p>4、<a href="https://t.zsxq.com/6Q3vN3b">kafka 系列文章</a></p><p>5、<a href="https://t.zsxq.com/iiYfMBe">Flink环境部署、应用配置及运行应用程序</a></p><p>6、<a href="https://t.zsxq.com/yfYrvFA">监控平台该有架构是长这样子的</a></p><p>7、<a href="https://t.zsxq.com/beu7Mvj">《大数据“重磅炸弹”——实时计算框架 Flink》专栏系列文章目录大纲</a></p><p>8、<a href="https://t.zsxq.com/UvrRNJM">《大数据“重磅炸弹”——实时计算框架 Flink》Chat 付费文章</a></p><p>9、<a href="https://t.zsxq.com/zjQvjeM">Apache Flink 是如何管理好内存的？</a></p><p>10、<a href="https://t.zsxq.com/eYNBaAa">Flink On K8s</a></p><p>11、<a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-core</a></p><p>12、<a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-datadog</a></p><p>13、<a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-dropwizard</a></p><p>14、<a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-graphite</a></p><p>15、<a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-influxdb</a></p><p>16、<a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-jmx</a></p><p>17、<a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-slf4j</a></p><p>18、<a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-statsd</a></p><p>19、<a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-prometheus</a></p><p>20、<a href="https://t.zsxq.com/f6eAu3J">Flink 注解源码解析</a></p><p>21、<a href="https://t.zsxq.com/yVnaYR7">使用 InfluxDB 和 Grafana 搭建监控 Flink 的平台</a></p><p>22、<a href="https://t.zsxq.com/UVfqfae">一文搞懂Flink内部的Exactly Once和At Least Once</a></p><p>23、<a href="https://t.zsxq.com/eM3ZRf2">一文让你彻底了解大数据实时计算框架 Flink</a></p><p>当然，除了更新 Flink 相关的东西外，我还会更新一些大数据相关的东西，因为我个人之前不是大数据开发，所以现在也要狂补些知识！总之，希望进来的童鞋们一起共同进步！</p><p>1、<a href="https://t.zsxq.com/7I6Iyrf">Java 核心知识点整理.pdf</a></p><p>2、<a href="https://t.zsxq.com/myJYZRF">假如我是面试官，我会问你这些问题</a></p><p>3、<a href="https://t.zsxq.com/iUZnamE">Kafka 系列文章和学习视频</a></p><p>4、<a href="https://t.zsxq.com/r7eIeyJ">重新定义 Flink 第二期 pdf</a></p><p>5、<a href="https://t.zsxq.com/ZjiYrVr">GitChat Flink 文章答疑记录</a></p><p>6、<a href="https://t.zsxq.com/QZVJyz7">Java 并发课程要掌握的知识点</a></p><p>7、<a href="https://t.zsxq.com/VVN7YB2">Lightweight Asynchronous Snapshots for Distributed Dataflows</a></p><p>8、<a href="https://t.zsxq.com/VVN7YB2">Apache Flink™- Stream and Batch Processing in a Single Engine</a></p><p>9、<a href="https://t.zsxq.com/NjAQFi2">Flink状态管理与容错机制</a></p><p>10、<a href="https://t.zsxq.com/MvfUvzN">Flink 流批一体的技术架构以及在阿里的实践</a></p><p>11、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>12、<a href="https://t.zsxq.com/MvfUvzN">Flink 流批一体的技术架构以及在阿里的实践</a></p><p>13、<a href="https://t.zsxq.com/N37mUzB">Stream Processing with Apache Flink pdf</a></p><p>14、<a href="https://t.zsxq.com/m6EAaQ3">Flink 结合机器学习算法的监控平台实践</a></p><p>15、<a href="https://t.zsxq.com/emMBaQN">《大数据重磅炸弹-实时计算Flink》预备篇——大数据实时计算介绍及其常用使用场景 pdf 和视频</a></p><p>16、<a href="https://t.zsxq.com/fqfuVRR">《大数据重磅炸弹-实时计算Flink》开篇词 pdf 和视频</a></p><p>17、<a href="https://t.zsxq.com/rVBQFI6">四本 Flink 书</a></p><p>18、<a href="https://t.zsxq.com/rVBQFI6">流处理系统 的相关 paper</a></p><p>19、<a href="https://t.zsxq.com/FyzvRne">Apache Flink 1.9 特性解读</a></p><p>20、<a href="https://t.zsxq.com/FyzvRne">打造基于Flink Table API的机器学习生态</a></p><p>21、<a href="https://t.zsxq.com/FyzvRne">基于Flink on Kubernetes的大数据平台</a></p><p>22、<a href="https://t.zsxq.com/FyzvRne">基于Apache Flink的高性能机器学习算法库</a></p><p>23、<a href="https://t.zsxq.com/FyzvRne">Apache Flink在快手的应用与实践</a></p><p>24、<a href="https://t.zsxq.com/FyzvRne">Apache Flink-1.9与Hive的兼容性</a></p><p>25、<a href="https://t.zsxq.com/FyzvRne">打造基于Flink Table API的机器学习生态</a></p><p>26、<a href="https://t.zsxq.com/rVBQFI6">流处理系统的相关 paper</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>美团点评基于 Flink 的实时数仓平台实践</title>
    <link href="http://www.54tianzhisheng.cn/2019/12/30/flink-meituan-real-time-warehouse/"/>
    <id>http://www.54tianzhisheng.cn/2019/12/30/flink-meituan-real-time-warehouse/</id>
    <published>2019-12-29T16:00:00.000Z</published>
    <updated>2020-02-15T05:24:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>数据仓库的建设是“数据智能”必不可少的一环，也是大规模数据应用中必然面临的挑战，而 Flink 实时数仓在数据链路中扮演着极为重要的角色。本文中，美团点评高级技术专家鲁昊为大家分享了美团点评基于 Apache Flink 的实时数仓平台实践。</p><a id="more"></a><p>本文授权转自社区公众号，<a href="https://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;mid=2247485571&amp;idx=1&amp;sn=fcce8640538e3e5bf12f61722f2e247a&amp;chksm=fd3b86c1ca4c0fd782fecc046c37e78d6a12851de89867c56b753577e9bad2646085f2989011&amp;scene=38#wechat_redirect">原文地址</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-033916.png" alt=""></p><p>目录：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-034000.png" alt=""></p><h2 id="一、美团点评实时计算演进"><a href="#一、美团点评实时计算演进" class="headerlink" title="一、美团点评实时计算演进"></a>一、美团点评实时计算演进</h2><h3 id="美团点评实时计算演进历程"><a href="#美团点评实时计算演进历程" class="headerlink" title="美团点评实时计算演进历程"></a>美团点评实时计算演进历程</h3><p>在 2016 年，美团点评就已经基于 Storm 实时计算引擎实现了初步的平台化。2017 年初，我们引入了 Spark Streaming 用于特定场景的支持，主要是在数据同步场景方面的尝试。在 2017 年底，美团点评实时计算平台引入了 Flink。相比于 Storm 和 Spark Streaming，Flink 在很多方面都具有优势。这个阶段我们进行了深度的平台化，主要关注点是安全、稳定和易用。从 19 年开始，我们致力于建设包括实时数仓、机器学习等特定场景的解决方案来为业务提供更好的支持。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-034138.png" alt=""></p><h3 id="实时计算平台"><a href="#实时计算平台" class="headerlink" title="实时计算平台"></a>实时计算平台</h3><p>目前，美团点评的实时计算平台日活跃作业数量为万级，高峰时作业处理的消息量达到每秒 1.5 亿条，而机器规模也已经达到了几千台，并且有几千位用户正在使用实时计算服务。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-034317.png" alt=""></p><h3 id="实时计算平台架构"><a href="#实时计算平台架构" class="headerlink" title="实时计算平台架构"></a>实时计算平台架构</h3><p>如下图所示的是美团点评实时计算平台的架构。</p><ul><li><p>最底层是收集层，这一层负责收集用户的实时数据，包括 Binlog、后端服务日志以及 IoT 数据，经过日志收集团队和 DB 收集团队的处理，数据将会被收集到 Kafka 中。这些数据不只是参与实时计算，也会参与离线计算。</p></li><li><p>收集层之上是存储层，这一层除了使用 Kafka 做消息通道之外，还会基于 HDFS 做状态数据存储以及基于 HBase 做维度数据的存储。</p></li><li><p>存储层之上是引擎层，包括 Storm 和 Flink。实时计算平台会在引擎层为用户提供一些框架的封装以及公共包和组件的支持。</p></li><li><p>在引擎层之上就是平台层了，平台层从数据、任务和资源三个视角去管理。</p></li><li><p>架构的最上层是应用层，包括了实时数仓、机器学习、数据同步以及事件驱动应用等。</p></li></ul><p>本次分享主要介绍实时数仓方面的建设情况。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-034831.png" alt=""></p><p>从功能角度来看，美团点评的实时计算平台主要包括作业和资源管理两个方面的功能。其中，作业部分包括作业配置、作业发布以及作业状态三个方面的功能。</p><ul><li><p>在作业配置方面，则包括作业设置、运行时设置以及拓扑结构设置；</p></li><li><p>在作业发布方面，则包括版本管理、编译/发布/回滚等；</p></li><li><p>作业状态则包括运行时状态、自定义指标和报警以及命令/运行时日志等。</p></li></ul><p>在资源管理方面，则为用户提供了多租户资源隔离以及资源交付和部署的能力。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-034952.png" alt=""></p><h3 id="业务数仓实践"><a href="#业务数仓实践" class="headerlink" title="业务数仓实践"></a>业务数仓实践</h3><ul><li>流量</li></ul><p>前面提到，现在的美团点评实时计算平台更多地会关注在安全、易用和稳定方面，而应用上很大的一个场景就是业务数仓。接下来会为大家分享几个业务数仓的例子。</p><p>第一个例子是流量，流量数仓是流量类业务的基础服务，从业务通道而言，会有不同通道的埋点和不同页面的埋点数据，通过日志收集通道会进行基础明细层的拆分，按照业务维度划分不同的业务通道，如美团通道、外卖通道等。</p><p>基于业务通道还会进行一次更加细粒度的拆分，比如曝光日志、猜你喜欢、推荐等。以上这些包括两种使用方式，一种是以流的方式提供下游其他业务方使用，另外一方面就是做一些流量方面的实时分析。</p><p>下图中右边是流量数仓的架构图，自下向上分为四层，分别是 SDK 层，包括了前端、小程序以及 APP 的埋点；其上是收集层，埋点日志落地到 Nginx，通过日志收集通道收到 Kafka 中。在计算层，流量团队基于 Storm 能力实现了上层的 SQL 封装，并实现了 SQL 动态更新的特性，在 SQL 变更时不必重启作业。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035047.png" alt=""></p><ul><li>广告实时效果</li></ul><p>这里再举一个基于流量数仓的例子-广告实时效果验证。下图中左侧是广告实时效果的对比图。广告的打点一般分为请求（PV）打点、SPV（Server PV）打点、CPV（Client PV）曝光打点和 CPV 点击打点，在所有打点中都会包含一个流量的 requestID 和命中的实验路径。根据 requestID 和命中的实验路径可以将所有的日志进行 join，得到一个 request 中需要的所有数据，然后将数据存入 Durid 中进行分析，支持实际 CTR、预估 CTR 等效果验证。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035155.png" alt=""></p><ul><li>即时配送</li></ul><p>这里列举的另外一个业务数仓实践的例子是即时配送。实时数据在即时配送的运营策略上发挥了重要作用。以送达时间预估为例，交付时间衡量的是骑手送餐的交付难度，整个履约时间分为了多个时间段，配送数仓会基于 Storm 做特征数据的清洗、提取，供算法团队进行训练并得到时间预估的结果。这个过程涉及到商家、骑手以及用户的多方参与，数据的特征会非常多，数据量也会非常大。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035241.png" alt=""></p><ul><li>总结</li></ul><p>业务实时数仓大致分为三类场景：流量类、业务类和特征类，这三种场景各有不同。</p><ul><li><p>在数据模型上，流量类是扁平化的宽表，业务数仓更多是基于范式的建模，特征数据是 KV 存储。</p></li><li><p>从数据来源区分，流量数仓的数据来源一般是日志数据；业务数仓的数据来源是业务 binlog 数据；特征数仓的数据来源则多种多样。</p></li><li><p>从数据量而言，流量和特征数仓都是海量数据，每天百亿级以上，而业务数仓的数据量一般每天百万到千万级。</p></li><li><p>从数据更新频率而言，流量数据极少更新，则业务和特征数据更新较多。流量数据一般关注时序和趋势，业务数据和特征数据关注状态变更。</p></li><li><p>在数据准确性上，流量数据要求较低，而业务数据和特征数据要求较高。</p></li><li><p>在模型调整频率上，业务数据调整频率较高，流量数据和特征数据调整频率较低。</p></li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035349.png" alt=""></p><h2 id="二、基于-Flink-的实时数仓平台"><a href="#二、基于-Flink-的实时数仓平台" class="headerlink" title="二、基于 Flink 的实时数仓平台"></a>二、基于 Flink 的实时数仓平台</h2><p>上面为大家介绍了实时数仓的业务场景，接下来为大家介绍实时数仓的演进过程和美团点评的实时数仓平台建设思路。</p><h3 id="传统数仓模型"><a href="#传统数仓模型" class="headerlink" title="传统数仓模型"></a>传统数仓模型</h3><p>为了更有效地组织和管理数据，数仓建设往往会进行数据分层，一般自下而上分为四层：ODS（操作数据层）、DWD（数据明细层）、DWS（汇总层）和应用层。即时查询主要通过 Presto、Hive 和 Spark 实现。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035440.png" alt=""></p><h3 id="实时数仓模型"><a href="#实时数仓模型" class="headerlink" title="实时数仓模型"></a>实时数仓模型</h3><p>实时数仓的分层方式一般也遵守传统数据仓库模型，也分为了 ODS 操作数据集、DWD 明细层和 DWS 汇总层以及应用层。但实时数仓模型的处理的方式却和传统数仓有所差别，如明细层和汇总层的数据一般会放在 Kafka 上，维度数据一般考虑到性能问题则会放在 HBase 或者 Tair 等 KV 存储上，即席查询则可以使用 Flink 完成。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035516.png" alt=""></p><h3 id="准实时数仓模型"><a href="#准实时数仓模型" class="headerlink" title="准实时数仓模型"></a>准实时数仓模型</h3><p>在以上两种数仓模型之外，我们发现业务方在实践过程中还有一种准实时数仓模型，其特点是不完全基于流去做，而是将明细层数据导入到 OLAP 存储中，基于 OLAP 的计算能力去做汇总并进行进一步的加工。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035550.png" alt=""></p><h3 id="实时数仓和传统数仓的对比"><a href="#实时数仓和传统数仓的对比" class="headerlink" title="实时数仓和传统数仓的对比"></a>实时数仓和传统数仓的对比</h3><p>实时数仓和传统数仓的对比主要可以从四个方面考虑：</p><ul><li><p>第一个是分层方式，离线数仓为了考虑到效率问题，一般会采取空间换时间的方式，层级划分会比较多；则实时数仓考虑到实时性问题，一般分层会比较少，另外也减少了中间流程出错的可能性。</p></li><li><p>第二个是事实数据存储方面，离线数仓会基于 HDFS，实时数仓则会基于消息队列（如 Kafka）。</p></li><li><p>第三个是维度数据存储，实时数仓会将数据放在 KV 存储上面。</p></li><li><p>第四个是数据加工过程，离线数仓一般以 Hive、Spark 等批处理为主，而实时数仓则是基于实时计算引擎如 Storm、Flink 等，以流处理为主。</p></li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035634.png" alt=""></p><h3 id="实时数仓建设方案对比"><a href="#实时数仓建设方案对比" class="headerlink" title="实时数仓建设方案对比"></a>实时数仓建设方案对比</h3><p>下图中对于实时数仓的两种建设方式，即准实时数仓和实时数仓两种方式进行了对比。它们的实现方式分别是基于 OLAP 引擎和流计算引擎，实时度则分别是分钟和秒级。</p><p>在调度开销方面，准实时数仓是批处理过程，因此仍然需要调度系统支持，虽然调度开销比离线数仓少一些，但是依然存在，而实时数仓却没有调度开销。</p><p>在业务灵活性方面，因为准实时数仓基于 OLAP 引擎实现，灵活性优于基于流计算的方式。</p><p>在对数据晚到的容忍度方面，因为准实时数仓可以基于一个周期内的数据进行全量计算，因此对于数据晚到的容忍度也是比较高的，而实时数仓使用的是增量计算，对于数据晚到的容忍度更低一些。</p><p>在扩展性方面，因为准实时数仓的计算和存储是一体的，因此相比于实时数仓，扩展性更弱一些。</p><p>在适用场景方面，准实时数仓主要用于有实时性要求但不太高、数据量不大以及多表关联复杂和业务变更频繁的场景，如交易类型的实时分析，实时数仓则更适用于实时性要求高、数据量大的场景，如实时特征、流量分发以及流量类型实时分析。</p><p>总结一下，基于 OLAP 引擎的建设方式是数据量不太大，业务流量不太高情况下为了提高时效性和开发效率的一个折中方案，从未来的发展趋势来看，基于流计算的实时数仓更具有发展前景。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035712.png" alt=""></p><h3 id="一站式解决方案"><a href="#一站式解决方案" class="headerlink" title="一站式解决方案"></a>一站式解决方案</h3><p>从业务实践过程中，我们看到了业务建设实时数仓的共同需求，包括发现不同业务的元数据是割裂的，业务开发也倾向于使用 SQL 方式同时开发离线数仓和实时数仓，需要更多的运维工具支持。因此我们规划了一站式解决方案，希望能够将整个流程贯通。</p><p>这里的一站式解决方案主要为用户提供了数据开发工作平台、元数据管理。同时我们考虑到业务从生产到应用过程中的问题，我们 OLAP 生产平台，从建模方式、生产任务管理和资源方面解决 OLAP 生产问题。左侧是我们已经具备数据安全体系、资源体系和数据治理，这些是离线数仓和实时数仓可以共用的。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035747.png" alt=""></p><h3 id="为何选择-Flink？"><a href="#为何选择-Flink？" class="headerlink" title="为何选择 Flink？"></a>为何选择 Flink？</h3><p>实时数仓平台建设之所以选择 Flink 是基于以下四个方面的考虑，这也是实时数仓方面关注的比较核心的问题。</p><ul><li><p>第一个是状态管理，实时数仓里面会进行很多的聚合计算，这些都需要对于状态进行访问和管理，Flink 在这方面比较成熟。</p></li><li><p>第二个是表义能力，Flink 提供极为丰富的多层次 API，包括 Stream API、Table API 以及 Flink SQL。</p></li><li><p>第三个是生态完善，实时数仓的用途广泛，用户对于多种存储有访问需求，Flink 对于这方面的支持也比较完善。</p></li></ul><p>最后一点就是 Flink 提供了流批统一的可能性。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-040023.png" alt=""></p><h3 id="实时数仓平台"><a href="#实时数仓平台" class="headerlink" title="实时数仓平台"></a>实时数仓平台</h3><ul><li>建设思路</li></ul><p>实时数仓平台的建设思路从外到内分为了四个层次，我们认为平台应该做的事情是为用户提供抽象的表达能力，分别是消息表达、数据表达、计算表达以及流和批统一。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-040153.png" alt=""></p><ul><li>实时数仓平台架构</li></ul><p>如下图所示的是美团点评的实时数仓平台架构，从下往上看，资源层和存储层复用了实时计算平台的能力，在引擎层则会基于 Flink Streaming 实现一些扩展能力，包括对 UDF 的集成和 Connector 的集成。再往上是基于 Flink SQL 独立出来的 SQL 层，主要负责解析、校验和优化。在这之上是平台层，包括开发工作台、元数据、UDF 平台以及 OLAP 平台。最上层则是平台所支持的实时数仓的应用，包括实时报表、实时 OLAP、实时 Dashboard 和实时特征等。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-040229.png" alt=""></p><ul><li>消息表达-数据接入</li></ul><p>在消息表达层面，因为 Binlog、埋点日志、后端日志以及 IoT 数据等的数据格式是不一致的，因此美团点评的实时数仓平台提供数据接入的流程，能够帮助大家把数据同步到 ODS 层。这里主要实现了两件事情，分别是统一消息协议和屏蔽处理细节。</p><p>如下图左侧是接入过程的一个例子，对于 Binlog 类型数据，实时数仓平台还为大家提供了分库分表的支持，能够将属于同一个业务的不同的分库分表数据根据业务规则收集到同一个 ODS 表中去。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-040310.png" alt=""></p><ul><li>计算表达-扩展 DDL</li></ul><p>美团点评实时数仓平台基于 Flink 扩展了 DDL，这部分工作的主要目的是建设元数据体系，打通内部的主流实时存储，包括 KV 数据、OLAP 数据等。由于开发工作台和元数据体系是打通的，因此很多数据的细节并不需要大家在 DDL 中明确地声明出来，只需要在声明中写上数据的名字，和运行时的一些设置，比如 MQ 从最新消费还是最旧消费或者从某个时间戳消费即可，其他的数据访问方式是一致的。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-040607.png" alt=""></p><ul><li>计算表达-UDF 平台</li></ul><p>对于 UDF 平台而言，需要从三个层面考虑：</p><p>首先是数据安全性。之前的数仓建设过程中，用户可以上传 Jar 包去直接引用 UDF，这样做是有危险性存在的，并且我们无法知道数据的流向。从数据安全的角度来考虑，平台会进行代码审计和血缘关系分析，对于历史风险组件或者存在问题的组件可以进行组件收敛。</p><p>第二个层面，在数据安全基础上我们还会关注 UDF 的运行质量，平台将会为用户提供模板、用例以及测试的管理，为用户屏蔽编译打包、Jar 包管理的过程，并且会在 UDF 模板中进行指标日志的埋点和异常处理。</p><p>第三个层面是 UDF 的复用能力，因为一个业务方开发的 UDF，其他业务方很可能也会使用，但是升级过程中可能会带来不兼容的问题，因此，平台为业务提供了项目管理、函数管理和版本管理的能力。</p><p>UDF 的应用其实非常广泛，UDF 平台并不是只支持实时数仓，也会同时支持离线数仓、机器学习以及查询服务等应用场景。下图中右侧展示的是 UDF 的使用案例，左图是 UDF 的开发流程，用户只需要关心注册流程，接下来的编译打包、测试以及上传等都由平台完成；右图是 UDF 的使用流程中，用户只需要声明 UDF，平台会进行解析校验、路径获取以及在作业提交的时候进行集成。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-040705.png" alt=""></p><ul><li>实时数仓平台-Web IDE</li></ul><p>最后介绍一下实时数仓平台的开发工作台，以 Web IDE 的形式集成了模型、作业以及 UDF 的管理，用户可以在 Web IDE 上以 SQL 方式开发。平台会对 SQL 做一些版本的管理，并且支持用户回退到已部署成功的版本上去。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-041116.png" alt=""></p><h2 id="三、未来发展与思考"><a href="#三、未来发展与思考" class="headerlink" title="三、未来发展与思考"></a>三、未来发展与思考</h2><h3 id="资源自动调优"><a href="#资源自动调优" class="headerlink" title="资源自动调优"></a>资源自动调优</h3><p>从整个实时计算角度来考虑，目前美团点评的实时计算平台的节点数已经达到了几千台，未来很可能会达到上万台，因此资源优化这件事情很快就会被提上日程。由于业务本身的流量存在高峰和低谷，对于一个实时任务来说，可能在高峰时需要很多资源，但是在低谷时并不需要那么多资源。</p><p>另外一方面，波峰本身也是会发生变化的，有可能随着业务的上涨使得原来分配的资源数量不够用。因此，资源自动调优有两个含义，一个是指能够适配作业的高峰流量上涨，自动适配 Max 值；另外一个含义是指使得作业能够在高峰过去之后自动适应流量减少，能够快速缩容。我们可以通过每个任务甚至是算子的历史运行情况，拟合得到算子、流量与资源的关系函数，在流量变化时同步调整资源量。</p><p>以上是资源优化的思路，除此之外还需要考虑当资源完成优化之后应该如何利用。为了保证可用性，实时和离线任务一般会分开部署，否则带宽、IO 都可能被离线计算打满导致实时任务延迟。而从资源使用率角度出发，则需要考虑实时和离线的混合部署，或者以流的方式来处理一些实时性要求并不是非常高的任务。这就要求更细粒度的资源隔离和更快的资源释放。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-041159.png" alt=""></p><h3 id="推动实时数仓建设方式升级"><a href="#推动实时数仓建设方式升级" class="headerlink" title="推动实时数仓建设方式升级"></a>推动实时数仓建设方式升级</h3><p>实时数仓的建设一般分为几个步骤：</p><ul><li><p>首先，业务提出需求，后续会进行设计建模、业务逻辑开发和底层技术实现。美团点评的实时数仓建设思路是将技术实现统一表达，让业务关注逻辑开发，而逻辑开发也可以基于配置化手段实现自动构建。</p></li><li><p>再上一层是可以根据业务需求实现智能建模，将设计建模过程实现自动化。</p></li></ul><p>目前，美团点评的实时数仓平台建设工作还集中在统一表达的层次，距离理想状态仍然有比较长的一段路要走。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-041237.png" alt=""></p><p>Flink Forward Asia 2019 PPT 下载链接给你们准备好啦！公众号(zhisheng)里面回复 ffa 即可下载，也可以扫描下面的二维码关注，回复 ffa 即可下载。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-150817.jpg" alt="微信公众号"></p><h2 id="更多-Flink-博客"><a href="#更多-Flink-博客" class="headerlink" title="更多 Flink 博客"></a>更多 Flink 博客</h2><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客。</p><p>本文的项目代码在 <a href="https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-connectors/flink-learning-connectors-rabbitmq">https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-connectors/flink-learning-connectors-rabbitmq</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、实战、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;数据仓库的建设是“数据智能”必不可少的一环，也是大规模数据应用中必然面临的挑战，而 Flink 实时数仓在数据链路中扮演着极为重要的角色。本文中，美团点评高级技术专家鲁昊为大家分享了美团点评基于 Apache Flink 的实时数仓平台实践。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>基于 Apache Flink 的监控告警系统</title>
    <link href="http://www.54tianzhisheng.cn/2019/12/23/flink-monitor-alert/"/>
    <id>http://www.54tianzhisheng.cn/2019/12/23/flink-monitor-alert/</id>
    <published>2019-12-22T16:00:00.000Z</published>
    <updated>2020-03-01T14:43:13.000Z</updated>
    
    <content type="html"><![CDATA[<p>本人在 Flink 社区钉钉群直播的视频</p><a id="more"></a><h3 id="监控告警"><a href="#监控告警" class="headerlink" title="监控告警"></a>监控告警</h3><iframe height=720 width=1150 src="//player.bilibili.com/player.html?aid=90890878&cid=155203148&page=1"> </iframe><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="hhttp://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本人在 Flink 社区钉钉群直播的视频&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
      <category term="监控告警" scheme="http://www.54tianzhisheng.cn/tags/%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>基于 Apache Flink 的大规模准实时数据分析平台</title>
    <link href="http://www.54tianzhisheng.cn/2019/12/10/flink-real-time-data-analysis-platform/"/>
    <id>http://www.54tianzhisheng.cn/2019/12/10/flink-real-time-data-analysis-platform/</id>
    <published>2019-12-09T16:00:00.000Z</published>
    <updated>2020-01-04T03:42:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文来自 Flink Forward Asia 2019 Lyft 公司的分享，作者是徐赢和高立，感谢！</p><a id="more"></a><p>授权转载自社区公众号：<a href="https://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;mid=2247485404&amp;idx=1&amp;sn=fc958616d6e3f3f3001f3e02bb784278&amp;chksm=fd3b899eca4c0088622f41d9a4a3183fbcb8b2f10cad82e34e64ddb1a0b453cad73f37bdd9a1&amp;scene=38#wechat_redirect">原文地址</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005544.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005601.png" alt=""></p><h2 id="一、Lyft-的流数据与场景"><a href="#一、Lyft-的流数据与场景" class="headerlink" title="一、Lyft 的流数据与场景"></a>一、Lyft 的流数据与场景</h2><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005641.png" alt=""></p><h3 id="关于-Lyft"><a href="#关于-Lyft" class="headerlink" title="关于 Lyft"></a>关于 Lyft</h3><p>Lyft 是位于北美的一个共享交通平台，和大家所熟知的 Uber 和国内的滴滴类似，Lyft 也为民众提供共享出行的服务。Lyft 的宗旨是提供世界最好的交通方案来改善人们的生活。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005718.png" alt=""></p><h3 id="Lyft-的流数据场景"><a href="#Lyft-的流数据场景" class="headerlink" title="Lyft 的流数据场景"></a>Lyft 的流数据场景</h3><p>Lyft 的流数据可以大致分为三类，秒级别、分钟级别和不高于 5 分钟级别。分钟级别流数据中，自适应定价系统、欺诈和异常检测系统是最常用的，此外还有 Lyft 最新研发的机器学习特征工程。不高于 5 分钟级别的场景则包括准实时数据交互查询相关的系统。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005743.png" alt=""></p><h3 id="Lyft-数据分析平台架构"><a href="#Lyft-数据分析平台架构" class="headerlink" title="Lyft 数据分析平台架构"></a>Lyft 数据分析平台架构</h3><p>如下图所示的是 Lyft 之前的数据分析平台架构。Lyft 的大部分流数据都是来自于事件，而事件产生的来源主要有两种，分别是手机 APP 和后端服务，比如乘客、司机、支付以及保险等服务都会产生各种各样的事件，而这些事件都需要实时响应。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005814.png" alt=""></p><p>在分析平台这部分，事件会流向 AWS 的 Kinesis 上面，这里的 Kinesis 与 Apache Kafka 非常类似，是一种 AWS 上专有的 PubSub 服务，而这些数据流都会量化成文件，这些文件则都会存储在 AWS 的 S3 上面，并且很多批处理任务都会弹出一些数据子集。在分析系统方面，Lyft 使用的是开源社区中比较活跃的 presto 查询引擎。Lyft 数据分析平台的用户主要有四种，即数据工程师、数据分析师以及机器学习专家和深度学习专家，他们往往都是通过分析引擎实现与数据的交互。</p><h3 id="既往平台的问题"><a href="#既往平台的问题" class="headerlink" title="既往平台的问题"></a>既往平台的问题</h3><p>Lyft 之所以要基于 Apache Flink 实现大规模准实时数据分析平台，是因为以往的平台存在一些问题。比如较高的延迟，导入数据无法满足准实时查询的要求；并且基于 Kinesis Client Library 的流式数据导入性能不足；导入数据存在太多小文件导致下游操作性能不足；数据 ETL 大多是高延迟多日多步的架构；此外，以往的平台对于嵌套数据提供的支持也不足。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005837.png" alt=""></p><h2 id="二、准实时数据分析平台和架构"><a href="#二、准实时数据分析平台和架构" class="headerlink" title="二、准实时数据分析平台和架构"></a>二、准实时数据分析平台和架构</h2><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005858.png" alt=""></p><h3 id="准实时平台架构"><a href="#准实时平台架构" class="headerlink" title="准实时平台架构"></a>准实时平台架构</h3><p>在新的准实时平台架构中，Lyft 采用 Flink 实现流数据持久化。Lyft 使用云端存储，而使用 Flink 直接向云端写一种叫做 Parquet 的数据格式，Parquet 是一种列数据存储格式，能够有效地支持交互式数据查询。Lyft 在 Parquet 原始数据上架构实时数仓，实时数仓的结构被存储在 Hive 的 Table 里面，Hive Table 的 metadata 存储在 Hive metastore 里面。</p><p>平台会对于原始数据做多级的非阻塞 ETL 加工，每一级都是非阻塞的(nonblocking)，主要是压缩和去重的操作，从而得到更高质量的数据。平台主要使用 Apache Airflow 对于 ETL 操作进行调度。所有的 Parquet 格式的原始数据都可以被 presto 查询，交互式查询的结果将能够以 BI 模型的方式显示给用户。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005915.png" alt=""></p><h3 id="平台设计"><a href="#平台设计" class="headerlink" title="平台设计"></a>平台设计</h3><p>Lyft 基于 Apache Flink 实现的大规模准实时数据分析平台具有几个特点：</p><ul><li><p>首先，平台借助 Flink 实现高速有效的流数据接入，使得云上集群规模缩减为原来的十分之一，因此大大降低了运维成本。</p></li><li><p>其次，Parquet 格式的数据支持交互式查询，当用户仅对于某几个列数据感兴趣时可以通过分区和选择列的方式过滤不必要的数据，从而提升查询的性能。</p></li><li><p>再次，基于 AWS 的云端存储，平台的数据无需特殊存储形式。</p></li><li><p>之后，多级 ETL 进程能够确保更好的性能和数据质量。</p></li><li><p>最后，还能够兼顾性能容错及可演进性。</p></li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005935.png" alt=""></p><h3 id="平台特征及应用"><a href="#平台特征及应用" class="headerlink" title="平台特征及应用"></a>平台特征及应用</h3><p>Lyft 准实时数据分析平台需要每天处理千亿级事件，能够做到数据延迟小于 5 分钟，而链路中使用的组件确保了数据完整性，同时基于 ETL 去冗余操作实现了数据单一性保证。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005952.png" alt=""></p><p>数据科学家和数据工程师在建模时会需要进行自发的交互式查询，此外，平台也会提供实时机器学习模型正确性预警，以及实时数据面板来监控供需市场健康状况。</p><h3 id="基于-Flink-的准实时数据导入"><a href="#基于-Flink-的准实时数据导入" class="headerlink" title="基于 Flink 的准实时数据导入"></a>基于 Flink 的准实时数据导入</h3><p>下图可以看到当事件到达 Kinesis 之后就会被存储成为 EventBatch。通过 Flink-Kinesis 连接器可以将事件提取出来并送到 FlatMap 和 Record Counter 上面，FlatMap 将事件打撒并送到下游的 Global Record Aggregator 和 Tagging Partitioning 上面，每当做 CheckPoint 时会关闭文件并做一个持久化操作，针对于 StreamingFileSink 的特征，平台设置了每三分钟做一次 CheckPoint 操作，这样可以保证当事件进入 Kinesis 连接器之后在三分钟之内就能够持久化。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010016.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010035.png" alt=""></p><p>以上的方式会造成太多数量的小文件问题，因为数据链路支持成千上万种文件，因此使用了 Subtasks 记录本地事件权重，并通过全局记录聚合器来计算事件全局权重并广播到下游去。而 Operator 接收到事件权重之后将会将事件分配给 Sink。</p><h3 id="ETL-多级压缩和去重"><a href="#ETL-多级压缩和去重" class="headerlink" title="ETL 多级压缩和去重"></a>ETL 多级压缩和去重</h3><p>上述的数据链路也会做 ETL 多级压缩和去重工作，主要是 Parquet 原始数据会经过每小时的智能压缩去重的 ETL 工作，产生更大的 Parquet File。同理，对于小时级别压缩去重不够的文件，每天还会再进行一次压缩去重。对于新产生的数据会有一个原子性的分区交换，也就是说当产生新的数据之后，ETL Job 会让 Hive metastore 里的表分区指向新的数据和分区。这里的过程使用了启发性算法来分析哪些事件必须要经过压缩和去重以及压缩去重的时间间隔级别。此外，为了满足隐私和合规的要求，一些 ETL 数据会被保存数以年计的时间。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010112.png" alt=""></p><h2 id="三、平台性能及容错深入分析"><a href="#三、平台性能及容错深入分析" class="headerlink" title="三、平台性能及容错深入分析"></a>三、平台性能及容错深入分析</h2><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010130.png" alt=""></p><h3 id="事件时间驱动的分区感测"><a href="#事件时间驱动的分区感测" class="headerlink" title="事件时间驱动的分区感测"></a>事件时间驱动的分区感测</h3><p>Flink 和 ETL 是通过事件时间驱动的分区感测实现同步的。S3 采用的是比较常见的分区格式，最后的分区是由时间戳决定的，时间戳则是基于 EventTime 的，这样的好处在于能够带来 Flink 和 ETL 共同的时间源，这样有助于同步操作。此外，基于事件时间能够使得一些回填操作和主操作实现类似的结果。Flink 处理完每个小时的事件后会向事件分区写入一个 Success 文件，这代表该小时的事件已经处理完毕，ETL 可以对于该小时的文件进行操作了。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010149.png" alt=""></p><p>Flink 本身的水印并不能直接用到 Lyft 的应用场景当中，主要是因为当 Flink 处理完时间戳并不意味着它已经被持久化到存储当中，此时就需要引入分区水印的概念，这样一来每个 Sink Source 就能够知道当前写入的分区，并且维护一个分区 ID，并且通过 Global State Aggregator 聚合每个分区的信息。每个 Subtasks 能够知道全局的信息，并将水印定义为分区时间戳中最小的一个。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010206.png" alt=""></p><p>ETL 主要有两个特点，分别是及时性和去重，而 ETL 的主要功能在于去重和压缩，最重要的是在非阻塞的情况下就进行去重。前面也提到 Smart ETL，所谓 Smart 就是智能感知，需要两个相应的信息来引导 Global State Aggregator，分别是分区完整性标识 SuccessFile，在每个分区还有几个相应的 States 统计信息能够告诉下游的 ETL 怎样去重和压缩以及操作的频率和范围。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010228.png" alt=""></p><h3 id="Schema-演进的挑战"><a href="#Schema-演进的挑战" class="headerlink" title="Schema 演进的挑战"></a>Schema 演进的挑战</h3><p>ETL 除了去重和压缩的挑战之外，还经常会遇到 Schema 的演化挑战。Schema 演化的挑战分为三个方面，即不同引擎的数据类型、嵌套结构的演变、数据类型演变对去重逻辑的影响。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010249.png" alt=""></p><h3 id="S3-深入分析"><a href="#S3-深入分析" class="headerlink" title="S3 深入分析"></a>S3 深入分析</h3><p>Lyft 的数据存储系统其实可以认为是数据湖，对于 S3 而言，Lyft 也有一些性能的优化考量。S3 本身内部也是有分区的，为了使其具有并行的读写性能，添加了 S3 的熵数前缀，在分区里面也增加了标记文件，这两种做法能够极大地降低 S3 的 IO 性能的影响。标识符对于能否触发 ETL 操作会产生影响，与此同时也是对于 presto 的集成，能够让 presto 决定什么情况下能够扫描多少个文件。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010306.png" alt=""></p><h3 id="Parquet-优化方案"><a href="#Parquet-优化方案" class="headerlink" title="Parquet 优化方案"></a>Parquet 优化方案</h3><p>Lyft 的准实时数据分析平台在 Parquet 方面做了很多优化，比如文件数据值大小范围统计信息、文件系统统计信息、基于主键数据值的排序加快 presto 的查询速度以及二级索引的生成。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010324.png" alt=""></p><h3 id="基于数据回填的平台容错机制"><a href="#基于数据回填的平台容错机制" class="headerlink" title="基于数据回填的平台容错机制"></a>基于数据回填的平台容错机制</h3><p>如下两个图所示的是 Lyft 准实时数据分析平台的基于数据回填的平台容错机制。对于 Flink 而言，因为平台的要求是达到准实时，而 Flink 的 Job 出现失效的时候可能会超过一定的时间，当 Job 重新开始之后就会形成两个数据流，主数据流总是从最新的数据开始往下执行，附加数据流则可以回溯到之前中断的位置进行执行直到中断结束的位置。这样的好处是既能保证主数据流的准实时特性，同时通过回填数据流保证数据的完整性。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010340.png" alt=""></p><p>对于 ETL 而言，基于数据回填的平台容错机制则表现在 Airflow 的幂等调度系统、原子压缩和 HMS 交换操作、分区自建自修复体系和 Schema 整合。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010404.png" alt=""></p><h2 id="四、总结与未来展望"><a href="#四、总结与未来展望" class="headerlink" title="四、总结与未来展望"></a>四、总结与未来展望</h2><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010423.png" alt=""></p><h3 id="体验与经验教训"><a href="#体验与经验教训" class="headerlink" title="体验与经验教训"></a>体验与经验教训</h3><p>利用 Flink 能够准实时注入 Parquet 数据，使得交互式查询体验为可能。同时，Flink 在 Lyft 中的应用很多地方也需要提高，虽然 Flink 在大多数情况的延时都能够得到保证，但是重启和部署的时候仍然可能造成分钟级别的延时，这会对于 SLO 产生一定影响。</p><p>此外，Lyft 目前做的一件事情就是改善部署系统使其能够支持 Kubernetes，并且使得其能够接近 0 宕机时间的效果。因为 Lyft 准实时数据分析平台在云端运行，因此在将数据上传到 S3 的时候会产生一些随机的网络情况，造成 Sink Subtasks 的停滞，进而造成整个 Flink Job 的停滞。而通过引入一些 Time Out 机制来检测 Sink Subtasks 的停滞，使得整个 Flink Job 能够顺利运行下去。</p><p>ETL 分区感应能够降低成本和延迟，成功文件则能够表示什么时候处理完成。此外，S3 文件布局对性能提升的影响还是非常大的，目前而言引入熵数还属于经验总结，后续 Lyft 也会对于这些进行总结分析并且公开。因为使用 Parquet 数据，因此对于 Schema 的兼容性要求就非常高，如果引入了不兼容事件则会使得下游的 ETL 瘫痪，因此 Lyft 已经做到的就是在数据链路上游对于 Schema 的兼容性进行检查，检测并拒绝用户提交不兼容的 Schema。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010455.png" alt=""></p><h3 id="未来展望"><a href="#未来展望" class="headerlink" title="未来展望"></a>未来展望</h3><p>Lyft 对于准实时数据分析平台也有一些设想。</p><ul><li><p>首先，Lyft 希望将 Flink 部署在 Kubernetes 集群环境下运行，使得 Kubernetes 能够管理这些 Flink Job，同时也能够充分利用 Kubernetes 集群的高可扩展性。</p></li><li><p>其次，Lyft 也希望实现通用的流数据导入框架，准实时数据分析平台不仅仅支持事件，也能够支持数据库以及服务日志等数据。</p></li><li><p>再次，Lyft 希望平台能够实现 ETL 智能压缩以及事件驱动 ETL，使得回填等事件能够自动触发相应的 ETL 过程，实现和以前的数据的合并，同时将延时数据导入来对于 ETL 过程进行更新。</p></li><li><p>最后，Lyft 还希望准实时数据分析平台能够实现存储过程的改进以及查询优化，借助 Parquet 的统计数据来改善 presto 的查询性能，借助表格管理相关的开源软件对存储管理进行性能改善，同时实现更多的功能。</p></li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010514.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010533.png" alt=""></p><p>Flink Forward Asia 2019 PPT 下载链接给你们准备好啦！公众号(zhisheng)里面回复 ffa 即可下载，也可以扫描下面的二维码关注，回复 ffa 即可下载。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-150817.jpg" alt="微信公众号"></p><h2 id="更多-Flink-博客"><a href="#更多-Flink-博客" class="headerlink" title="更多 Flink 博客"></a>更多 Flink 博客</h2><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客。</p><p>本文的项目代码在 <a href="https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-connectors/flink-learning-connectors-rabbitmq">https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-connectors/flink-learning-connectors-rabbitmq</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、实战、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文来自 Flink Forward Asia 2019 Lyft 公司的分享，作者是徐赢和高立，感谢！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Flink Forward Asia 2019 PPT 下载</title>
    <link href="http://www.54tianzhisheng.cn/2019/12/07/Flink_Forward_Asia_2019/"/>
    <id>http://www.54tianzhisheng.cn/2019/12/07/Flink_Forward_Asia_2019/</id>
    <published>2019-12-06T16:00:00.000Z</published>
    <updated>2019-12-08T02:43:29.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink Forward Asia 2019 在北京召开的，有主会场和几个分会场（企业实践、Apache Flink 核心技术、开源大数据生态、实时数仓、人工智能），内容涉及很多，可以查看下面的 PPT。</p><a id="more"></a><h3 id="主会场"><a href="#主会场" class="headerlink" title="主会场"></a>主会场</h3><p>1、《Stateful Functions: Building general-purpose Applications and Services on Apache Flink》</p><p>2、《Apache Flink Heading Towards A Unified Engine》</p><p>3、《Storage Reimagined for a Streaming World》 </p><p>4、《Lyft 基于 Apache Flink 的大规模准实时数据分析平台》</p><h3 id="企业实践"><a href="#企业实践" class="headerlink" title="企业实践"></a>企业实践</h3><p>1、《Apache Flink 在字节跳动的实践与优化》</p><p>2、《Apache Flink在快手实时多维分析场景的应用》</p><p>3、《bilibili 实时平台的架构与实践》</p><p>4、《Apache Flink 资源动态调整及其实践》</p><p>5、《Apache Flink在滴滴的应用与实践》</p><p>6、《Apache Flink 在网易的实践》</p><p>7、《Apache Flink 在中国农业银行的探索和实践》</p><p>8、《基于 Apache Flink 的爱奇艺实时计算平台建设实践》</p><p>9、《实时计算在贝壳的实践》</p><p>10、《基于 Apache Flink 构建 CEP（Complex Event Process）引擎的挑战和实践》</p><h3 id="Apache-Flink-核心技术"><a href="#Apache-Flink-核心技术" class="headerlink" title="Apache Flink 核心技术"></a>Apache Flink 核心技术</h3><p>1、《Pluggable Shuffle Service and Unaligned Checkpoint》</p><p>2、《漂移计算 – 跨 DC 跨数据源的高性能 SQL 引擎》</p><p>3、《New Source API – Make it Easy! 》</p><p>4、《Stateful Functions: Unlocking the next wave of applications with Stream Processing》</p><p>5、《Apache Flink新场景——OLAP引擎》</p><p>6、《New Feature and Improvements on State Backends in Flink 1.10》</p><p>7、《阿里巴巴在 Apache Flink 大规模持久化存储的实践之道》</p><p>8、《Using Apache Flink as a Unified Data Processing Platform》</p><p>9、《深入探索 Apache Flink SQL 流批统一的查询引擎与最佳实践》   </p><p>10、《Apache Flink 流批一体的资源管理与任务调度》</p><h3 id="开源大数据生态"><a href="#开源大数据生态" class="headerlink" title="开源大数据生态"></a>开源大数据生态</h3><p>1、《YuniKorn 对 Apache Flink on K8s 的调度优化》</p><p>2、《流处理基准测试》</p><p>3、《Apache Flink and the Apache Way》</p><p>4、《Delivering stream data reliably with Pravega》</p><p>5、《Deep dive into Pyflink &amp; integration with Zeppelin》</p><p>6、《Apache Flink 与 Apache Hive 的集成》</p><p>7、《趣头条基于 Apache Flink+ClickHouse 构建实时数据分析平台》</p><p>8、《基于 Apache Flink 的边缘流式计算》</p><p>9、《基于 Apache Pulsar 和 Apache Flink 进行批流一体的弹性数据处理》</p><p>10、《The integretion of Apache Flink SQL and Apache Calcite》</p><h3 id="实时数仓"><a href="#实时数仓" class="headerlink" title="实时数仓"></a>实时数仓</h3><p>1、《美团点评基于 Apache Flink 的实时数仓平台实践》</p><p>2、《小米流式平台架构演进与实践》</p><p>3、《Netflix：Evolving Keystone to an Open Collaborative Real-time ETL Platform》</p><p>4、《菜鸟供应链实时数据技术架构的演进》</p><p>5、《OPPO 基于 Apache Flink 的实时数仓实践》</p><h3 id="人工智能"><a href="#人工智能" class="headerlink" title="人工智能"></a>人工智能</h3><p>1、《Deep Learning On Apache Flink》</p><p>2、《在 Apache Flink 上使用 Analytics-Zoo 进行大数据分析与深度学习模型推理的架构与实践》</p><p>3、《携程实时智能检测平台实践》</p><p>4、《基于Apache Flink的机器学习算法平台实践与开源》</p><p>5、《Apache Flink AI生态系统工作》</p><h3 id="如何获取上面这些-PPT？"><a href="#如何获取上面这些-PPT？" class="headerlink" title="如何获取上面这些 PPT？"></a>如何获取上面这些 PPT？</h3><p>上面的这些 PPT 本人已经整理好了，你可以关注微信公众号：<strong>zhisheng</strong>，然后在里面回复关键字: ffa 即可获取已放出的 PPT。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-08-024104.jpg" alt=""></p><p>另外你也可以加我微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt="">  </p><h2 id="更多-Flink-的文章"><a href="#更多-Flink-的文章" class="headerlink" title="更多 Flink 的文章"></a>更多 Flink 的文章</h2><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink Forward Asia 2019 在北京召开的，有主会场和几个分会场（企业实践、Apache Flink 核心技术、开源大数据生态、实时数仓、人工智能），内容涉及很多，可以查看下面的 PPT。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>阿里巴巴 Flink 踩坑经验：如何大幅降低 HDFS 压力？</title>
    <link href="http://www.54tianzhisheng.cn/2019/11/30/flink-checkpoint-hdfs/"/>
    <id>http://www.54tianzhisheng.cn/2019/11/30/flink-checkpoint-hdfs/</id>
    <published>2019-11-29T16:00:00.000Z</published>
    <updated>2020-01-11T05:55:04.000Z</updated>
    
    <content type="html"><![CDATA[<p>众所周知，Flink 是当前最为广泛使用的计算引擎之一，它使用 Checkpoint 机制进行容错处理 [1]，Checkpoint 会将状态快照备份到分布式存储系统，供后续恢复使用。在 Alibaba 内部，我们使用的存储主要是 HDFS，当同一个集群的 Job 到达一定数量后，会对 HDFS 造成非常大的压力，本文将介绍一种大幅度降低 HDFS 压力的方法——小文件合并。</p><a id="more"></a><p>本文转自：<a href="">https://www.infoq.cn/article/OLlJNzQpTOHfyrgOG8xq</a></p><p>作者：邱从贤</p><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>不管使用 FsStateBackend、RocksDBStateBackend 还是 NiagaraStateBackend，Flink 在进行 Checkpoint 的时候，TM 会将状态快照写到分布式文件系统中，然后将文件句柄发给 JM，JM 完成全局 checkpoint 快照的存储，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-144832.jpg" alt=""></p><p>对于全量 Checkpoint 来说，TM 将每个 Checkpoint 内部的数据都写到同一个文件，而对于 RocksDBStateBackend/NiagaraStateBackend 的增量 Checkpoint [2] 来说，则会将每个 sst 文件写到一个分布式系统的文件内。当作业量很大，且作业的并发很大时，则会对底层 HDFS 形成非常大的压力：1）大量的 RPC 请求会影响 RPC 的响应时间（如下图所示）；2）大量文件对 NameNode 内存造成很大压力。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-144921.jpg" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-144902.jpg" alt=""></p><p>在 Flink 中曾经尝试使用 ByteStreamStateHandle 来解决小文件多的问题 [3]，将小于一定阈值的 state 直接发送到 JM，由 JM 统一写到分布式文件中，从而避免在 TM 端生成小文件。但是这个方案有一定的局限性，阈值设置太小，还会有很多小文件生成，阈值设置太大，则会导致 JM 内存消耗太多有 OOM 的风险。</p><h3 id="1-小文件合并方案"><a href="#1-小文件合并方案" class="headerlink" title="1 小文件合并方案"></a>1 小文件合并方案</h3><p>针对上面的问题我们提出一种解决方案——小文件合并。</p><p>在原来的实现中，每个 sst 文件会打开一个 CheckpointOutputStream，每个 CheckpointOutputStream 对应一个 FSDataOutputStream，将本地文件写往一个分布式文件，然后关闭 FSDataOutputStream，生成一个 StateHandle。如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-145048.jpg" alt=""></p><p>小文件合并则会重用打开的 FSDataOutputStream，直至文件大小达到预设的阈值为止，换句话说多个 sst 文件会重用同一个 DFS 上的文件，每个 sst 文件占用 DFS 文件中的一部分，最终多个 StateHandle 共用一个物理文件，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-145114.jpg" alt=""></p><p>在接下来的章节中我们会描述实现的细节，其中需要重点考虑的地方包括：</p><ul><li>并发 Checkpoint 的支持</li></ul><p>Flink 天生支持并发 Checkpoint，小文件合并方案则会将多个文件写往同一个分布式存储文件中，如果考虑不当，数据会写串或者损坏，因此我们需要有一种机制保证该方案的正确性，详细描述参考 2.1 节。</p><ul><li>防止误删文件</li></ul><p>我们使用引用计数来记录文件的使用情况，仅通过文件引用计数是否降为 0 进行判断删除，则可能误删文件，如何保证文件不会被错误删除，我们将会在 2.2 节进行阐述。</p><ul><li>降低空间放大</li></ul><p>使用小文件合并之后，只要文件中还有一个 statehandle 被使用，整个分布式文件就不能被删除，因此会占用更多的空间，我们在 2.3 节描述了解决该问题的详细方案。</p><ul><li>异常处理</li></ul><p>我们将在 2.4 节阐述如何处理异常情况，包括 JM 异常和 TM 异常的情况。</p><p>2.5 节中会详细描述在 Checkpoint 被取消或者失败后，如何取消 TM 端的 Snapshot，如果不取消 TM 端的 Snapshot，则会导致 TM 端实际运行的 Snapshot 比正常的多。</p><p>在第 3 节中阐述了小文件合并方案与现有方案的兼容性；第 4 节则会描述小文件合并方案的优势和不足；最后在第 5 节我们展示在生产环境下取得的效果。</p><h3 id="2-设计实现"><a href="#2-设计实现" class="headerlink" title="2 设计实现"></a>2 设计实现</h3><p>本节中我们会详细描述整个小文件合并的细节，以及其中的设计要点。</p><p>这里我们大致回忆一下 TM 端 Snapshot 的过程：</p><ul><li>TM 端 barrier 对齐</li><li>TM Snapshot 同步操作</li><li>TM Snapshot 异步操作</li></ul><p>其中上传 sst 文件到分布式存储系统在上面的第三步，同一个 Checkpoint 内的文件顺序上传，多个 Checkpoint 的文件上传可能同时进行。</p><h4 id="2-1-并发-Checkpoint-支持"><a href="#2-1-并发-Checkpoint-支持" class="headerlink" title="2.1 并发 Checkpoint 支持"></a>2.1 并发 Checkpoint 支持</h4><p>Flink 天生支持并发 Checkpoint，因此小文件合并方案也需要能够支持并发 Checkpoint，如果不同 Checkpoint 的 sst 文件同时写往一个分布式文件，则会导致文件内容损坏，后续无法从该文件进行 restore。</p><p>在 FLINK-11937[4] 的提案中，我们会将每个 Checkpoint 的 state 文件写到同一个 HDFS 文件，不同 Checkpoint 的 state 写到不同的 HDFS 文件 – 换句话说，HDFS 文件不跨 Checkpoint 共用，从而避免了多个客户端同时写入同一个文件的情况。</p><p>后续我们会继续推进跨 Checkpoint 共用文件的方案，当然在跨 Checkpoint 共用文件的方案中，并行的 Checkpoint 也会写往不同的 HDFS 文件。</p><h4 id="2-2-防止误删文件"><a href="#2-2-防止误删文件" class="headerlink" title="2.2 防止误删文件"></a>2.2 防止误删文件</h4><p>复用底层文件之后，我们使用引用计数追踪文件的使用情况，在文件引用数降为 0 的情况下删除文件。但是在某些情况下，文件引用数为 0 的时候，并不代表文件不会被继续使用，可能导致文件误删。下面我们会详细描述开启并发 Checkpoint 后可能导致文件误删的情况，以及解决方案。</p><p>以下图为例，maxConcurrentlyCheckpoint = 2</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-145326.jpg" alt=""></p><p>上图中共有 3 个 Checkpoint，其中 chk-1 已经完成，chk-2 和 chk-3 都基于 chk-1 进行，chk-2 在 chk-3 前完成，chk-3 在注册 4.sst 的时候发现，发现 4.sst 在 chk-2 中已经注册过，会重用 chk-2 中 4.sst 对应的 stateHandle，然后取消 chk-3 中的 4.sst 的注册，并且删除 stateHandle，在处理完 chk-3 中 4.sst 之后，该 stateHandle 对应的分布式文件的引用计数为 0，如果我们这个时候删除分布式文件，则会同时删除 5.sst 对应的内容，导致后续无法从 chk-3 恢复。</p><p>这里的问题是如何在 stateHandle 对应的分布式文件引用计数降为 0 的时候正确判断是否还会继续引用该文件，因此在整个 Checkpoint 完成处理之后再判断某个分布式文件能否删除，如果真个 Checkpoint 完成发现文件没有被引用，则可以安全删除，否则不进行删除。</p><h4 id="2-3-降低空间放大"><a href="#2-3-降低空间放大" class="headerlink" title="2.3 降低空间放大"></a>2.3 降低空间放大</h4><p>使用小文件合并方案后，每个 sst 文件对应分布式文件中的一个 segment，如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-145406.jpg" alt=""></p><p>文件仅能在所有 segment 都不再使用时进行删除，上图中有 4 个 segment，仅 segment-4 被使用，但是整个文件都不能删除，其中 segment[1-3] 的空间被浪费掉了，从实际生产环境中的数据可知，整体的空间放大率（实际占用的空间 / 真实有用的空间）在 1.3 - 1.6 之间。</p><p>为了解决空间放大的问题，在 TM 端起异步线程对放大率超过阈值的文件进行压缩。而且仅对已经关闭的文件进行压缩。</p><p>整个压缩的流程如下所示：</p><ul><li>计算每个文件的放大率</li><li>如果放大率较小则直接跳到步骤 7</li><li>如果文件 A 的放大率超过阈值，则生成一个对应的新文件 A‘（如果这个过程中创建文件失败，则由 TM 负责清理工作）</li><li>记录 A 与 A’ 的映射关系</li><li>在下一次 Checkpoint X 往 JM 发送落在文件 A 中的 StateHandle 时，则使用 A` 中的信息生成一个新的 StateHandle 发送给 JM</li><li>Checkpoint X 完成后，我们增加 A‘ 的引用计数，减少 A 的引用计数，在引用计数降为 0 后将文件 A 删除（如果 JM 增加了 A’ 的引用，然后出现异常，则会从上次成功的 Checkpoint 重新构建整个引用计数器）</li><li>文件压缩完成</li></ul><h4 id="2-4-异常情况处理"><a href="#2-4-异常情况处理" class="headerlink" title="2.4 异常情况处理"></a>2.4 异常情况处理</h4><p>在 Checkpoint 的过程中，主要有两种异常：JM 异常和 TM 异常，我们将分情况阐述。</p><h5 id="2-4-1-JM-异常"><a href="#2-4-1-JM-异常" class="headerlink" title="2.4.1 JM 异常"></a>2.4.1 JM 异常</h5><p>JM 端主要记录 StateHandle 以及文件的引用计数，引用计数相关数据不需要持久化到外存中，因此不需要特殊的处理，也不需要考虑 transaction 等相关操作，如果 JM 发送 failover，则可以直接从最近一次 complete Checkpoint 恢复，并重建引用计数即可。</p><h5 id="2-4-2-TM-异常"><a href="#2-4-2-TM-异常" class="headerlink" title="2.4.2 TM 异常"></a>2.4.2 TM 异常</h5><p>TM 异常可以分为两种：1）该文件在之前 Checkpoint 中已经汇报过给 JM；2）文件尚未汇报过给 JM，我们会分情况阐述。</p><p><strong>文件已经汇报过给 JM</strong></p><p>文件汇报过给 JM，因此在 JM 端有文件的引用计数，文件的删除由 JM 控制，当文件的引用计数变为 0 之后，JM 将删除该文件。</p><p><strong>文件尚未汇报给 JM</strong></p><p>该文件暂时尚未汇报过给 JM，该文件不再被使用，也不会被 JM 感知，成为孤儿文件。这种情况暂时有外围工具统一进行清理。</p><h4 id="2-5-取消-TM-端-snapshot"><a href="#2-5-取消-TM-端-snapshot" class="headerlink" title="2.5 取消 TM 端 snapshot"></a>2.5 取消 TM 端 snapshot</h4><p>像前面章节所说，我们需要在 Checkpoint 超时 / 失败时，取消 TM 端的 snapshot，而 Flink 则没有相应的通知机制，现在 FLINK-8871[5] 在追踪相应的优化，我们在内部增加了相关实现，当 Checkpoint 失败时会发送 RPC 数据给 TM，TM 端接受到相应的 RPC 消息后，会取消相应的 snapshot。</p><h3 id="3-兼容性"><a href="#3-兼容性" class="headerlink" title="3 兼容性"></a>3 兼容性</h3><p>小文件合并功能支持从之前的版本无缝迁移过来。从之前的 Checkpoint restore 的的步骤如下：</p><ul><li>每个 TM 分到自己需要 restore 的 state handle</li><li>TM 从远程下载 state handle 对应的数据</li><li>从本地进行恢复</li></ul><p>小文件合并主要影响的是第 2 步，从远程下载对应数据的时候对不同的 StateHandle 进行适配，因此不影响整体的兼容性。</p><h3 id="4-优势和不足"><a href="#4-优势和不足" class="headerlink" title="4 优势和不足"></a>4 优势和不足</h3><ul><li>优势：大幅度降低 HDFS 的压力：包括 RPC 压力以及 NameNode 内存的压力</li><li>不足：不支持 State 多线程上传的功能（State 上传暂时不是 Checkpoint 的瓶颈）</li></ul><h3 id="5-线上环境的结果"><a href="#5-线上环境的结果" class="headerlink" title="5 线上环境的结果"></a>5 线上环境的结果</h3><p>在该方案上线后，对 Namenode 的压力大幅降低，下面的截图来自线上生产集群，从数据来看，文件创建和关闭的 RPC 有明显下降，RPC 的响应时间也有大幅度降低，确保顺利度过双十一。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-145805.jpg" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-145821.jpg" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-145834.jpg" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-145848.jpg" alt=""></p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] <a href="https://ci.apache.org/projects/flink/flink-docs-stable/ops/state/checkpoints.html">https://ci.apache.org/projects/flink/flink-docs-stable/ops/state/checkpoints.html</a></p><p>[2] <a href="https://flink.apache.org/features/2018/01/30/incremental-checkpointing.html">https://flink.apache.org/features/2018/01/30/incremental-checkpointing.html</a></p><p>[3] <a href="https://www.slideshare.net/dataArtisans/stephan-ewen-experiences-running-flink-at-very-large-scale">https://www.slideshare.net/dataArtisans/stephan-ewen-experiences-running-flink-at-very-large-scale</a></p><p>[4] <a href="https://issues.apache.org/jira/browse/FLINK-11937">https://issues.apache.org/jira/browse/FLINK-11937</a></p><p>[5] <a href="https://issues.apache.org/jira/browse/FLINK-8871">https://issues.apache.org/jira/browse/FLINK-8871</a></p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;众所周知，Flink 是当前最为广泛使用的计算引擎之一，它使用 Checkpoint 机制进行容错处理 [1]，Checkpoint 会将状态快照备份到分布式存储系统，供后续恢复使用。在 Alibaba 内部，我们使用的存储主要是 HDFS，当同一个集群的 Job 到达一定数量后，会对 HDFS 造成非常大的压力，本文将介绍一种大幅度降低 HDFS 压力的方法——小文件合并。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>58 同城基于 Flink 的千亿级实时计算平台架构实践</title>
    <link href="http://www.54tianzhisheng.cn/2019/11/30/flink-in-58/"/>
    <id>http://www.54tianzhisheng.cn/2019/11/30/flink-in-58/</id>
    <published>2019-11-29T16:00:00.000Z</published>
    <updated>2020-01-11T06:10:29.000Z</updated>
    
    <content type="html"><![CDATA[<p>58 同城作为覆盖生活全领域的服务平台，业务覆盖招聘、房产、汽车、金融、二手及本地服务等各个方面。丰富的业务线和庞大的用户数每天产生海量用户数据需要实时化的计算分析，实时计算平台定位于为集团海量数据提供高效、稳定、分布式实时计算的基础服务。本文主要介绍 58 同城基于 Flink 打造的一站式实时计算平台 Wstream。</p><a id="more"></a><p>本文转自：<a href="https://mp.weixin.qq.com/s?__biz=MzI4NTA1MDEwNg==&amp;mid=2650784251&amp;idx=1&amp;sn=3f90f0eadad3b781200ec8b31d281dfd&amp;chksm=f3f9746ec48efd78b0e10fa9a3e9fe646ef385c9450762ed634194760b03a528b561dbcab321&amp;scene=27#wechat_redirect">dbaplus 社群公众号</a></p><p>作者：冯海涛 / 万石康，负责 58 同城实时计算平台建设。</p><h3 id="实时计算场景"><a href="#实时计算场景" class="headerlink" title="实时计算场景"></a>实时计算场景</h3><p>和很多互联网公司一样，实时计算在 58 拥有丰富的场景需求，主要包括以下几类：</p><ul><li>实时数据 ETL：实时消费 Kafka 数据进行清洗、转换、结构化处理用于下游计算处理。</li><li>实时数仓：实时化数据计算，仓库模型加工和存储。实时分析业务及用户各类指标，让运营更加实时化。</li><li>实时监控：对系统和用户行为进行实时检测和分析，如业务指标实时监控，运维线上稳定性监控，金融风控等。</li><li>实时分析：特征平台，用户画像，实时个性化推荐等。</li></ul><h3 id="平台演进"><a href="#平台演进" class="headerlink" title="平台演进"></a>平台演进</h3><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060416.jpg" alt=""></p><p>在实时计算平台建设过程中，主要是跟进开源社区发展以及实际业务需求，计算框架经历了 Storm 到 Spark Streaming 到 Flink 的发展，同时建设一站式实时计算平台，旨在提升用户实时计算需求开发上线管理监控效率，优化平台管理。</p><p>实时计算引擎前期基于 Storm 和 Spark Streaming 构建, 很多情况下并不能很好的满足业务需求，如商业部门基于 Spark Streaming 构建的特征平台希望将计算延迟由分钟级降低到秒级，提升用户体验，运维监控平台基于 Storm 分析公司全量 nginx 日志对线上业务进行监控，需要秒级甚至毫秒级别的延迟，Storm 的吞吐能力成为瓶颈。</p><p>同时随着实时需求不断增加，场景更加丰富，在追求任务高吞吐低延迟的基础上，对计算过程中间状态管理，灵活窗口支持，以及 exactly once 语义保障的诉求越来越多。Apache Flink 开源之后，支持高吞吐低延迟的架构设计以及高可用的稳定性，同时拥有实时计算场景一系列特性以及支持实时 Sql 模型，使我们决定采用 Flink 作为新一代实时计算平台的计算引擎。</p><h3 id="平台规模"><a href="#平台规模" class="headerlink" title="平台规模"></a>平台规模</h3><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060445.jpg" alt=""></p><p>实时计算平台当前主要基于 Storm/Spark Streaming/Flink，集群共计 500 多台机器，每天处理数据量 6000 亿 +，其中 Flink 经过近一年的建设，任务占比已经达到 50%。</p><h3 id="Flink-稳定性"><a href="#Flink-稳定性" class="headerlink" title="Flink 稳定性"></a>Flink 稳定性</h3><p>Flink 作为实时计算集群，可用性要求远高于离线计算集群。为保障集群可用性，平台主要采用任务隔离以及高可用集群架构保障稳定性。</p><h4 id="任务隔离"><a href="#任务隔离" class="headerlink" title="任务隔离"></a>任务隔离</h4><p>在应用层面主要基于业务线以及场景进行机器隔离，队列资源分配管理，避免集群抖动造成全局影响。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060523.jpg" alt=""></p><h4 id="集群架构"><a href="#集群架构" class="headerlink" title="集群架构"></a>集群架构</h4><p>Flink 集群采用了 ON YARN 模式独立部署，为减少集群维护工作量，底层 HDFS 利用公司统一 HDFS Federation 架构下建立独立的 namespace，减少 Flink 任务在 checkpoint 采用 hdfs/rocksdb 作为状态存储后端场景下由于 hdfs 抖动出现频繁异常失败。</p><p>在资源隔离层面，引入 Node Label 机制实现重要任务运行在独立机器，不同计算性质任务运行在合适的机器下，最大化机器资源的利用率。同时在 YARN 资源隔离基础上增加 Cgroup 进行物理 cpu 隔离，减少任务间抢占影响，保障任务运行稳定性。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060546.jpg" alt=""></p><h3 id="平台化管理"><a href="#平台化管理" class="headerlink" title="平台化管理"></a>平台化管理</h3><p>Wstream 是一套基于 Apache Flink 构建的一站式、高性能实时大数据处理平台。提供 SQL 化流式数据分析能力，大幅降低数据实时分析门槛，支持通过 DDL 实现 source/sink 以及维表，支持 UDF/UDAF/UDTF，为用户提供更强大的数据实时处理能力。支持多样式应用构建方式 FlinkJar/Stream SQL/Flink-Storm，以满足不同用户的开发需求，同时通过调试，监控，诊断，探查结果等辅助手段完善任务生命周期管理。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060608.jpg" alt=""></p><p>###<br>流式 sql 能力建设<br>Stream SQL 是平台为了打造 sql 化实时计算能力，减小实时计算开发门槛，基于开源的 Flink，对底层 sql 模块进行扩展实现以下功能：</p><ul><li>支持自定义 DDL 语法（包括源表, 输出表, 维表）</li><li>支持自定义 UDF/UDTF/UDAF 语法</li><li>实现了流与维表的 join, 双流 join</li></ul><p>在支持大数据开源组件的同时，也打通了公司主流的实时存储平台。同时为用户提供基于 Sql client 的 cli 方式以及在 Wstream 集成了对实时 sql 能力的支持，为用户提供在线开发调试 sql 任务的编辑器，同时支持代码高亮，智能提示，语法校验及运行时校验，尽可能避免用户提交到集群的任务出现异常。</p><p>另外也为用户提供了向导化配置方式，解决用户定义 table 需要了解复杂的参数设置，用户只需关心业务逻辑处理，像开发离线 Hive 一样使用 sql 开发实时任务。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060642.jpg" alt=""></p><h3 id="Storm-任务迁移-Flink"><a href="#Storm-任务迁移-Flink" class="headerlink" title="Storm 任务迁移 Flink"></a>Storm 任务迁移 Flink</h3><p>在完善 Flink 平台建设的同时，我们也启动 Storm 任务迁移 Flink 计划，旨在提升实时计算平台整体效率，减少机器成本和运维成本。Flink-Storm 作为官方提供 Flink 兼容 Storm 程序为我们实现无缝迁移提供了可行性，但是作为 beta 版本，在实际使用过程中存在很多无法满足现实场景的情况，因此我们进行了大量改进，主要包括实现 Storm 任务 on yarn ，迁移之后任务 at least once 语义保障，兼容 Storm 的 tick tuple 机制等等。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060703.jpg" alt=""></p><p>通过对 Fink-Storm 的优化，在无需用户修改代码的基础上，我们已经顺利完成多个 Storm 版本集群任务迁移和集群下线，在保障实时性及吞吐量的基础上可以节约计算资源 40% 以上，同时借助 yarn 统一管理实时计算平台无需维护多套 Storm 集群，整体提升了平台资源利用率，减轻平台运维工作量。</p><h3 id="任务诊断"><a href="#任务诊断" class="headerlink" title="任务诊断"></a>任务诊断</h3><h4 id="指标监控"><a href="#指标监控" class="headerlink" title="指标监控"></a>指标监控</h4><p>Flink webUI 提供了大量的运行时信息供用户了解任务当前运行状况，但是存在无法获取历史 metrics 的问题导致用户无法了解任务历史运行状态，因此我们采用了 Flink 原生支持的 Prometheus 进行实时指标采集和存储。</p><p>Prometheus 是一个开源的监控和报警系统，通过 pushgateway 的方式实时上报 metrics，Prometheus 集群采用 Fedration 部署模式，meta 节点定时抓取所有子节点指标进行汇总，方便统一数据源提供给 Grafana 进行可视化以及告警配置。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060730.jpg" alt=""></p><h4 id="任务延迟"><a href="#任务延迟" class="headerlink" title="任务延迟"></a>任务延迟</h4><p>吞吐能力和延迟作为衡量实时任务性能最重要的指标，我们经常需要通过这两个指标来调整任务并发度和资源配置。Flink Metrics 提供 latencyTrackingInterval 参数启用任务延迟跟踪，打开会显著影响集群和任务性能，官方高度建议只在 debug 下使用。</p><p>在实践场景下，Flink 任务数据源基本都是 Kafka，因此我们采用 topic 消费堆积作为衡量任务延迟的指标，监控模块实时通过 Flink rest 获取任务正在消费 topic 的 offset，同时通过 Kafka JMX 获取对应 topic 的 logsize，采用 logsize– offset 作为 topic 的堆积。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060754.jpg" alt=""></p><h4 id="日志检索"><a href="#日志检索" class="headerlink" title="日志检索"></a>日志检索</h4><p>Flink 作为分布式计算引擎，所有任务会由 YARN 统一调度到任意的计算节点，因此任务的运行日志会分布在不同的机器，用户定位日志困难。我们通过调整 log4j 日志框架默认机制，按天切分任务日志，定期清理过期日志，避免异常任务频繁写满磁盘导致计算节点不可用的情况，同时在所有计算节点部署 agent 实时采集日志，汇聚写入 Kafka，通过日志分发平台实时将数据分发到 ES，方便用户进行日志检索和定位问题。</p><h3 id="Flink-优化"><a href="#Flink-优化" class="headerlink" title="Flink 优化"></a>Flink 优化</h3><p>在实际使用过程中，我们也针对业务场景进行了一些优化和扩展，主要包括：</p><p>1）Storm 任务需要 Storm 引擎提供 ack 机制保障消息传递 at least once 语义，迁移到 Flink 无法使用 ack 机制，我们通过定制 KafakSpout 实现 checkpoint 相关接口，通过 Flink checkpoint 机制实现消息传递不丢失。另外 Flink-Storm 默认只能支持 standalone 的提交方式，我们通过实现 yarn client 相关接口增加了 storm on yarn 的支持。</p><p>2）Flink 1.6 推荐的是一个 TaskManager 对应一个 slot 的使用方式，在申请资源的时候根据最大并发度申请对应数量的 TaskManger，这样导致的问题就是在任务设置 task slots 之后需要申请的资源大于实际资源。</p><p>我们通过在 ResoureManager 请求资源管理器 SlotManager 的时候增加 TaskManagerSlot 相关信息，用于维护申请到的待分配 TaskManager 和 slot，之后对于 SlotRequests 请求不是直接申请 TaskManager，而是先从 SlotManager 申请是否有足够 slot，没有才会启动新的 TaskManger, 这样就实现了申请资源等于实际消耗资源，避免任务在资源足够的情况下无法启动。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060824.jpg" alt=""></p><p>3）Kafak Connector 改造，增加自动换行支持，另外针对 08source 无法设置 client.id，通过将 client.id 生成机制优化成更有标识意义的 id，便于 Kafka 层面管控。</p><p>4）Flink 提交任务无法支持第三方依赖 jar 包和配置文件供 TaskManager 使用，我们通过修改 flink 启动脚本，增加相关参数支持外部传输文件，之后在任务启动过程中通过将对应的 jar 包和文件加入 classpath，借助 yarn 的文件管理机制实现类似 spark 对应的使用方式，方便用户使用。</p><p>5）业务场景存在大量实时写入 hdfs 需求，Flink 自带 BucketingSink 默认只支持 string 和 avro 格式，我们在此基础上同时支持了 LZO 及 Parquet 格式写入，极大提升数据写入性能。</p><h3 id="后续规划"><a href="#后续规划" class="headerlink" title="后续规划"></a>后续规划</h3><p>实时计算平台当前正在进行 Storm 任务迁移 Flink 集群，目前已经基本完成，大幅提升了平台资源利用率和计算效率。后续将继续调研完善 Flink 相关能力，推动 Flink 在更多的实时场景下的应用，包括实时规则引擎，实时机器学习等。</p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;58 同城作为覆盖生活全领域的服务平台，业务覆盖招聘、房产、汽车、金融、二手及本地服务等各个方面。丰富的业务线和庞大的用户数每天产生海量用户数据需要实时化的计算分析，实时计算平台定位于为集团海量数据提供高效、稳定、分布式实时计算的基础服务。本文主要介绍 58 同城基于 Flink 打造的一站式实时计算平台 Wstream。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>基于 Flink 构建关联分析引擎的挑战和实践</title>
    <link href="http://www.54tianzhisheng.cn/2019/11/30/flink-aqniu/"/>
    <id>http://www.54tianzhisheng.cn/2019/11/30/flink-aqniu/</id>
    <published>2019-11-29T16:00:00.000Z</published>
    <updated>2020-01-11T05:53:42.000Z</updated>
    
    <content type="html"><![CDATA[<p>如何构建流式关联分析引擎？</p><a id="more"></a><blockquote><p>本文转载自奇安信官网，作者：奇安信集团高级研发总监韩鹏</p><p>原文地址：<a href="">https://www.aqniu.com/tools-tech/59894.html</a></p></blockquote><p>随着云计算、大数据等新一代IT技术在各行业的深入应用，政企机构IT规模和复杂程度不断提高，网络流量、日志等各类数据规模大幅提升。与此同时，网络攻防日益激烈，网络安全威胁逐渐凸显出来，这对于SOC/SIEM产品的性能提出了一个很大的挑战。因此，奇安信独立研发了国内首款流式分布式关联分析引擎Sabre，搭载于公司旗下态势感知与安全运营平台（下文简称NGSOC），从而大幅提升NGSOC的数据分析能力和网络安全检测能力。</p><p>本文将从技术研发的角度，全面阐述Sabre的由来。</p><h3 id="1-Sabre是什么？"><a href="#1-Sabre是什么？" class="headerlink" title="1.Sabre是什么？"></a>1.Sabre是什么？</h3><p>Sabre是奇安信研发的新一代流式分布式关联分析引擎，是CEP（Complex Event Processing，复杂事件处理）技术在大数据领域的一个具体实现。奇安信研发关联引擎已有数年历史，中间经历了三次主要的技术演进，在2015年之前，奇安信使用的是基于开源CEP软件Esper研发的关联引擎，由于一些架构和设计上的问题，整体性能不是非常理想，也不支持多机扩展；在2016-2017年，用C++开发了一个高性能引擎，代号Dolphin，可以在单机上实现很高的性能；在2018年，从技术上全面转向Flink框架，极大增强了系统的可扩展性，推出了Sabre引擎作为NGSOC的核心检测引擎。</p><p>Sabre应用于奇安信的态势感知与安全运营平台（NGSOC）产品中，NGSOC主要服务于中大型政企客户，目前已经成功应用于200+大型政企机构，在国内安全管理平台市场占有率第一，其中搭载的Sabre引擎提供了核心的安全检测能力。和很多互联网公司内部自建数据处理平台不同的是，Sabre更注重的是技术的工程化交付，因此在设计和实现上和一般基于Flink的业务系统相比会有较大差异。</p><h3 id="2-为什么要开发Sabre？"><a href="#2-为什么要开发Sabre？" class="headerlink" title="2.为什么要开发Sabre？"></a>2.为什么要开发Sabre？</h3><p>随着网络应用规模和复杂度的不断提高，网络中传输的数据量急剧上升，网络攻防对抗日趋激烈，企业内部新的安全问题开始显现，实时关联分析引擎，作为NGSOC检测体系中的核心组件，也遇到了越来越多的挑战：</p><p>(1) 性能优化问题。主要针对随着新型攻击的不断出现，关联分析规则规模不断上升导致的性能问题。传统开源关联引擎往往加载几十条规则即达到了性能瓶颈，而NGSOC的应用场景中，关联引擎需要支撑规模上千的关联规则。在有限的硬件资源条件下，如何避免系统整体性能随规则条数上升而发生线性下降，成为关联引擎的一个主要挑战。</p><p>(2) 规则的语义扩展问题。在网络安全事件井喷式发生的今天，安全需求迅速扩展。为了能够在有限时间内对特定语义的快速支持，关联引擎的整体架构必须异常灵活，才能适应未来安全分析场景的各种需求，而基于开源关联引擎实现的产品会在激烈的需求变化时遇到很多问题。</p><p>(3) 系统扩展性问题。主要指分布式环境下节点的扩展。随着企业网络流量和业务资产的不断扩容，NGSOC的系统处理能力必须能随企业业务规模的不断扩张而动态扩展。未来的分布式关联分析引擎需要支持数百节点的规模，以能够与现有的大数据平台无缝集成。</p><p>与Storm、Spark Streaming等流式计算框架相比，Flink具有编程接口丰富、自带多种Window算子、支持Exactly-Once、高性能分布式检查点、批流计算模式统一等优点。且Flink发展较为迅速，开源社区极为活跃，是目前最具发展潜力的流式计算框架，是未来实时计算执牛耳者。由于Flink为事件驱动的实时关联分析引擎在底层框架上提供了有力支持，因此奇安信的下一代关联分析引擎Sabre是基于Flink流式计算框架实现的。</p><p>在选择了Flink之后，发现Flink开源方案直接应用于安全检测领域，仍有很大的技术障碍。</p><p>和互联网企业内部使用的大型集群相比，NGSOC面向的企业级应用集群规模较小，硬件资源受限，且客户的定制需求较多，导致安全监测的规则要求更严格，引擎发布成本较高。但是，现有的Flink开源解决方案，或者需要根据业务需求进行改造，或者性能较差，均不能较好地解决上述问题。首先，原生Flink只提供了函数式编程模式，即需要直接编写复合特定业务需求的固定程序代码，由此导致开发测试周期较长，不便于动态更新规则，可复用性较弱，且不能从全局语义层面进行优化，性能较差。其次，Flink-CEP仅是一个受限的序列算子，在运行时需要将所有数据传输到CEP算子，然后在CEP算子中串行执行各个条件语句。这种汇集到单点的运行模式，较多的冗余数据需要执行条件匹配，产生了不必要的网络负载，而且降低了CPU利用率。再次，还存在一些非官方开源的轻量级CEP引擎，比如Flink-siddhi，功能简单，不是一个完整的解决方案。</p><p>面向企业级的网络安全监测引擎具有一些特定需求，当前解决方案对此支持较差。比如，现实情况，客户对算子实例和Taskmanager概念较为模糊，真正关心的运行状态的基本单位是规则。而Flink监控页面显示的是算子实例及Taskmanager进程整体内存的运行状态，而在网络安全监控的业务场景中，对运行状态和资源的监控均需要细化到规则层面。其次，在算子层面，Flink原生Window算子，没有较好的资源（CPU/内存）保护机制，且存在大量重复告警，不符合网络安全监测领域的业务需求。再次，Flink缺乏一些必要算子，例如不支持“不发生算子”。一个较为常见的应用场景，某条规则指定在较长时间内没收到某台服务器的系统日志，则认为此台服务器发生了异常，需要及时通知用户。</p><p>综上所述，现有解决方案应用于网络安全监测领域均会遇到问题，由此奇安信集团基于Flink构建了一种全新的CEP引擎。</p><h3 id="3-Sabre如何处理数据？"><a href="#3-Sabre如何处理数据？" class="headerlink" title="3.Sabre如何处理数据？"></a>3.Sabre如何处理数据？</h3><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2019-12-16-134007.jpg" alt=""></p><p>上图为NGSOC的数据处理架构图，展示了整个系统的数据流。自下而上，NGSOC的数据处理过程由四部分组成，其核心是由“流式分布式关联分析引擎Sabre”构成的数据处理层PROCESS，且Sabre运行的硬件环境是由多个节点组成的分布式集群。右侧的规则配置管理模块供专业的安全人员使用，可通过类Visio图的界面较为友好便捷地配置规则；规则管理模块具有添加、删除、编辑和查找规则的功能，并可批量启动/停用多个规则，规则管理模块会将处于启动状态的有效规则统一发送给Sabre引擎。<br>最上方的绿色部分为结果处理层RESULT，Sabre会将处理结果“告警”或“关联事件”发送给下级响应模块，实现响应联动、分析调查及追踪溯源等功能。最下方的蓝色部分为日志采集层COLLECT，主要有“网络流量日志采集器”、“设备及系统日志采集器”和“其他类型的日志采集器（比如：防火墙、入侵检测系统IDS、入侵防护系统IPS、高级威胁监测系统APT等等）”三大类。中间部分为日志解析层PARSE，网络流量日志和系统安全日志格式多种多样，须将上述两类原始日志数据格式化，而其他类型的日志（比如：威胁情报、漏洞、资产）本身即为格式化数据，最终所有格式化数据均需统一存储到高性能消息队列Kafka。</p><h3 id="4-Sabre的关键技术"><a href="#4-Sabre的关键技术" class="headerlink" title="4.Sabre的关键技术"></a>4.Sabre的关键技术</h3><p>(1) 系统架构</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2019-12-16-134108.jpg" alt=""></p><p>上图为Sabre系统整体架构图。Sabre整体架构包含三大核心模块，中间是Sabre-server，左侧是配置端，右侧是Sabre运行端。核心数据流存在两条主线，红线表示规则的提交、编译、发布和运行流程。绿线表示状态监控的生成、收集、统计和展示流程。如图所示，此架构与Hive极为相似，是一种通用的大数据OLAP系统架构。下面详细介绍三大核心模块和两大核心数据流。</p><p>首先，通过规则配置端创建规则，采用性能保护配置端修改性能保护策略，然后将任务所属的规则文件和性能保护策略文件一并推送到Sabre-server提供的REST接口，该接口会调用文件解析及优化方法构建规则有向无环图。接着执行词法语法分析方法，将规则有向无环图中各个节点的EPL转换为与其对应的AST（Abstract Syntax Tree，抽象语法树），再将AST翻译为任务java代码。最后调用maven命令打包java代码为任务jar包，并将任务jar包及基础运行库一并提交到Flink-on-YARN集群。</p><p>Flink有多种运行模式（例如 standalone Flink cluster、Flink cluster on YARN、Flink job on YARN等），Sabre采用了“Flink job on YARN”模式，在奇安信NGSOC应用的特定场景下，采用YARN可统一维护硬件资源，并且使用 Flink job on YARN 可与Hadoop平台进行无缝对接，以此实现了很好的任务间资源隔离。</p><p>在Sabre任务执行过程中，Kafka数据源向引擎提供原始事件。引擎处理结果分为回注事件和告警事件两类。告警事件会直接输出到目的Kafka，供下级应用消费。回注事件表示一条规则的处理结果可直接回注到下级规则，作为下级规则的数据源事件，由此可实现规则的相互引用。</p><p>绿线流程表示任务执行过程中会定时输出节点的运行监控消息到Sabre-server的监控消息缓存器，然后监控消息统计器再汇总各个规则实例的运行监控消息，统计为整条规则的运行监控状态，最后通过Sabre-server提供的REST接口推送给规则监控端。</p><p>(2) 功能设计</p><p>算子的设计和实现是构建CEP的重要组成部分。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2019-12-16-134140.jpg" alt=""></p><p>上图展示了Flink和Sabre算子的比较关系。包含三列：Flink原生算子、Sabre算子、两者之间的比较结果（相同、实现、优化、新增）。Sabre共有13种完全自研的核心算子，其中Datasource、CustomKafkaSink和CustomDatabase按照 Flink接口要求做了具体实现，Filter、Key、Join和Aggregation按照Flink原有算子的语义做了重新实现，CustomWindow和Sequence在Flink原有算子语义的基础上做了优化实现。</p><p>由于Flink原有FilterFunction算子只能简单返回布尔值，以致输出结果的控制能力较差，而重新实现的Filter算子可同时执行多种业务逻辑，将一个“原始事件”输出一个或多个“处理事件”。Sabre还实现了一种针对窗口的全局触发器Trigger，Trigger能够将多个子计算性算子组合为复杂表达式，并实现了具有GroupBy/Distinct功能的Key算子以适配此Trigger算子。众所周知，Join和Aggregation的时间范围由Window限定，而Flink原有Window算子不适合网络安全监测需求，为此Sabre设计了一种“自定义Window算子”，且重新实现了与“自定义Window算子”相匹配的Join和Aggregation算子。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2019-12-16-134216.jpg" alt=""></p><p>上图展示了Sabre算子间的关联关系。序列Sequence、聚合Aggregation、不发生NotOccur、流式机器学习StreamML和连接Join均属于Window执行时间包含的计算性算子。蓝色虚线表示引用动态数据，紫色虚线表示Filter无须经过Window可直连输出组件。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2019-12-16-134307.jpg" alt=""></p><p>如上图所示，为满足复杂场景需求，一种规则的输出可直接作为另一种规则的输入。通过这种规则拆分的方式，能分层构造较为复杂的“多级规则”。如：上面的“暴力探测”规则结果可以直接回注到下面的“登陆成功 ”规则，而无须额外的通信组件。</p><p>(3) 性能优化</p><p>因为采用了Flink作为底层运行组件，所以Sabre具有与Flink等同的执行性能。并且，针对网络安全监测领域的特定需求，还做了如下的性能优化工作：</p><p>1）全局组件（数据源、动态表）引用优化。由于Kafka类型的数据源topic有限，而规则数量可动态扩展，导致多个规则会有极大概率共用同一个数据源，根据EPL语义等价原则合并相同的数据源，进而可以减少数据输入总量及线程总数。</p><p>2）全新的匹配引擎。序列Sequence算子采用了新颖的流式状态机引擎，复用了状态机缓存的状态，提升了匹配速度。类似优化还包含大规模IP匹配引擎和大规模串匹配引擎。</p><p>3）表计算表达式优化。对于规则中引用的动态表，会根据表达式的具体特性构建其对应的最优计算数据结构，以避免扫描全表数据，进而确保了执行的时间复杂度为常量值。</p><p>4）自定义流式Window算子。采用“时间槽”技术实现了乱序纠正功能，并具有可以实时输出无重复、无遗漏告警的特性。</p><p>5）字段自动推导，优化事件结构。根据规则前后逻辑关系，推导出规则中标注使用的原始日志相关字段，无须输出所有字段，以此优化输出事件结构，减少输出事件大小。</p><p>6）数据分区自动推导，优化流拓扑。由于功能需要，Window往往会缓存大量数据，以致消耗较多内存。通过对全局窗口Hash优化，避免所有全局窗口都分配到同一个Taskmanager进程，由此提高了引擎整体内存的利用率。</p><p>(4) 机器学习</p><p>机器学习在网络异常检测上已经越来越重要，为适应实时检测的需求，Sabre没有使用Flink MachineLearning，而是引入了自研的流式机器学习算子StreamML。Flink MachineLearning是一种基于批模式DataSetApi实现的机器学习函数库，而StreamML是一种流式的机器学习算子，其目的是为了满足网络安全监测的特定需求。与阿里巴巴开源的Alink相比，StreamML允许机器学习算法工程师通过配置规则的方式即可快速验证算法模型，无需编写任何程序代码。并且，流式机器学习算子StreamML实现了“模型训练/更新”与“模型使用”统一的理念。其核心功能是通过算法、技术及模型实现数据训练及对新数据检测。该流式机器学习算子StreamML引入的输入有三类，分别是：事件流、检测对象和对象属性；输出也包含三类，分别是：事件、告警和预警。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2019-12-16-134339.jpg" alt=""></p><p>流式机器学习算子StreamML的组件栈包含三部分，从下往上依次为：机器学习方法、应用场景和产品业务。通过基本的机器学习算法（比如：统计学习算法、序列分析算法、聚类分析算法），流式机器学习算子StreamML可满足具体特定的安全监测应用场景（比如：行为特征异常检测、时间序列异常检测、群组聚类分析），进而为用户提供可理解的产品业务（比如：基线、用户及实体行为分析UEBA）。</p><p>行为特征异常检测：根据采集的样本数据（长时间）对统计分析对象建立行为基线，并以此基线为准，检测发现偏离正常行为模式的行为。例如：该用户通常从哪里发起连接？哪个运营商？哪个国家？哪个地区？这个用户行为异常在组织内是否为常见异常？</p><p>时间序列异常检测：根据某一个或多个统计属性，判断按时间顺序排列的数值序列是否异常，由此通过监测指标变化来发现安全事件。例如：监测某网站每小时的访问量以防止DDOS攻击；建模每个账号传输文件大小的平均值，检测出传输文件大小的平均值离群的账号。</p><p>群组聚类分析：对数据的特征属性间潜在相关性进行挖掘，将具有类似特征值的数据进行分组聚类。例如：该用户是否拥有任何特殊特征？可执行权限/特权用户？基于执行的操作命令和可访问的实体，来识别IT管理员、DBA和其它高权限用户。</p><h3 id="5-Sabre如何快速适配复杂的客户环境"><a href="#5-Sabre如何快速适配复杂的客户环境" class="headerlink" title="5.Sabre如何快速适配复杂的客户环境?"></a>5.Sabre如何快速适配复杂的客户环境?</h3><p>由于客户规模较大，项目种类较多，部署环境较为复杂，或者存在多种Yarn集群版本，或者Sabre需作为单一Flink应用发布到客户已部署的Flink集群。如何节省成本及提高实施效率，快速适配上述复杂的部署环境是个亟需解决的问题，为此Sabre的设计原则是仅采用Flink的分布式计算能力，业务代码尽可能减少对API层的依赖，以便于兼容多种Flink版本。如图所示，Deploy、Core、APIs、Libraries四层是大家熟知的Flink基本的组件栈。Sabre对API层的依赖降到了最低，只引用了DataStream、KeyedStream和SplitStream三种数据流API。函数依赖则包括DataStream的assignTimestamps、flatMap、union、keyBy、split、process、addSink等函数，KeyedStream最基础的process函数，以及SplitStream的select函数。由于依赖的Flink API较少，Sabre可以很容易适配到各个Flink版本，从而具有良好的Flink版本兼容性。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2019-12-16-134430.jpg" alt=""></p><h3 id="6-如何保障Sabre稳定运行？"><a href="#6-如何保障Sabre稳定运行？" class="headerlink" title="6.如何保障Sabre稳定运行？"></a>6.如何保障Sabre稳定运行？</h3><p>为减少引擎的维护成本，需要保障引擎在超限数据量的条件下亦然能够稳定运行，Sabre主要做了两个优化：流量控制和自我保护。</p><p>为了增强Sabre引擎的健壮性，避免因规则配置错误，导致生成大量无效告警，在输出端做了流量控制，以更好地保护下级应用。当下级抗压能力较弱时（例如数据库），整个系统会做输出降级。</p><p>另一个问题是，跑在JVM上的程序，经常会遇到由于长时间 Full GC导致OOM的错误，并且此时CPU占用率往往非常高，Flink同样存在上述问题。自我保护功能采用了同时兼顾“Window隶属规则的优先级”及“Window引用规则数量”两个条件的加权算法，以此根据全局规则语义实现自动推导Window优先级，并根据此优先级确定各个Window的自我保护顺序。实时监控CPU及内存占用，当超过一定阈值时，智能优化事件分布，以防出现CPU长期过高或内存使用率过大而导致的OOM问题。</p><p>目前，基于Flink构建的Sabre引擎还在继续开发新的功能，并会持续优化引擎性能。未来将总结凝练项目中的优秀实践，并及时回馈给Apache Flink社区。</p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如何构建流式关联分析引擎？&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《大数据实时计算引擎 Flink 实战与性能优化》目录大纲</title>
    <link href="http://www.54tianzhisheng.cn/2019/11/24/flink-in-action-directory/"/>
    <id>http://www.54tianzhisheng.cn/2019/11/24/flink-in-action-directory/</id>
    <published>2019-11-23T16:00:00.000Z</published>
    <updated>2019-11-24T07:29:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>基于 Flink 1.9 讲解的书籍目录大纲，含 Flink 入门、概念、原理、实战、性能调优、源码解析等内容。涉及 Flink Connector、Metrics、Library、DataStream API、Table API &amp; SQL 等内容的学习案例，还有 Flink 落地应用的大型项目案例分享。</p><a id="more"></a><p>书籍和专栏同时在进行，扫码下面专栏二维码可以订阅专栏，提前查看书籍内容。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="书籍目录大纲"><a href="#书籍目录大纲" class="headerlink" title="书籍目录大纲"></a>书籍目录大纲</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br></pre></td><td class="code"><pre><span class="line">1预备篇</span><br><span class="line"></span><br><span class="line">第一章——实时计算引擎</span><br><span class="line">    1.1你的公司是否需要引入实时计算引擎</span><br><span class="line">        1.1.1 实时计算需求</span><br><span class="line">        1.1.2 数据实时采集</span><br><span class="line">        1.1.3 数据实时计算</span><br><span class="line">        1.1.4 数据实时下发</span><br><span class="line">        1.1.5 实时计算场景</span><br><span class="line">        1.1.6 离线计算 vs 实时计算</span><br><span class="line">        1.1.7 实时计算面临的挑战</span><br><span class="line">        1.1.8 小结与反思</span><br><span class="line">    1.2彻底了解大数据实时计算框架 Flink</span><br><span class="line">        1.2.1 Flink 简介</span><br><span class="line">        1.2.2 Flink 整体架构</span><br><span class="line">        1.2.3 Flink 的多种方式部署</span><br><span class="line">        1.2.4 Flink 分布式运行流程</span><br><span class="line">        1.2.5 Flink API</span><br><span class="line">        1.2.6 Flink 程序与数据流结构</span><br><span class="line">        1.2.7 丰富的 Connector</span><br><span class="line">        1.2.8 事件时间&amp;处理时间语义</span><br><span class="line">        1.2.9 灵活的窗口机制</span><br><span class="line">        1.2.10 并行执行任务机制</span><br><span class="line">        1.2.11 状态存储和容错</span><br><span class="line">        1.2.12 自己的内存管理机制</span><br><span class="line">        1.2.13 多种扩展库</span><br><span class="line">        1.2.14 小结与反思</span><br><span class="line">    1.3大数据计算框架对比</span><br><span class="line">        1.3.1 Flink</span><br><span class="line">        1.3.2 Blink</span><br><span class="line">        1.3.3 Spark</span><br><span class="line">        1.3.4 Spark Streaming</span><br><span class="line">        1.3.5 Structured Streaming</span><br><span class="line">        1.3.6 Flink VS Spark</span><br><span class="line">        1.3.7 Storm</span><br><span class="line">        1.3.8 Flink VS Storm</span><br><span class="line">        1.3.9 全部对比结果</span><br><span class="line">        1.3.10 小结与反思</span><br><span class="line">    1.4总结</span><br><span class="line"></span><br><span class="line">2第二章——Flink 入门</span><br><span class="line">    2.1Flink 环境准备</span><br><span class="line">        2.1.1 JDK 安装与配置</span><br><span class="line">        2.1.2 Maven 安装与配置</span><br><span class="line">        2.1.3 IDE 安装与配置</span><br><span class="line">        2.1.4 MySQL 安装与配置</span><br><span class="line">        2.1.5 Kafka 安装与配置</span><br><span class="line">        2.1.6 ElasticSearch 安装与配置</span><br><span class="line">        2.1.7 小结与反思</span><br><span class="line">    2.2Flink 环境搭建</span><br><span class="line">        2.2.1 Flink 下载与安装</span><br><span class="line">        2.2.2 Flink 启动与运行</span><br><span class="line">        2.2.3 Flink 目录配置文件解读</span><br><span class="line">        2.2.4 Flink 源码下载</span><br><span class="line">        2.2.5 Flink 源码编译</span><br><span class="line">        2.2.6 将 Flink 源码导入到 IDE</span><br><span class="line">        2.2.7 小结与反思</span><br><span class="line">    2.3案例1：WordCount 应用程序</span><br><span class="line">        2.3.1 使用 Maven 创建项目</span><br><span class="line">        2.3.2 使用 IDEA 创建项目</span><br><span class="line">        2.3.3 流计算 WordCount 应用程序代码实现</span><br><span class="line">        2.3.4 运行流计算 WordCount 应用程序</span><br><span class="line">        2.3.5 流计算 WordCount 应用程序代码分析</span><br><span class="line">        2.3.6 小结与反思</span><br><span class="line">    2.4案例2：实时处理 Socket 数据</span><br><span class="line">        2.4.1 使用 IDEA 创建项目</span><br><span class="line">        2.4.2 实时处理 Socket 数据应用程序代码实现</span><br><span class="line">        2.4.3 运行实时处理 Socket 数据应用程序</span><br><span class="line">        2.4.4 实时处理 Socket 数据应用程序代码分析</span><br><span class="line">        2.4.5 Flink 中使用 Lambda 表达式</span><br><span class="line">        2.4.5 小结与反思</span><br><span class="line">    2.5总结</span><br><span class="line">    </span><br><span class="line">2基础篇</span><br><span class="line"></span><br><span class="line">3第三章——Flink 中的流计算处理</span><br><span class="line">    3.1Flink 多种时间语义对比</span><br><span class="line">        3.1.1 Processing Time</span><br><span class="line">        3.1.2 Event Time</span><br><span class="line">        3.1.3 Ingestion Time</span><br><span class="line">        3.1.4 三种 Time 的对比结果</span><br><span class="line">        3.1.5 使用场景分析</span><br><span class="line">        3.1.6 Time 策略设置</span><br><span class="line">        3.1.7 小结与反思</span><br><span class="line">    3.2Flink Window 基础概念与实现原理</span><br><span class="line">        3.2.1 Window 简介</span><br><span class="line">        3.2.2 Window 有什么作用？</span><br><span class="line">        3.2.3 Flink 自带的 Window</span><br><span class="line">        3.2.4 Time Window 的用法及源码分析</span><br><span class="line">        3.2.5 Count Window 的用法及源码分析</span><br><span class="line">        3.2.6 Session Window 的用法及源码分析</span><br><span class="line">        3.2.7 如何自定义 Window？</span><br><span class="line">        3.2.8 Window 源码分析</span><br><span class="line">        3.2.9 Window 组件之 WindowAssigner 的用法及源码分析</span><br><span class="line">        3.2.10 Window 组件之 Trigger 的用法及源码分析</span><br><span class="line">        3.2.11 Window 组件之 Evictor 的用法及源码分析</span><br><span class="line">        3.2.12 小结与反思</span><br><span class="line">    3.3必须熟悉的数据转换 Operator(算子)</span><br><span class="line">        3.3.1 DataStream Operator</span><br><span class="line">        3.3.2 DataSet Operator</span><br><span class="line">        3.3.3 流计算与批计算统一的思路</span><br><span class="line">        3.3.4 小结与反思</span><br><span class="line">    3.4使用 DataStream API 来处理数据</span><br><span class="line">        3.4.1 DataStream 的用法及分析</span><br><span class="line">        3.4.2 SingleOutputStreamOperator 的用法及分析</span><br><span class="line">        3.4.3 KeyedStream 的用法及分析</span><br><span class="line">        3.4.4 SplitStream 的用法及分析</span><br><span class="line">        3.4.5 WindowedStream 的用法及分析</span><br><span class="line">        3.4.6 AllWindowedStream 的用法及分析</span><br><span class="line">        3.4.7 ConnectedStreams 的用法及分析</span><br><span class="line">        3.4.8 BroadcastStream 的用法及分析</span><br><span class="line">        3.4.9 BroadcastConnectedStream 的用法及分析</span><br><span class="line">        3.4.10 QueryableStateStream 的用法及分析</span><br><span class="line">        3.4.11 小结与反思</span><br><span class="line">    3.5Watermark 的用法和结合 Window 处理延迟数据</span><br><span class="line">        3.5.1 Watermark 简介</span><br><span class="line">        3.5.2 Flink 中的 Watermark 的设置</span><br><span class="line">        3.5.3 Punctuated Watermark</span><br><span class="line">        3.5.4 Periodic Watermark</span><br><span class="line">        3.5.5 每个 Kafka 分区的时间戳</span><br><span class="line">        3.5.6 将 Watermark 与 Window 结合起来处理延迟数据</span><br><span class="line">        3.5.7 处理延迟数据的三种方法</span><br><span class="line">        3.5.8 小结与反思</span><br><span class="line">    3.6Flink 常用的 Source Connector 和 Sink Connector 介绍</span><br><span class="line">        3.6.1 Data Source 简介</span><br><span class="line">        3.6.2 常用的 Data Source</span><br><span class="line">        3.6.3 Data Sink 简介</span><br><span class="line">        3.6.4 常用的 Data Sink</span><br><span class="line">        3.6.5 小结与反思</span><br><span class="line">    3.7Flink Connector —— Kafka 的使用和源码分析</span><br><span class="line">        3.7.1 准备环境和依赖</span><br><span class="line">        3.7.2 将测试数据发送到 Kafka Topic</span><br><span class="line">        3.7.3 Flink 如何消费 Kafka 数据？</span><br><span class="line">        3.7.4 Flink 如何将计算后的数据发送到 Kafka？</span><br><span class="line">        3.7.5 FlinkKafkaConsumer 源码分析</span><br><span class="line">        3.7.6 FlinkKafkaProducer 源码分析</span><br><span class="line">        3.7.7 使用 Flink-connector-kafka 可能会遇到的问题</span><br><span class="line">        3.7.8 小结与反思</span><br><span class="line">    3.8自定义 Flink Connector</span><br><span class="line">        3.8.1 自定义 Source Connector</span><br><span class="line">        3.8.2 RichSourceFunction 的用法及源码分析</span><br><span class="line">        3.8.3 自定义 Sink Connector</span><br><span class="line">        3.8.4 RichSinkFunction 的用法及源码分析</span><br><span class="line">        3.8.5 小结与反思</span><br><span class="line">    3.9Flink Connector —— ElasticSearch 的用法和分析</span><br><span class="line">        3.9.1 准备环境和依赖</span><br><span class="line">        3.9.2 使用 Flink 将数据写入到 ElasticSearch 应用程序</span><br><span class="line">        3.9.3 验证数据是否写入 ElasticSearch？</span><br><span class="line">        3.9.4 如何保证在海量数据实时写入下 ElasticSearch 的稳定性？</span><br><span class="line">        3.9.5 使用 Flink-connector-elasticsearch 可能会遇到的问题</span><br><span class="line">        3.9.6 小结与反思</span><br><span class="line">    3.10Flink Connector —— HBase 的用法</span><br><span class="line">        3.10.1 准备环境和依赖</span><br><span class="line">        3.10.2 Flink 使用 TableInputFormat 读取 HBase 批量数据</span><br><span class="line">        3.10.3 Flink 使用 TableOutputFormat 向 HBase 写入数据</span><br><span class="line">        3.10.4 Flink 使用 HBaseOutputFormat 向 HBase 实时写入数据</span><br><span class="line">        3.10.5 项目运行及验证</span><br><span class="line">        3.10.6 小结与反思</span><br><span class="line">    3.11Flink Connector —— Redis 的用法</span><br><span class="line">        3.11.1 安装 Redis</span><br><span class="line">        3.11.2 将商品数据发送到 Kafka</span><br><span class="line">        3.11.3 Flink 消费 Kafka 中的商品数据</span><br><span class="line">        3.11.4 Redis Connector 简介</span><br><span class="line">        3.11.5 Flink 写入数据到 Redis</span><br><span class="line">        3.11.6 项目运行及验证</span><br><span class="line">        3.11.7 小结与反思</span><br><span class="line">    3.12使用 Side Output 分流</span><br><span class="line">        3.12.1 使用 Filter 分流</span><br><span class="line">        3.12.2 使用 Split 分流</span><br><span class="line">        3.12.3 使用 Side Output 分流</span><br><span class="line">        3.12.4 小结与反思</span><br><span class="line">    3.13总结</span><br><span class="line">    </span><br><span class="line">3进阶篇</span><br><span class="line"></span><br><span class="line">4第四章——Flink 中的状态及容错机制</span><br><span class="line">    4.1深度讲解 Flink 中的状态</span><br><span class="line">        4.1.1 为什么需要 State？</span><br><span class="line">        4.1.2 State 的种类</span><br><span class="line">        4.1.3 Keyed State</span><br><span class="line">        4.1.4 Operator State</span><br><span class="line">        4.1.5 Raw and Managed State</span><br><span class="line">        4.1.6 如何使用托管的 Keyed State</span><br><span class="line">        4.1.7 State TTL(存活时间)</span><br><span class="line">        4.1.8 如何使用托管的 Operator State</span><br><span class="line">        4.1.9 Stateful Source Functions</span><br><span class="line">        4.1.10 Broadcast State</span><br><span class="line">        4.1.11 Queryable State</span><br><span class="line">        4.1.12 小结与反思</span><br><span class="line">    4.2Flink 状态后端存储</span><br><span class="line">        4.2.1 State Backends</span><br><span class="line">        4.2.2 MemoryStateBackend 的用法及分析</span><br><span class="line">        4.2.3 FsStateBackend 的用法及分析</span><br><span class="line">        4.2.4 RocksDBStateBackend 的用法及分析</span><br><span class="line">        4.2.5 如何选择状态后端存储？</span><br><span class="line">        4.2.6 小结与反思</span><br><span class="line">    4.3Flink Checkpoint 和 Savepoint 的区别及其配置使用</span><br><span class="line">        4.3.1 Checkpoint 简介及使用</span><br><span class="line">        4.3.2 Savepoint 简介及使用</span><br><span class="line">        4.3.3 Savepoint 与 Checkpoint 的区别</span><br><span class="line">        4.3.4 Checkpoint 流程</span><br><span class="line">        4.3.5 如何从 Checkpoint 中恢复状态</span><br><span class="line">        4.3.6 如何从 Savepoint 中恢复状态</span><br><span class="line">        4.3.6 小结与反思</span><br><span class="line">    4.4总结</span><br><span class="line">    </span><br><span class="line">5第五章——Table API &amp; SQL</span><br><span class="line">    5.1Flink Table &amp; SQL 概念与通用 API</span><br><span class="line">        5.1.1 新增 Blink SQL 查询处理器</span><br><span class="line">        5.1.2 为什么选择 Table API &amp; SQL？</span><br><span class="line">        5.1.3 Flink Table 项目模块</span><br><span class="line">        5.1.4 两种 planner 之间的区别</span><br><span class="line">        5.1.5 添加项目依赖</span><br><span class="line">        5.1.6 创建一个 TableEnvironment</span><br><span class="line">        5.1.7 Table API &amp; SQL 应用程序的结构</span><br><span class="line">        5.1.8 Catalog 中注册 Table</span><br><span class="line">        5.1.9 注册外部的 Catalog</span><br><span class="line">        5.1.10 查询 Table</span><br><span class="line">        5.1.11 提交 Table</span><br><span class="line">        5.1.12 翻译并执行查询</span><br><span class="line">        5.1.13 小结与反思</span><br><span class="line">    5.2Flink Table API &amp; SQL 功能</span><br><span class="line">        5.2.1 Flink Table 和 SQL 与 DataStream 和 DataSet 集成</span><br><span class="line">        5.2.2 查询优化</span><br><span class="line">        5.2.3 数据类型</span><br><span class="line">        5.2.4 时间属性</span><br><span class="line">        5.2.5 SQL Connector</span><br><span class="line">        5.2.6 SQL Client</span><br><span class="line">        5.2.7 Hive</span><br><span class="line">        5.2.8 小结与反思</span><br><span class="line">    5.3总结</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">6第六章——扩展库</span><br><span class="line">    6.1Flink CEP 简介及其使用场景</span><br><span class="line">        6.1.1 CEP 简介</span><br><span class="line">        6.1.2 规则引擎对比</span><br><span class="line">        6.1.3 Flink CEP 简介</span><br><span class="line">        6.1.4 Flink CEP 动态更新规则</span><br><span class="line">        6.1.5 Flink CEP 使用场景分析</span><br><span class="line">        6.1.6 小结与反思</span><br><span class="line">    6.2使用 Flink CEP 处理复杂事件</span><br><span class="line">        6.2.1 准备依赖</span><br><span class="line">        6.2.2 Flink CEP 入门应用程序</span><br><span class="line">        6.2.3 Pattern API</span><br><span class="line">        6.2.4 检测 Pattern</span><br><span class="line">        6.2.5 CEP 时间属性</span><br><span class="line">        6.2.6 小结与反思</span><br><span class="line">    6.3Flink 扩展库——State Processor API</span><br><span class="line">        6.3.1 State Processor API 简介</span><br><span class="line">        6.3.2 在 Flink 1.9 之前是如何处理状态的？</span><br><span class="line">        6.3.3 使用 State Processor API 读写作业状态</span><br><span class="line">        6.3.4 使用 DataSet 读取作业状态</span><br><span class="line">        6.3.5 为什么要使用 DataSet API？</span><br><span class="line">        6.3.6 小结与反思</span><br><span class="line">    6.4Flink 扩展库——Machine Learning</span><br><span class="line">        6.4.1 Flink-ML 简介</span><br><span class="line">        6.4.2 使用 Flink-ML</span><br><span class="line">        6.4.3 使用 Flink-ML Pipeline</span><br><span class="line">        6.4.4 小结与反思</span><br><span class="line">    6.5Flink 扩展库——Gelly</span><br><span class="line">        6.5.1 Gelly 简介</span><br><span class="line">        6.5.2 使用 Gelly</span><br><span class="line">        6.5.3 Gelly API</span><br><span class="line">        6.5.4 小结与反思</span><br><span class="line">    6.6 总结</span><br><span class="line"></span><br><span class="line">4高级篇</span><br><span class="line"></span><br><span class="line">7第七章——Flink 作业环境部署</span><br><span class="line">    7.1Flink 配置详解及如何配置高可用？</span><br><span class="line">        7.1.1 Flink 配置详解</span><br><span class="line">        7.1.2 Log 的配置</span><br><span class="line">        7.1.3 如何配置 JobManager 高可用？</span><br><span class="line">        7.1.4 小结与反思</span><br><span class="line">    7.2Flink 作业如何在 Standalone、YARN、Mesos、K8S 上部署运行？</span><br><span class="line">        7.2.1 Standalone</span><br><span class="line">        7.2.2 YARN</span><br><span class="line">        7.2.3 Mesos</span><br><span class="line">        7.3.4 Kubernetes</span><br><span class="line">        7.2.5 小结与反思</span><br><span class="line">    7.3总结</span><br><span class="line">    </span><br><span class="line">8第八章——Flink 监控</span><br><span class="line">    8.1实时监控 Flink 及其作业</span><br><span class="line">        8.1.1 监控 JobManager</span><br><span class="line">        8.1.2 监控 TaskManager</span><br><span class="line">        8.1.3 监控 Flink 作业</span><br><span class="line">        8.1.4 最关心的性能指标</span><br><span class="line">        8.1.5 小结与反思</span><br><span class="line">    8.2搭建一套 Flink 监控系统</span><br><span class="line">        8.2.1 利用 API 获取监控数据</span><br><span class="line">        8.2.2 Metrics 类型简介</span><br><span class="line">        8.2.3 利用 JMXReporter 获取监控数据</span><br><span class="line">        8.2.4 利用 PrometheusReporter 获取监控数据</span><br><span class="line">        8.2.5 利用 PrometheusPushGatewayReporter 获取监控数据</span><br><span class="line">        8.2.6 利用 InfluxDBReporter 获取监控数据</span><br><span class="line">        8.2.7 安装 InfluxDB 和 Grafana</span><br><span class="line">        8.2.8 配置 Grafana 展示监控数据</span><br><span class="line">        8.2.9 小结与反思</span><br><span class="line">    8.3总结</span><br><span class="line"></span><br><span class="line">9第九章——Flink 性能调优</span><br><span class="line">    9.1如何处理 Flink Job Backpressure （反压）问题？</span><br><span class="line">        9.1.1 Flink 流处理为什么需要网络流控</span><br><span class="line">        9.1.2 Flink 1.5 之前的网络流控机制</span><br><span class="line">        9.1.3 基于 Credit 的反压机制</span><br><span class="line">        9.1.4 定位产生反压的位置</span><br><span class="line">        9.1.5 分析和处理反压问题</span><br><span class="line">        9.1.6 小结与反思</span><br><span class="line">    9.2如何查看 Flink 作业执行计划？</span><br><span class="line">        9.2.1 如何获取执行计划 JSON？</span><br><span class="line">        9.2.2 生成执行计划图</span><br><span class="line">        9.2.3 深入探究 Flink 作业执行计划</span><br><span class="line">        9.2.4 Flink 中算子 chain 起来的条件</span><br><span class="line">        9.2.5 如何禁止 Operator chain？</span><br><span class="line">        9.2.6 小结与反思</span><br><span class="line">    9.3Flink Parallelism 和 Slot 深度理解</span><br><span class="line">        9.3.1 Parallelism 简介</span><br><span class="line">        9.3.2 如何设置 Parallelism？</span><br><span class="line">        9.3.3 Slot 简介</span><br><span class="line">        9.3.4 Slot 和 Parallelism 的关系</span><br><span class="line">        9.3.5 可能会遇到 Slot 和 Parallelism 的问题</span><br><span class="line">        9.3.6 小结与反思</span><br><span class="line">    9.4如何合理的设置 Flink 作业并行度？</span><br><span class="line">        9.4.1 Source 端并行度的配置</span><br><span class="line">        9.4.2 中间 Operator 并行度的配置</span><br><span class="line">        9.4.3 Sink 端并行度的配置</span><br><span class="line">        9.4.4 Operator Chain</span><br><span class="line">        9.4.5 小结与反思</span><br><span class="line">    9.5Flink 中如何保证 Exactly Once？</span><br><span class="line">        9.5.1 Flink 内部如何保证 Exactly Once？</span><br><span class="line">        9.5.2 端对端如何保证 Exactly Once？</span><br><span class="line">        9.5.3 分析 FlinkKafkaConsumer 的设计思想</span><br><span class="line">        9.5.4 小结与反思</span><br><span class="line">    9.6如何处理 Flink 中数据倾斜问题？</span><br><span class="line">        9.6.1 数据倾斜简介</span><br><span class="line">        9.6.2 判断是否存在数据倾斜</span><br><span class="line">        9.6.3 分析和解决数据倾斜问题</span><br><span class="line">        9.6.4 小结与反思</span><br><span class="line">    9.7总结</span><br><span class="line"></span><br><span class="line">10第十章——Flink 最佳实践</span><br><span class="line">    10.1如何设置 Flink Job RestartStrategy（重启策略）？</span><br><span class="line">        10.1.1 常见错误导致 Flink 作业重启</span><br><span class="line">        10.1.2 RestartStrategy 简介</span><br><span class="line">        10.1.3 为什么需要 RestartStrategy？</span><br><span class="line">        10.1.4 如何配置 RestartStrategy？</span><br><span class="line">        10.1.5 RestartStrategy 源码分析</span><br><span class="line">        10.1.6 Failover Strategies（故障恢复策略）</span><br><span class="line">        10.1.7 小结与反思</span><br><span class="line">    10.2如何使用 Flink ParameterTool 读取配置？</span><br><span class="line">        10.2.1 Flink Job 配置</span><br><span class="line">        10.2.2 ParameterTool 管理配置</span><br><span class="line">        10.2.3 ParameterTool 源码分析</span><br><span class="line">        10.2.4 小结与反思</span><br><span class="line">    10.3总结</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">5实战篇</span><br><span class="line"></span><br><span class="line">11第十一章——Flink 实战</span><br><span class="line">    11.1如何统计网站各页面一天内的 PV 和 UV？</span><br><span class="line">        11.1.1 统计网站各页面一天内的 PV</span><br><span class="line">        11.1.2 统计网站各页面一天内 UV 的三种方案</span><br><span class="line">        11.1.3 小结与反思</span><br><span class="line">    11.2如何使用 Flink ProcessFunction 处理宕机告警?</span><br><span class="line">        11.2.1 ProcessFunction 简介</span><br><span class="line">        11.2.2 CoProcessFunction 简介</span><br><span class="line">        11.2.3 Timer 简介</span><br><span class="line">        11.2.4 如果利用 ProcessFunction 处理宕机告警？</span><br><span class="line">        11.2.5 小结与反思</span><br><span class="line">    11.3如何利用 Async I／O 读取告警规则？</span><br><span class="line">        11.3.1 为什么需要 Async I/O？</span><br><span class="line">        11.3.2 Async I/O API</span><br><span class="line">        11.3.3 利用 Async I/O 读取告警规则需求分析</span><br><span class="line">        11.3.4 如何使用 Async I/O 读取告警规则数据</span><br><span class="line">        11.3.5 小结与反思</span><br><span class="line">    11.4如何利用广播变量动态更新告警规则？</span><br><span class="line">        11.4.1 BroadcastVariable 简介</span><br><span class="line">        11.4.2 如何使用 BroadcastVariable ？</span><br><span class="line">        11.4.3 利用广播变量动态更新告警规则数据需求分析</span><br><span class="line">        11.4.4 读取告警规则数据</span><br><span class="line">        11.4.5 监控数据连接规则数据</span><br><span class="line">        11.4.6 小结与反思</span><br><span class="line">    11.5如何实时将应用 Error 日志告警？</span><br><span class="line">        11.5.1 日志处理方案的演进</span><br><span class="line">        11.5.2 日志采集工具对比</span><br><span class="line">        11.5.3 日志结构设计</span><br><span class="line">        11.5.4 异常日志实时告警项目架构</span><br><span class="line">        11.5.5 日志数据发送到 Kafka</span><br><span class="line">        11.5.6 Flink 实时处理日志数据</span><br><span class="line">        11.5.7 处理应用异常日志</span><br><span class="line">        11.5.8 小结与反思</span><br><span class="line">    11.6总结</span><br><span class="line">    </span><br><span class="line">6案例篇</span><br><span class="line"></span><br><span class="line">12第十二章——Flink 案例</span><br><span class="line">    12.1基于 Flink 实时处理海量日志</span><br><span class="line">        12.2.1 实时处理海量日志需求分析</span><br><span class="line">        12.2.2 实时处理海量日志架构设计</span><br><span class="line">        12.2.3 日志实时采集</span><br><span class="line">        12.2.4 日志格式统一</span><br><span class="line">        12.2.5 日志实时清洗</span><br><span class="line">        12.2.6 日志实时告警</span><br><span class="line">        12.2.7 日志实时存储</span><br><span class="line">        12.2.8 日志实时展示</span><br><span class="line">        12.2.9 小结与反思</span><br><span class="line">    12.2基于 Flink 的百亿数据实时去重</span><br><span class="line">        12.2.1 去重的通用解决方案</span><br><span class="line">        12.2.2 使用 BloomFilter 实现去重</span><br><span class="line">        12.2.3 使用 HBase 维护全局 Set 实现去重</span><br><span class="line">        12.2.4 使用 Flink 的 KeyedState 实现去重</span><br><span class="line">        12.2.5 使用 RocksDBStateBackend 的优化方法</span><br><span class="line">        12.2.6 小结与反思</span><br><span class="line">    12.3基于 Flink 的实时监控告警系统</span><br><span class="line">        12.3.1 监控系统的诉求</span><br><span class="line">        12.3.2 监控系统包含的内容</span><br><span class="line">        12.3.3 Metrics／Trace／Log 数据实时采集</span><br><span class="line">        12.3.4 消息队列如何撑住高峰流量</span><br><span class="line">        12.3.5 指标数据实时计算</span><br><span class="line">        12.3.6 提供及时且准确的根因分析告警</span><br><span class="line">        12.3.7 AIOps 智能运维道路探索</span><br><span class="line">        12.3.8 如何保障高峰流量实时写入存储系统的稳定性</span><br><span class="line">        12.3.9 监控数据使用可视化图表展示</span><br><span class="line">        12.3.10 小结与反思</span><br><span class="line">    12.4总结</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;基于 Flink 1.9 讲解的书籍目录大纲，含 Flink 入门、概念、原理、实战、性能调优、源码解析等内容。涉及 Flink Connector、Metrics、Library、DataStream API、Table API &amp;amp; SQL 等内容的学习案例，还有 Flink 落地应用的大型项目案例分享。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>数据仓库简介、发展、架构演进、实时数仓建设、与离线数仓对比</title>
    <link href="http://www.54tianzhisheng.cn/2019/11/23/real-time-warehouse/"/>
    <id>http://www.54tianzhisheng.cn/2019/11/23/real-time-warehouse/</id>
    <published>2019-11-22T16:00:00.000Z</published>
    <updated>2019-11-24T08:34:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>数据仓库也是公司数据发展到一定规模后必然会提供的一种基础服务，数据仓库的建设也是“数据智能”中必不可少的一环。本文将从数据仓库的简介、经历了怎样的发展、如何建设、架构演变、应用案例以及实时数仓与离线数仓的对比六个方面全面分享关于数仓的详细内容。</p><a id="more"></a><p>本文作者：郭华（付空）</p><p>原地地址：<a href="">https://ververica.cn/developers/how-to-do-real-time-counting/</a></p><h2 id="1-数据仓库简介"><a href="#1-数据仓库简介" class="headerlink" title="1. 数据仓库简介"></a>1. 数据仓库简介</h2><p>数据仓库是一个面向主题的（Subject Oriented）、集成的（Integrate）、相对稳定的（Non-Volatile）、反映历史变化（Time Variant）的数据集合，用于支持管理决策。</p><p>数据仓库是伴随着企业信息化发展起来的，在企业信息化的过程中，随着信息化工具的升级和新工具的应用，数据量变的越来越大，数据格式越来越多，决策要求越来越苛刻，数据仓库技术也在不停的发展。</p><p><strong>数据仓库的趋势</strong>：</p><ul><li><p>实时数据仓库以满足实时化&amp;自动化决策需求；</p></li><li><p>大数据&amp;数据湖以支持大量&amp;复杂数据类型（文本、图像、视频、音频）；</p></li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-075759.jpg" alt=""></p><h2 id="2-数据仓库的发展"><a href="#2-数据仓库的发展" class="headerlink" title="2. 数据仓库的发展"></a>2. 数据仓库的发展</h2><p>数据仓库有两个环节：数据仓库的构建与数据仓库的应用。</p><p>早期数据仓库构建主要指的是把企业的业务数据库如 ERP、CRM、SCM 等数据按照决策分析的要求建模并汇总到数据仓库引擎中，其应用以报表为主，目的是支持管理层和业务人员决策（中长期策略型决策）。</p><p>随着业务和环境的发展，这两方面都在发生着剧烈变化。</p><ul><li><p>随着IT技术走向互联网、移动化，数据源变得越来越丰富，在原来业务数据库的基础上出现了非结构化数据，比如网站 log，IoT 设备数据，APP 埋点数据等，这些数据量比以往结构化的数据大了几个量级，对 ETL 过程、存储都提出了更高的要求；</p></li><li><p>互联网的在线特性也将业务需求推向了实时化，随时根据当前客户行为而调整策略变得越来越常见，比如大促过程中库存管理，运营管理等（即既有中远期策略型，也有短期操作型）；同时公司业务互联网化之后导致同时服务的客户剧增，有些情况人工难以完全处理，这就需要机器自动决策。比如欺诈检测和用户审核。</p></li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-075902.jpg" alt=""></p><p>总结来看，对数据仓库的需求可以抽象成两方面：实时产生结果、处理和保存大量异构数据。</p><blockquote><p>注：这里不讨论数据湖技术。</p></blockquote><h2 id="3-数据仓库建设方法论"><a href="#3-数据仓库建设方法论" class="headerlink" title="3. 数据仓库建设方法论"></a>3. 数据仓库建设方法论</h2><h3 id="3-1-面向主题"><a href="#3-1-面向主题" class="headerlink" title="3.1 面向主题"></a>3.1 面向主题</h3><p>从公司业务出发，是分析的宏观领域，比如供应商主题、商品主题、客户主题和仓库主题</p><h3 id="3-2-为多维数据分析服务"><a href="#3-2-为多维数据分析服务" class="headerlink" title="3.2 为多维数据分析服务"></a>3.2 为多维数据分析服务</h3><p>数据报表；数据立方体，上卷、下钻、切片、旋转等分析功能。</p><h3 id="3-3-反范式数据模型"><a href="#3-3-反范式数据模型" class="headerlink" title="3.3 反范式数据模型"></a>3.3 反范式数据模型</h3><p>以事实表和维度表组成的星型数据模型</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-075956.jpg" alt=""></p><h2 id="4-数据仓库架构的演变"><a href="#4-数据仓库架构的演变" class="headerlink" title="4. 数据仓库架构的演变"></a>4. 数据仓库架构的演变</h2><p>数据仓库概念是 Inmon 于 1990 年提出并给出了完整的建设方法。随着互联网时代来临，数据量暴增，开始使用大数据工具来替代经典数仓中的传统工具。此时仅仅是工具的取代，架构上并没有根本的区别，可以把这个架构叫做<strong>离线大数据架构</strong>。</p><p>后来随着业务实时性要求的不断提高，人们开始在离线大数据架构基础上加了一个加速层，使用流处理技术直接完成那些实时性要求较高的指标计算，这便是 <strong>Lambda 架构</strong>。</p><p>再后来，实时的业务越来越多，事件化的数据源也越来越多，实时处理从次要部分变成了主要部分，架构也做了相应调整，出现了以实时事件处理为核心的 <strong>Kappa 架构</strong>。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-080041.jpg" alt=""></p><h3 id="4-1-离线大数据架构"><a href="#4-1-离线大数据架构" class="headerlink" title="4.1 离线大数据架构"></a>4.1 离线大数据架构</h3><p>数据源通过离线的方式导入到离线数仓中。下游应用根据业务需求选择直接读取 DM 或加一层数据服务，比如 MySQL 或 Redis。数据仓库从模型层面分为三层：</p><p>ODS，操作数据层，保存原始数据；</p><ul><li><p>DWD，数据仓库明细层，根据主题定义好事实与维度表，保存最细粒度的事实数据；</p></li><li><p>DM，数据集市/轻度汇总层，在 DWD 层的基础之上根据不同的业务需求做轻度汇总；</p></li><li><p>典型的数仓存储是 HDFS/Hive，ETL 可以是 MapReduce 脚本或 HiveSQL。</p></li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-080123.jpg" alt=""></p><h3 id="4-2-Lambda-架构"><a href="#4-2-Lambda-架构" class="headerlink" title="4.2 Lambda 架构"></a>4.2 Lambda 架构</h3><p>随着大数据应用的发展，人们逐渐对系统的实时性提出了要求，为了计算一些实时指标，就在原来离线数仓的基础上增加了一个实时计算的链路，并对数据源做流式改造（即把数据发送到消息队列），实时计算去订阅消息队列，直接完成指标增量的计算，推送到下游的数据服务中去，由数据服务层完成离线&amp;实时结果的合并。</p><blockquote><p>注：流处理计算的指标批处理依然计算，最终以批处理为准，即每次批处理计算后会覆盖流处理的结果。（这仅仅是流处理引擎不完善做的折中）</p></blockquote><p>Lambda 架构问题：</p><ul><li><p>同样的需求需要开发两套一样的代码：这是 Lambda 架构最大的问题，两套代码不仅仅意味着开发困难（同样的需求，一个在批处理引擎上实现，一个在流处理引擎上实现，还要分别构造数据测试保证两者结果一致），后期维护更加困难，比如需求变更后需要分别更改两套代码，独立测试结果，且两个作业需要同步上线。</p></li><li><p>资源占用增多：同样的逻辑计算两次，整体资源占用会增多（多出实时计算这部分</p></li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-080211.jpg" alt=""></p><h3 id="4-3-Kappa-架构"><a href="#4-3-Kappa-架构" class="headerlink" title="4.3 Kappa 架构"></a>4.3 Kappa 架构</h3><p>Lambda 架构虽然满足了实时的需求，但带来了更多的开发与运维工作，其架构背景是流处理引擎还不完善，流处理的结果只作为临时的、近似的值提供参考。后来随着 Flink 等流处理引擎的出现，流处理技术很成熟了，这时为了解决两套代码的问题，LickedIn 的 Jay Kreps 提出了 Kappa 架构。</p><ul><li><p>Kappa 架构可以认为是 Lambda 架构的简化版（只要移除 lambda 架构中的批处理部分即可）。</p></li><li><p>在 Kappa 架构中，需求修改或历史数据重新处理都通过上游重放完成。</p></li><li><p>Kappa 架构最大的问题是流式重新处理历史的吞吐能力会低于批处理，但这个可以通过增加计算资源来弥补。</p></li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-080256.jpg" alt=""></p><p>Kappa 架构的重新处理过程：</p><p>重新处理是人们对 Kappa 架构最担心的点，但实际上并不复杂：</p><ul><li><p>选择一个具有重放功能的、能够保存历史数据并支持多消费者的消息队列，根据需求设置历史数据保存的时长，比如 Kafka，可以保存全部历史数据。</p></li><li><p>当某个或某些指标有重新处理的需求时，按照新逻辑写一个新作业，然后从上游消息队列的最开始重新消费，把结果写到一个新的下游表中。</p></li><li><p>当新作业赶上进度后，应用切换数据源，读取 2 中产生的新结果表。</p></li><li><p>停止老的作业，删除老的结果表。</p></li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-080342.jpg" alt=""></p><h3 id="4-4-Lambda-架构与-Kappa-架构的对比"><a href="#4-4-Lambda-架构与-Kappa-架构的对比" class="headerlink" title="4.4 Lambda 架构与 Kappa 架构的对比"></a>4.4 Lambda 架构与 Kappa 架构的对比</h3><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-080410.jpg" alt=""></p><ul><li><p>在真实的场景中，很多时候并不是完全规范的 Lambda 架构或 Kappa 架构，可以是两者的混合，比如大部分实时指标使用 Kappa 架构完成计算，少量关键指标（比如金额相关）使用 Lambda 架构用批处理重新计算，增加一次校对过程。</p></li><li><p>Kappa 架构并不是中间结果完全不落地，现在很多大数据系统都需要支持机器学习（离线训练），所以实时中间结果需要落地对应的存储引擎供机器学习使用，另外有时候还需要对明细数据查询，这种场景也需要把实时明细层写出到对应的引擎中。参考后面的案例。</p></li><li><p>另外，随着数据多样性的发展，数据仓库这种提前规定 schema 的模式显得越来难以支持灵活的探索&amp;分析需求，这时候便出现了一种数据湖技术，即把原始数据全部缓存到某个大数据存储上，后续分析时再根据需求去解析原始数据。简单的说，数据仓库模式是 schema on write，数据湖模式是 schema on read。</p></li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-080441.jpg" alt=""></p><h2 id="5-实时数仓案例"><a href="#5-实时数仓案例" class="headerlink" title="5. 实时数仓案例"></a>5. 实时数仓案例</h2><p>菜鸟仓配实时数据仓库本案例参考自菜鸟仓配团队的分享，涉及全局设计、数据模型、数据保障等几个方面。</p><blockquote><p>注：特别感谢缘桥同学的无私分享。</p></blockquote><h3 id="5-1-整体设计"><a href="#5-1-整体设计" class="headerlink" title="5.1 整体设计"></a>5.1 整体设计</h3><p>整体设计如下图，基于业务系统的数据，数据模型采用中间层的设计理念，建设仓配实时数仓；计算引擎，选择更易用、性能表现更佳的实时计算作为主要的计算引擎；数据服务，选择天工数据服务中间件，避免直连数据库，且基于天工可以做到主备链路灵活配置秒级切换；数据应用，围绕大促全链路，从活动计划、活动备货、活动直播、活动售后、活动复盘五个维度，建设仓配大促数据体系。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-080523.jpg" alt=""></p><h3 id="5-2-数据模型"><a href="#5-2-数据模型" class="headerlink" title="5.2 数据模型"></a>5.2 数据模型</h3><p>不管是从计算成本，还是从易用性，还是从复用性，还是从一致性等等，我们都必须避免烟囱式的开发模式，而是以中间层的方式建设仓配实时数仓。与离线中间层基本一致，我们将实时中间层分为两层。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-080546.jpg" alt=""></p><p><strong>第一层 DWD 公共实时明细层</strong></p><p>实时计算订阅业务数据消息队列，然后通过数据清洗、多数据源 join、流式数据与离线维度信息等的组合，将一些相同粒度的业务系统、维表中的维度属性全部关联到一起，增加数据易用性和复用性，得到最终的实时明细数据。这部分数据有两个分支，一部分直接落地到 ADS，供实时明细查询使用，一部分再发送到消息队列中，供下层计算使用；</p><p><strong>第二层 DWS 公共实时汇总层</strong></p><p>以数据域+业务域的理念建设公共汇总层，与离线数仓不同的是，这里汇总层分为轻度汇总层和高度汇总层，并同时产出，轻度汇总层写入 ADS，用于前端产品复杂的 olap 查询场景，满足自助分析和产出报表的需求；高度汇总层写入 Hbase，用于前端比较简单的 kv 查询场景，提升查询性能，比如实时大屏等；</p><p>注：</p><ul><li>ADS 是一款提供 OLAP 分析服务的引擎。开源提供类似功能的有，Elastic Search、Kylin、Druid 等；</li><li>案例中选择把数据写入到 Hbase 供 KV 查询，也可根据情况选择其他引擎，比如数据量不多，查询压力也不大的话，可以用 MySQL；</li><li>因主题建模与业务关系较大，这里不做描述；</li></ul><h3 id="5-3-数据保障"><a href="#5-3-数据保障" class="headerlink" title="5.3 数据保障"></a>5.3 数据保障</h3><p>阿里巴巴每年都有双十一等大促，大促期间流量与数据量都会暴增。实时系统要保证实时性，相对离线系统对数据量要更敏感，对稳定性要求更高。所以为了应对这种场景，还需要在这种场景下做两种准备：</p><p>大促前的系统压测；</p><p>大促中的主备链路保障；</p><p>菜鸟双11「仓储配送数据实时化」详情了解：<a href="">https://yq.aliyun.com/articles/658787</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-080723.jpg" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-080723.jpg" alt=""></p><h2 id="6-实时数仓与离线数仓的对比"><a href="#6-实时数仓与离线数仓的对比" class="headerlink" title="6. 实时数仓与离线数仓的对比"></a>6. 实时数仓与离线数仓的对比</h2><p>在看过前面的叙述与菜鸟案例之后，我们看一下实时数仓与离线数仓在几方面的对比：</p><ul><li><p>首先，从架构上，实时数仓与离线数仓有比较明显的区别，实时数仓以 Kappa 架构为主，而离线数仓以传统大数据架构为主。Lambda 架构可以认为是两者的中间态。</p></li><li><p>其次，从建设方法上，实时数仓和离线数仓基本还是沿用传统的数仓主题建模理论，产出事实宽表。另外实时数仓中实时流数据的 join 有隐藏时间语义，在建设中需注意。</p></li><li><p>最后，从数据保障看，实时数仓因为要保证实时性，所以对数据量的变化较为敏感。在大促等场景下需要提前做好压测和主备保障工作，这是与离线数据的一个较为明显的区别。</p></li></ul><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-150802.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;数据仓库也是公司数据发展到一定规模后必然会提供的一种基础服务，数据仓库的建设也是“数据智能”中必不可少的一环。本文将从数据仓库的简介、经历了怎样的发展、如何建设、架构演变、应用案例以及实时数仓与离线数仓的对比六个方面全面分享关于数仓的详细内容。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>详解 Flink Metrics 原理与监控实战</title>
    <link href="http://www.54tianzhisheng.cn/2019/11/23/flink-metrics/"/>
    <id>http://www.54tianzhisheng.cn/2019/11/23/flink-metrics/</id>
    <published>2019-11-22T16:00:00.000Z</published>
    <updated>2019-11-24T13:02:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要讲解 Metrics、如何使用 Metrics 分析问题并解决问题，并对 Metrics 监控实战进行解释说明。</p><a id="more"></a><p>本文作者：Apache Flink Contributor 刘彪</p><h3 id="什么是-Metrics？"><a href="#什么是-Metrics？" class="headerlink" title="什么是 Metrics？"></a>什么是 Metrics？</h3><p>Flink 提供的 Metrics 可以在 Flink 内部收集一些指标，通过这些指标让开发人员更好地理解作业或集群的状态。由于集群运行后很难发现内部的实际状况，跑得慢或快，是否异常等，开发人员无法实时查看所有的 Task 日志，比如作业很大或者有很多作业的情况下，该如何处理？此时 Metrics 可以很好的帮助开发人员了解作业的当前状况。</p><h4 id="Metric-Types"><a href="#Metric-Types" class="headerlink" title="Metric Types"></a>Metric Types</h4><p>Metrics 的类型如下：</p><ul><li>首先，常用的如 Counter，写过 mapreduce 作业的开发人员就应该很熟悉 Counter，其实含义都是一样的，就是对一个计数器进行累加，即对于多条数据和多兆数据一直往上加的过程。</li><li>第二，Gauge，Gauge 是最简单的 Metrics，它反映一个值。比如要看现在 Java heap 内存用了多少，就可以每次实时的暴露一个 Gauge，Gauge 当前的值就是heap使用的量。</li><li>第三，Meter，Meter 是指统计吞吐量和单位时间内发生“事件”的次数。它相当于求一种速率，即事件次数除以使用的时间。</li><li>第四，Histogram，Histogram 比较复杂，也并不常用，Histogram 用于统计一些数据的分布，比如说 Quantile、Mean、StdDev、Max、Min 等。 </li></ul><h4 id="Metric-Group"><a href="#Metric-Group" class="headerlink" title="Metric Group"></a>Metric Group</h4><p>Metric 在 Flink 内部有多层结构，以 Group 的方式组织，它并不是一个扁平化的结构，Metric Group + Metric Name 是 Metrics 的唯一标识。 </p><p>Metric Group 的层级有 TaskManagerMetricGroup 和TaskManagerJobMetricGroup，每个 Job 具体到某一个 task 的 group，task 又分为 TaskIOMetricGroup 和 OperatorMetricGroup。Operator 下面也有 IO 统计和一些 Metrics，整个层级大概如下图所示。Metrics 不会影响系统，它处在不同的组中，并且 Flink支持自己去加 Group，可以有自己的层级。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">•TaskManagerMetricGroup</span><br><span class="line">    •TaskManagerJobMetricGroup</span><br><span class="line">        •TaskMetricGroup</span><br><span class="line">            •TaskIOMetricGroup</span><br><span class="line">            •OperatorMetricGroup</span><br><span class="line">                •$&#123;User-defined Group&#125; / $&#123;User-defined Metrics&#125;</span><br><span class="line">                •OperatorIOMetricGroup</span><br><span class="line">•JobManagerMetricGroup</span><br><span class="line">    •JobManagerJobMetricGroup</span><br></pre></td></tr></table></figure><p>JobManagerMetricGroup 相对简单，相当于 Master，它的层级也相对较少。</p><p>Metrics 定义还是比较简单的，即指标的信息可以自己收集，自己统计，在外部系统能够看到 Metrics 的信息，并能够对其进行聚合计算。 </p><h3 id="如何使用-Metrics？"><a href="#如何使用-Metrics？" class="headerlink" title="如何使用 Metrics？"></a>如何使用 Metrics？</h3><h4 id="System-Metrics"><a href="#System-Metrics" class="headerlink" title="System Metrics"></a>System Metrics</h4><p>System Metrics，将整个集群的状态已经涵盖得非常详细。具体包括以下方面：</p><ul><li>Master 级别和 Work 级别的 JVM 参数，如 load 和 time；其 Memory 划分也很详细，包括 heap 的使用情况、non-heap 的使用情况、direct 的使用情况，以及 mapped 的使用情况；Threads 可以看到具体有多少线程；还有非常实用的 Garbage Collection。</li><li>Network 使用比较广泛，当需要解决一些性能问题的时候，Network 非常实用。Flink 不只是网络传输，还是一个有向无环图的结构，可以看到它的每个上下游都是一种简单的生产者消费者模型。Flink 通过网络相当于标准的生产者和消费者中间通过有限长度的队列模型。如果想要评估定位性能，中间队列会迅速缩小问题的范围，能够很快的找到问题瓶颈。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">•CPU</span><br><span class="line">•Memory</span><br><span class="line">•Threads</span><br><span class="line">•Garbage Collection</span><br><span class="line">•Network</span><br><span class="line">•Classloader</span><br><span class="line">•Cluster</span><br><span class="line">•Availability</span><br><span class="line">•Checkpointing</span><br><span class="line">•StateBackend</span><br><span class="line">•IO</span><br><span class="line">•详见: [https://ci.apache.org/projects/flink/flink-docs-release-1.8/monitoring/metrics.html#system-metrics](https://ci.apache.org/projects/flink/flink-docs-release-1.8/monitoring/metrics.html)</span><br></pre></td></tr></table></figure><ul><li>运维集群的人会比较关心 Cluster 的相关信息，如果作业太大，则需要非常关注 Checkpointing，它有可能会在一些常规的指标上无法体现出潜在问题。比如 Checkpointing 长时间没有工作，数据流看起来没有延迟，此时可能会出现作业一切正常的假象。另外，如果进行了一轮 failover 重启之后，因为 Checkpointing 长时间没有工作，有可能会回滚到很长一段时间之前的状态，整个作业可能就直接废掉了。</li><li>RocksDB 是生产环境当中比较常用的 state backend 实现，如果数据量足够大，就需要多关注 RocksDB 的 Metrics，因为它随着数据量的增大，性能可能会下降。</li></ul><h4 id="User-defined-Metrics"><a href="#User-defined-Metrics" class="headerlink" title="User-defined Metrics"></a>User-defined Metrics</h4><p>除了系统的 Metrics 之外，Flink 支持自定义 Metrics ，即 User-defined Metrics。上文说的都是系统框架方面，对于自己的业务逻辑也可以用 Metrics 来暴露一些指标，以便进行监控。</p><p>User-defined Metrics 现在提及的都是 datastream 的 API，table、sql 可能需要 context 协助，但如果写 UDF，它们其实是大同小异的。 </p><p>Datastream 的 API 是继承 RichFunction ，继承 RichFunction 才可以有 Metrics 的接口。然后通过 RichFunction 会带来一个 getRuntimeContext().getMetricGroup().addGroup(…) 的方法，这里就是 User-defined Metrics 的入口。通过这种方式，可以自定义 user-defined Metric Group。如果想定义具体的 Metrics，同样需要用getRuntimeContext().getMetricGroup().counter/gauge/meter/histogram(…) 方法，它会有相应的构造函数，可以定义到自己的 Metrics 类型中。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">继承 RichFunction</span><br><span class="line">    •Register user-defined Metric Group: getRuntimeContext().getMetricGroup().addGroup(…)</span><br><span class="line">    •Register user-defined Metric: getRuntimeContext().getMetricGroup().counter/gauge/meter/histogram(…)</span><br></pre></td></tr></table></figure><h4 id="User-defined-Metrics-Example"><a href="#User-defined-Metrics-Example" class="headerlink" title="User-defined Metrics Example"></a>User-defined Metrics Example</h4><p>下面通过一段简单的例子说明如何使用 Metrics。比如，定义了一个 Counter 传一个 name，Counter 默认的类型是 single counter（Flink 内置的一个实现），可以对 Counter 进行 inc（）操作，并在代码里面直接获取。</p><p>Meter 也是这样，Flink 有一个内置的实现是 Meterview，因为 Meter 是多长时间内发生事件的记录，所以它是要有一个多长时间的窗口。平常用 Meter 时直接 markEvent()，相当于加一个事件不停地打点，最后用 getrate（） 的方法直接把这一段时间发生的事件除一下给算出来。</p><p>Gauge 就比较简单了，把当前的时间打出来，用 Lambda 表达式直接把 System::currentTimeMillis 打进去就可以，相当于每次调用的时候都会去真正调一下系统当天时间进行计算。</p><p>Histogram 稍微复杂一点，Flink 中代码提供了两种实现，在此取一其中个实现，仍然需要一个窗口大小，更新的时候可以给它一个值。 </p><p>这些 Metrics 一般都不是线程安全的。如果想要用多线程，就需要加同步，更多详情请参考下面链接。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">•Counter processedCount = getRuntimeContext().getMetricGroup().counter(&quot;processed_count&quot;);</span><br><span class="line">  processedCount.inc();</span><br><span class="line">•Meter processRate = getRuntimeContext().getMetricGroup().meter(&quot;rate&quot;, new MeterView(60));</span><br><span class="line">  processRate.markEvent();</span><br><span class="line">•getRuntimeContext().getMetricGroup().gauge(&quot;current_timestamp&quot;, System::currentTimeMillis);</span><br><span class="line">•Histogram histogram = getRuntimeContext().getMetricGroup().histogram(&quot;histogram&quot;, new DescriptiveStatisticsHistogram(1000));</span><br><span class="line">  histogram.update(1024);</span><br><span class="line">•[https://ci.apache.org/projects/flink/flink-docs-release-1.8/monitoring/metrics.html#metric-types]</span><br></pre></td></tr></table></figure><h4 id="获取-Metrics"><a href="#获取-Metrics" class="headerlink" title="获取 Metrics"></a>获取 Metrics</h4><p>获取 Metrics 有三种方法，首先可以在 WebUI 上看到；其次可以通过 RESTful API 获取，RESTful API 对程序比较友好，比如写自动化脚本或程序，自动化运维和测试，通过 RESTful API 解析返回的 Json 格式对程序比较友好；最后，还可以通过 Metric Reporter 获取，监控主要使用 Metric Reporter 功能。</p><p>获取 Metrics 的方式在物理架构上是怎样实现的？</p><p>了解背景和原理会对使用有更深刻的理解。WebUI 和 RESTful API 是通过中心化节点定期查询把各个组件中的 Metrics 拉上来的实现方式。其中，fetch 不一定是实时更新的，默认为 10 秒，所以有可能在 WebUI 和 RESTful API 中刷新的数据不是实时想要得到的数据；此外，fetch 有可能不同步，比如两个组件，一边在加另一边没有动，可能是由于某种原因超时没有拉过来，这样是无法更新相关值的，它是 try best 的操作，所以有时我们看到的指标有可能会延迟，或许等待后相关值就更新了。</p><p>红色的路径通过 MetricFetcher，会有一个中心化的节点把它们聚合在一起展示。而 MetricReporter 不一样，每一个单独的点直接汇报，它没有中心化节点帮助做聚合。如果想要聚合，需要在第三方系统中进行，比如常见的 TSDB 系统。当然，不是中心化结构也是它的好处，它可以免去中心化节点带来的问题，比如内存放不下等，MetricReporter 把原始数据直接 Reporter 出来，用原始数据做处理会有更强大的功能。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-083902.jpg" alt=""></p><h4 id="Metric-Reporter"><a href="#Metric-Reporter" class="headerlink" title="Metric Reporter"></a>Metric Reporter</h4><p>Flink 内置了很多 Reporter，对外部系统的技术选型可以参考，比如 JMX 是 java 自带的技术，不严格属于第三方。还有 InfluxDB、Prometheus、Slf4j（直接打 log 里）等，调试时候很好用，可以直接看 logger，Flink 本身自带日志系统，会打到 Flink 框架包里面去。详见：详见：<a href="">https://ci.apache.org/projects/flink/flink-docs-release-1.8/monitoring/metrics.html#reporter</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">//配置</span><br><span class="line">metrics.reporters: your_monitor,jmx</span><br><span class="line">metrics.reporter.jmx.class: org.apache.flink.metrics.jmx.JMXReporter</span><br><span class="line">metrics.reporter.jmx.port: 1025-10000</span><br><span class="line">metrics.reporter.your_monitor.class: com.your_company.YourMonitorClass</span><br><span class="line">metrics.reporter.your_monitor.interval: 10 SECONDS</span><br><span class="line">metrics.reporter.your_monitor.config.a: your_a_value</span><br><span class="line">metrics.reporter.your_monitor.config.b: your_b_value</span><br></pre></td></tr></table></figure><p>Metric Reporter 是如何配置的？如上所示，首先 Metrics Reporters 的名字用逗号分隔，然后通过 metrics.reporter.jmx.class 的 classname 反射找 reporter，还需要拿到 metrics.reporter.jmx.port 的配置，比如像第三方系统通过网络发送的比较多。但要知道往哪里发，ip 地址、port 信息是比较常见的。此外还有 metrics.reporter.your_monitor.class 是必须要有的，可以自己定义间隔时间，Flink 可以解析，不需要自行去读，并且还可以写自己的 config。</p><h3 id="实战：利用-Metrics-监控"><a href="#实战：利用-Metrics-监控" class="headerlink" title="实战：利用 Metrics 监控"></a>实战：利用 Metrics 监控</h3><p>常用 Metrics 做自动化运维和性能分析。</p><h4 id="自动化运维"><a href="#自动化运维" class="headerlink" title="自动化运维"></a>自动化运维</h4><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-084205.jpg" alt=""></p><p>自动化运维怎么做？</p><p>首先，收集一些关键的 Metrics 作为决策依据，利用 Metric Reporter 收集 Metrics 到存储/分析系统 (例如 TSDB)，或者直接通过 RESTful API 获取。<br>有了数据之后，可以定制监控规则，关注关键指标，Failover、Checkpoint,、业务 Delay 信息。定制规则用途最广的是可以用来报警，省去很多人工的工作，并且可以定制 failover 多少次时需要人为介入。<br>当出现问题时，有钉钉报警、邮件报警、短信报警、电话报警等通知工具。<br>自动化运维的优势是可以通过大盘、报表的形式清晰的查看数据，通过大盘时刻了解作业总体信息，通过报表分析优化。</p><h4 id="性能分析"><a href="#性能分析" class="headerlink" title="性能分析"></a>性能分析</h4><p>性能分析一般遵循如下的流程：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-084235.jpg" alt=""></p><p>首先从发现问题开始，如果有 Metrics 系统，再配上监控报警，就可以很快定位问题。然后对问题进行剖析，大盘看问题会比较方便，通过具体的 System Metrics 分析，缩小范围，验证假设，找到瓶颈，进而分析原因，从业务逻辑、JVM、 操作系统、State、数据分布等多维度进行分析；如果还不能找到问题原因，就只能借助 profiling 工具了。</p><h4 id="实战：“我的任务慢，怎么办”"><a href="#实战：“我的任务慢，怎么办”" class="headerlink" title="实战：“我的任务慢，怎么办”"></a>实战：“我的任务慢，怎么办”</h4><p>“任务慢，怎么办？”可以称之为无法解答的终极问题之一。</p><p>其原因在于这种问题是系统框架问题，比如看医生时告诉医生身体不舒服，然后就让医生下结论。而通常医生需要通过一系列的检查来缩小范围，确定问题。同理，任务慢的问题也需要经过多轮剖析才能得到明确的答案。</p><p>除了不熟悉 Flink 机制以外，大多数人的问题是对于整个系统跑起来是黑盒，根本不知道系统在如何运行，缺少信息，无法了解系统状态。此时，一个有效的策略是求助 Metrics 来了解系统内部的状况，下面通过一些具体的例子来说明。</p><ul><li>发现问题</li></ul><p>比如下图 failover 指标，线上有一个不是 0，其它都是 0，此时就发现问题了。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-084308.jpg" alt=""></p><p>再比如下图 Input 指标正常都在四、五百万，突然跌成 0，这里也存在问题。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-084345.jpg" alt=""></p><p>业务延时问题如下图，比如处理到的数据跟当前时间比对，发现处理的数据是一小时前的数据，平时都是处理一秒之前的数据，这也是有问题的。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-084405.jpg" alt=""></p><ul><li>缩小范围，定位瓶颈</li></ul><p>当出现一个地方比较慢，但是不知道哪里慢时，如下图红色部分，OUTQ 并发值已经达到 100% 了，其它都还比较正常，甚至优秀。到这里生产者消费者模型出现了问题，生产者 INQ 是满的，消费者 OUT_Q 也是满的，从图中看出节点 4 已经很慢了，节点 1 产生的数据节点 4 处理不过来，而节点 5 的性能都很正常，说明节点 1 和节点 4 之间的队列已经堵了，这样我们就可以重点查看节点 1 和节点 4，缩小了问题范围。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-084437.jpg" alt=""></p><p>500 个 InBps 都具有 256 个 PARALLEL ，这么多个点不可能一一去看，因此需要在聚合时把 index 是第几个并发做一个标签。聚合按着标签进行划分，看哪一个并发是 100%。在图中可以划分出最高的两个线，即线 324 和线 115，这样就又进一步的缩小了范围。 </p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-24-084458.jpg" alt=""></p><p>利用 Metrics 缩小范围的方式如下图所示，就是用 Checkpoint Alignment 进行对齐，进而缩小范围，但这种方法用的较少。</p><ul><li>多维度分析</li></ul><p>分析任务有时候为什么特别慢呢？</p><p>当定位到某一个 Task 处理特别慢时，需要对慢的因素做出分析。分析任务慢的因素是有优先级的，可以从上向下查，由业务方面向底层系统。因为大部分问题都出现在业务维度上，比如查看业务维度的影响可以有以下几个方面，并发度是否合理、数据波峰波谷、数据倾斜；其次依次从 Garbage Collection、Checkpoint Alignment、State Backend 性能角度进行分析；最后从系统性能角度进行分析，比如 CPU、内存、Swap、Disk IO、吞吐量、容量、Network IO、带宽等。</p><h3 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q &amp; A"></a>Q &amp; A</h3><p>Q：Metrics 是系统内部的监控，那是否可以作为 Flink 日志分析的输出？</p><p>可以，但是没有必要，都用 Flink 去处理其他系统的日志了，输出或报警直接当做 sink 输出就好了。因为 Metrics 是统计内部状态，你这是处理正常输入数据，直接输出就可以了。</p><p>Q：Reporter 是有专门的线程吗？</p><p>每个 Reporter 都有自己单独的线程。在 Flink 的内部，线程其实还是挺多的，如果跑一个作业，直接到 TaskManager 上，jstack 就能看到线程的详情。</p><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-150802.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要讲解 Metrics、如何使用 Metrics 分析问题并解决问题，并对 Metrics 监控实战进行解释说明。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>《大数据实时计算引擎 Flink 实战与性能优化》新专栏</title>
    <link href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/"/>
    <id>http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</id>
    <published>2019-11-14T16:00:00.000Z</published>
    <updated>2019-11-05T07:11:12.000Z</updated>
    
    <content type="html"><![CDATA[<p>基于 Flink 1.9 讲解的专栏，涉及入门、概念、原理、实战、性能调优、系统案例的讲解。</p><a id="more"></a><h2 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h2><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="专栏亮点"><a href="#专栏亮点" class="headerlink" title="专栏亮点"></a>专栏亮点</h3><ul><li><p>全网首个使用最新版本 <strong>Flink 1.9</strong> 进行内容讲解（该版本更新很大，架构功能都有更新），领跑于目前市面上常见的 Flink 1.7 版本的教学课程。</p></li><li><p>包含大量的<strong>实战案例和代码</strong>去讲解原理，有助于读者一边学习一边敲代码，达到更快，更深刻的学习境界。目前市面上的书籍没有任何实战的内容，还只是讲解纯概念和翻译官网。</p></li><li><p>在专栏高级篇中，根据 Flink 常见的项目问题提供了<strong>排查和解决的思维方法</strong>，并通过这些问题探究了为什么会出现这类问题。</p></li><li><p>在实战和案例篇，围绕大厂公司的<strong>经典需求</strong>进行分析，包括架构设计、每个环节的操作、代码实现都有一一讲解。</p></li></ul><h3 id="为什么要学习-Flink？"><a href="#为什么要学习-Flink？" class="headerlink" title="为什么要学习 Flink？"></a>为什么要学习 Flink？</h3><p>随着大数据的不断发展，对数据的及时性要求越来越高，实时场景需求也变得越来越多，主要分下面几大类：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-055800.jpg" alt=""></p><p>为了满足这些实时场景的需求，衍生出不少计算引擎框架。现有市面上的大数据计算引擎的对比如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-055826.jpg" alt=""></p><p>可以发现无论从 Flink 的架构设计上，还是从其功能完整性和易用性来讲都是领先的，再加上 Flink 是<strong>阿里巴巴主推</strong>的计算引擎框架，所以从去年开始就越来越火了！</p><p>目前，阿里巴巴、腾讯、美团、华为、滴滴出行、携程、饿了么、爱奇艺、有赞、唯品会等大厂都已经将 Flink 实践于公司大型项目中，带起了一波 Flink 风潮，<strong>势必也会让 Flink 人才市场产生供不应求的招聘现象</strong>。</p><h3 id="专栏内容"><a href="#专栏内容" class="headerlink" title="专栏内容"></a>专栏内容</h3><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-060049.jpg" alt=""></p><h4 id="预备篇"><a href="#预备篇" class="headerlink" title="预备篇"></a>预备篇</h4><p>介绍实时计算常见的使用场景，讲解 Flink 的特性，并且对比了 Spark Streaming、Structured Streaming 和 Storm 等大数据处理引擎，然后准备环境并通过两个 Flink 应用程序带大家上手 Flink。</p><h3 id="基础篇"><a href="#基础篇" class="headerlink" title="基础篇"></a>基础篇</h3><p>深入讲解 Flink 中 Time、Window、Watermark、Connector 原理，并有大量文章篇幅（含详细代码）讲解如何去使用这些 Connector（比如 Kafka、ElasticSearch、HBase、Redis、MySQL 等），并且会讲解使用过程中可能会遇到的坑，还教大家如何去自定义 Connector。</p><h3 id="进阶篇"><a href="#进阶篇" class="headerlink" title="进阶篇"></a>进阶篇</h3><p>讲解 Flink 中 State、Checkpoint、Savepoint、内存管理机制、CEP、Table／SQL API、Machine Learning 、Gelly。在这篇中不仅只讲概念，还会讲解如何去使用 State、如何配置 Checkpoint、Checkpoint 的流程和如何利用 CEP 处理复杂事件。</p><h3 id="高级篇"><a href="#高级篇" class="headerlink" title="高级篇"></a>高级篇</h3><p>重点介绍 Flink 作业上线后的监控运维：如何保证高可用、如何定位和排查反压问题、如何合理的设置作业的并行度、如何保证 Exactly Once、如何处理数据倾斜问题、如何调优整个作业的执行效率、如何监控 Flink 及其作业？</p><h3 id="实战篇"><a href="#实战篇" class="headerlink" title="实战篇"></a>实战篇</h3><p>教大家如何分析实时计算场景的需求，并使用 Flink 里面的技术去实现这些需求，比如实时统计 PV／UV、实时统计商品销售额 TopK、应用 Error 日志实时告警、机器宕机告警。这些需求如何使用 Flink 实现的都会提供完整的代码供大家参考，通过这些需求你可以学到 ProcessFunction、Async I／O、广播变量等知识的使用方式。</p><h3 id="系统案例篇"><a href="#系统案例篇" class="headerlink" title="系统案例篇"></a>系统案例篇</h3><p>讲解大型流量下的真实案例：如何去实时处理海量日志（错误日志实时告警／日志实时 ETL／日志实时展示／日志实时搜索）、基于 Flink 的百亿数据实时去重实践（从去重的通用解决方案 –&gt; 使用 BloomFilter 来实现去重 –&gt; 使用 Flink 的 KeyedState 实现去重）。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-060153.jpg" alt=""></p><h3 id="多图讲解-Flink-知识点"><a href="#多图讲解-Flink-知识点" class="headerlink" title="多图讲解 Flink 知识点"></a>多图讲解 Flink 知识点</h3><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-060219.jpg" alt=" Flink 支持多种时间语义"></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-060232.jpg" alt="Flink 提供灵活的窗口"></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-060310.jpg" alt="Flink On YARN"></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-060900.jpg" alt="Flink Checkpoint"></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-060926.jpg" alt="Flink 监控"></p><h3 id="你将获得什么"><a href="#你将获得什么" class="headerlink" title="你将获得什么"></a>你将获得什么</h3><ul><li>掌握 Flink 与其他计算框架的区别</li><li>掌握 Flink Time／Window／Watermark／Connectors 概念和实现原理</li><li>掌握 Flink State／Checkpoint／Savepoint 状态与容错</li><li>熟练使用 DataStream／DataSet／Table／SQL API 开发 Flink 作业</li><li>掌握 Flink 作业部署／运维／监控／性能调优</li><li>学会如何分析并完成实时计算需求</li><li>获得大型高并发流量系统案例实战项目经验</li></ul><h3 id="适宜人群"><a href="#适宜人群" class="headerlink" title="适宜人群"></a>适宜人群</h3><ul><li>Flink 爱好者</li><li>实时计算开发工程师</li><li>大数据开发工程师</li><li>计算机专业研究生</li><li>有实时计算场景场景的 Java 开发工程师</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;基于 Flink 1.9 讲解的专栏，涉及入门、概念、原理、实战、性能调优、系统案例的讲解。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>一文彻底搞懂 Flink 网络流控与反压机制</title>
    <link href="http://www.54tianzhisheng.cn/2019/08/26/flink-back-pressure/"/>
    <id>http://www.54tianzhisheng.cn/2019/08/26/flink-back-pressure/</id>
    <published>2019-08-25T16:00:00.000Z</published>
    <updated>2019-12-12T14:29:32.000Z</updated>
    
    <content type="html"><![CDATA[<ul><li>看完本文，你能get到以下知识<ul><li>Flink 流处理为什么需要网络流控？</li><li>Flink V1.5 版之前网络流控介绍</li></ul></li></ul><a id="more"></a><ul><li>Flink V1.5 版之前的反压策略存在的问题</li><li><strong>Credit的反压策略实现原理</strong>，Credit是如何解决 Flink 1.5 之前的问题？</li><li>对比spark，都说flink延迟低，来一条处理一条，真是这样吗？其实Flink内部也有Buffer机制，Buffer机制具体是如何实现的？</li><li>Flink 如何在吞吐量和延迟之间做权衡？<ul><li>后续相关博客</li></ul></li><li>Flink 反压相关 Metrics 介绍</li><li>基于 Flink 的流控机制和反压如何定位 Flink 任务的瓶颈。或者说，如果一个平时正常的 Flink 任务突然出现延迟了，怎么来定位问题？到底是 Kafka 读取数据慢，还是中间某个计算环节比较消耗资源使得变慢，还是由于最后的写入外部存储时比较慢？</li></ul><h2 id="Flink-流处理为什么需要网络流控？"><a href="#Flink-流处理为什么需要网络流控？" class="headerlink" title="Flink 流处理为什么需要网络流控？"></a>Flink 流处理为什么需要网络流控？</h2><p>分析一个简单的 Flink 流任务，下图是一个简单的Flink流任务执行图：任务首先从 Kafka 中读取数据、 map 算子对数据进行转换、keyBy 按照指定 key 对数据进行分区（相同 key 的数据经过 keyBy 后分到同一个 subtask 实例中），keyBy 后对数据接着进行 map 转换，然后使用 Sink 将数据输出到外部存储。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004422.jpg" alt=""></p><p>众所周知，在大数据处理中，无论是批处理还是流处理，单点处理的性能总是有限的，我们的单个 Job 一般会运行在多个节点上，多个节点共同配合来提升整个系统的处理性能。图中，任务被切分成 4 个可独立执行的 subtask（ A0、A1、B0、B1），在数据处理过程中，就会存在 shuffle（数据传输）的过程。例如，subtask A0 处理完的数据经过 keyBy 后发送到 subtask B0、B1 所在节点去处理。</p><p>那么问题来了，下图中，上游 Producer 向下游 Consumer 发送数据，在发送端和接受端都有相应的 Send Buffer 和 Receive Buffer，但是上游 Producer 生成数据的速率比下游 Consumer 消费数据的速率快。Producer 生产数据 2MB/s， Consumer 消费数据 1MB/s，Receive Buffer 只有 5MB，所以过了5秒后，接收端的 Receive Buffer 满了。（可以把下图中的 Producer 当做上面案例中的 subtask A0，把下图中的 Consumer 当做上面案例中的 subtask B0）</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004441.jpg" alt=""></p><p>下游接收区的 Receive Buffer 有限，如果上游一直有源源不断的数据，那么将会面临着以下两个情况：</p><ol><li><p>下游消费者会丢弃新到达的数据，因为下游消费者的缓冲区放不下</p></li><li><p>为了不丢弃数据，所以下游消费者的 Receive Buffer 持续扩张，最后耗尽消费者的内存，OOM，程序挂掉</p></li></ol><p>常识告诉我们，这两种情况在生产环境都是不能接受的，第一种会把数据丢弃、第二种会把我们的应用程序挂掉。所以，该问题的解决方案不应该是下游 Receive Buffer 一直累积数据，而是上游 Producer 发现下游 Consumer 处理比较慢之后，应该在 Producer 端做出限流的策略，防止在下游 Consumer 端无限制的数据堆积。</p><p>那上游 Producer 端该如何做限流呢？可以采用下图所示静态限流的策略：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004457.jpg" alt=""></p><p>静态限速的思想就是，提前已知下游 Consumer 的消费速率，然后通过在上游 Producer 端使用类似令牌桶的思想，限制 Producer 端生产数据的速率，从而控制上游 Producer 端向下游 Consumer 端发送数据的速率。但是静态限速会存在问题：</p><ol><li>通常无法事先预估下游 Consumer 端能承受的最大速率</li><li>就算通过某种方式预估出下游 Consumer 端能承受的最大速率，下游应用程序也可能会因为网络抖动、 CPU 共享竞争、内存紧张、IO阻塞等原因造成下游应用程序的吞吐量降低，然后又会出现上面所说的下游接收区的 Receive Buffer 有限，上游一直有源源不断的数据发送到下游的问题，还是会造成下游要么丢数据，要么为了不丢数据 buffer 不断扩充导致下游 OOM的问题</li></ol><p>综上所述，我们发现了，上游 Producer 端必须有一个限流的策略，且静态限流是不可靠的，于是就需要一个动态限流的策略。可以采用下图动态反馈所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004519.jpg" alt=""></p><p>下游 Consumer 端会频繁地向上游 Producer 端进行动态反馈，告诉 Producer 下游 Consumer 的负载能力，从而 Producer 端动态调整向下游 Consumer 发送数据的速率实现 Producer 端的动态限流。当 Consumer 端处理较慢时，Consumer 将负载反馈到 Producer 端，Producer端<strong>会根据反馈适当降低 Producer 自身从上游或者 Source 端读数据的速率</strong>来降低向下游 Consumer 发送数据的速率。当 Consumer 处理负载能力提升后，又及时向 Producer 端反馈，Producer 会通过提升从上游或 Source 端读数据的速率来提升向下游发送数据的速率。通过这个动态反馈来提升整个系统的吞吐量。</p><p>补充一点，如下图所示，假如我们的 Job 分为 Task A、B、C，Task A 是 Source Task、Task B 处理数据、Task C 是 Sink Task。假如 Task C 由于各种原因吞吐量降低，会将负载信息反馈给 Task B，Task B 会降低向 Task C 发送数据的速率，此时如果 Task B 如果还是一直从 Task A 读取数据，那么按照同样的道理，数据会把 Task B 的  Send Buffer 和 Receive Buffer 撑爆，又会出现上面描述的问题。所以，当 Task B 的 Send Buffer 和 Receive Buffer 被用完后，Task B 会用同样的原理将负载信息反馈给 Task A，Task A 收到 Task B 的负载信息后，会降低 给 Task B 发送数据的速率，以此类推。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004537.jpg" alt=""></p><p>上面这个流程，就是 Flink 动态限流（反压机制）的简单描述。我们可以看到 Flink 的反压其实是从下游往上游传播的，一直往上传播到 Source Task 后，Source Task 最终会降低从 Source 端读取数据的速率。如果下游 Task C 的负载能力提升后，会及时反馈给 Task B，于是 Task B 会提升往 Task C 发送数据的速率，Task B 又将负载提升的信息反馈给 Task A，Task A 就会提升从 Source 端读取数据的速率，从而提升整个系统的负载能力。</p><p>读到这里，我们应该知道 Flink 为什么需要一个网络流控机制了，并且知道 Flink 的网络流控机制必须是一个动态反馈的过程。但是还有以下几个问题：</p><ol><li>数据具体是怎么从上游  Producer 端发送到下游 Consumer 端的？</li><li>Flink 的动态限流具体是怎么实现的？下游的负载能力和压力是如何传递给上游的？</li></ol><p>我们带着这两个问题，学习下面的 Flink 网络流控与反压机制</p><h2 id="Flink-V1-5-版之前网络流控介绍"><a href="#Flink-V1-5-版之前网络流控介绍" class="headerlink" title="Flink V1.5 版之前网络流控介绍"></a>Flink V1.5 版之前网络流控介绍</h2><p>在 Flink V1.5 版之前，其实 Flink 并没有刻意做上述所说的动态反馈。那么问题来了，没有做上述的动态反馈机制，Flink 难道不怕数据丢失或者上游和下游的一些 Buffer 把内存撑爆吗？当然不怕了，因为 Flink 已经依赖其他机制来实现了所谓的动态反馈。其实很简单，让我们继续往下看。</p><p>如下图所示，对于一个 Flink 任务，动态反馈可以抽象成以下两个阶段：</p><ol><li>跨 Task，动态反馈如何从下游 Task 的 Receive Buffer 反馈给上游 Task 的 Send Buffer</li></ol><ul><li>当下游 Task C 的 Receive Buffer 满了，如何告诉上游 Task B 应该降低数据发送速率</li><li><p>当下游 Task C 的 Receive Buffer 空了，如何告诉上游 Task B 应该提升数据发送速率</p></li><li><p>注：这里又分了两种情况，Task B 和 Task C 可能在同一台节点上运行，也有可能不在同一个台节点运行</p><ul><li>Task B 和 Task C 在同一台节点上运行指的是：一台节点运行了一个或多个 TaskManager，包含了多个 Slot，Task B 和 Task C 都运行在这台节点上，且 Task B 是 Task C 的上游，给 Task C 发送数据。此时 Task B 给 Task C 发送数据实际上是同一个 JVM 内的数据发送，所以<strong>不存在网络通信</strong></li><li>Task B 和 Task C 不在同一台节点上运行指的是：Task B 和 Task C 运行在不同的 TaskManager 中，且 Task B 是 Task C 的上游，给 Task C 发送数据。此时 Task B 给 Task C 发送数据是跨节点的，所以<strong>会存在网络通信</strong></li></ul></li></ul><ol><li>Task 内，动态反馈如何从内部的 Send Buffer 反馈给内部的 Receive Buffer</li></ol><ul><li>当 Task B 的 Send Buffer 满了，如何告诉 Task B 内部的 Receive Buffer 下游 Send Buffer 满了、下游处理性能不行了？因为要让 Task B 的 Receive Buffer 感受到压力，才能把下游的压力传递到 Task A</li><li>当 Task B 的 Send Buffer 空了，如何告诉 Task B 内部的 Receive Buffer 下游 Send Buffer 空了，下游处理性能很强，上游加快处理数据吧</li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004553.jpg" alt=""></p><h4 id="跨-TaskManager，反压如何向上游传播"><a href="#跨-TaskManager，反压如何向上游传播" class="headerlink" title="跨 TaskManager，反压如何向上游传播"></a>跨 TaskManager，反压如何向上游传播</h4><p>先了解一下 Flink 的 TaskManager 之间网络传输的数据流向：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004607.jpg" alt=""></p><p>图中，我们可以看到 TaskManager A 给 TaskManager B 发送数据，TaskManager A 做为 Producer，TaskManager B 做为 Consumer。Producer 端的 Operator 实例会产生数据，最后通过网络发送给 Consumer 端的 Operator 实例。Producer 端 Operator 实例生产的数据首先缓存到 TaskManager 内部的 NetWork Buffer。NetWork 依赖 Netty 来做通信，Producer 端的 Netty 内部有 ChannelOutbound Buffer，Consumer 端的 Netty 内部有 ChannelInbound Buffer。Netty 最终还是要通过 Socket 发送网络请求，Socket 这一层也会有 Buffer，Producer 端有 Send Buffer，Consumer 端有 Receive Buffer。</p><p>总结一下，现在有两个 TaskManager A、B，TaskManager A 中 Producer Operator 处理完的数据由 TaskManager B 中 Consumer Operator 处理。那么 Producer Operator 处理完的数据是怎么到达 Consumer Operator 的？首先 Producer Operator 从自己的上游或者外部数据源读取到数据后，对一条条的数据进行处理，处理完的数据首先输出到 Producer Operator 对应的 NetWork Buffer 中。Buffer 写满或者超时后，就会触发将 NetWork Buffer 中的数据拷贝到 Producer 端 Netty 的 ChannelOutbound Buffer，之后又把数据拷贝到 Socket 的 Send Buffer 中，这里有一个从用户态拷贝到内核态的过程，最后通过 Socket 发送网络请求，把 Send Buffer 中的数据发送到 Consumer 端的 Receive Buffer。数据到达 Consumer 端后，再依次从 Socket 的 Receive Buffer 拷贝到 Netty 的 ChannelInbound Buffer，再拷贝到 Consumer Operator 的 NetWork Buffer，最后 Consumer Operator 就可以读到数据进行处理了。这就是两个 TaskManager 之间的数据传输过程，我们可以看到发送方和接收方各有三层的 Buffer。</p><p>了解了数据传输流程，我们再具体了解一下跨 TaskManager 的反压过程，如下图所示，Producer 端生产数据速率为 2，Consumer 消费数据速率为 1。持续下去，下游消费较慢，Buffer 容量又是有限的，那 Flink 反压是怎么做的？</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004625.jpg" alt=""></p><p>上面介绍后，我们知道每个 Operator 计算数据时，输出和输入都有对应的 NetWork Buffer，这个 NetWork Buffer 对应到 Flink 就是图中所示的 ResultSubPartition 和 InputChannel。ResultSubPartition 和 InputChannel 都是向 LocalBufferPool 申请 Buffer 空间，然后 LocalBufferPool 再向 NetWork BufferPool 申请内存空间。这里，NetWork BufferPool 是 TaskManager 内所有 Task 共享的 BufferPool，TaskManager 初始化时就会向堆外内存申请 NetWork BufferPool。LocalBufferPool 是每个 Task 自己的 BufferPool，假如一个 TaskManager 内运行着 5 个 Task，那么就会有 5 个 LocalBufferPool，但 TaskManager 内永远只有一个 NetWork BufferPool。Netty 的 Buffer 也是初始化时直接向堆外内存申请内存空间。虽然可以申请，但是<strong>必须明白内存申请肯定是有限制的，不可能无限制的申请</strong>，我们在启动任务时可以指定该任务最多可能申请多大的内存空间用于 NetWork Buffer。</p><p>我们继续分析我们的场景， Producer 端生产数据速率为2，Consumer 端消费数据速率为1。数据从 Task A 的 ResultSubPartition 按照上面的流程最后传输到 Task B 的 InputChannel 供 Task B 读取并计算。持续一段时间后，由于 Task B 消费比较慢，导致 InputChannel 被占满了，所以 InputChannel 向 LocalBufferPool 申请新的 Buffer 空间，LocalBufferPool 分配给 InputChannel 一些 Buffer。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004640.jpg" alt=""></p><p>再持续一段时间后，InputChannel 重复向 LocalBufferPool 申请 Buffer 空间，导致 LocalBufferPool 也满了，所以 LocalBufferPool 向 NetWork BufferPool 申请 Buffer 空间，NetWork BufferPool  给 LocalBufferPool 分配 Buffer。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004700.jpg" alt=""></p><p>再持续下去，NetWork BufferPool 满了，或者说 NetWork BufferPool 不能把自己的 Buffer 全分配给 Task B 对应的 LocalBufferPool ，因为 TaskManager 上一般会运行了多个 Task，每个 Task 只能使用 NetWork BufferPool 中的一部分。所以，<strong>可以认为 Task B 把自己可以使用的 InputChannel 、 LocalBufferPool 和 NetWork BufferPool 都用完了</strong>。此时 Netty 还想把数据写入到 InputChannel，但是发现 InputChannel 满了，所以 Socket 层会把 Netty 的 autoRead disable，Netty 不会再从 Socket 中去读消息。可以看到下图中多个 ❌，表示 Buffer 已满，数据已经不能往下游写了，发生了阻塞。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004714.jpg" alt=""></p><p>由于 Netty 不从 Socket 的 Receive Buffer 读数据了，所以很快 Socket 的 Receive Buffer 就会变满，TCP 的 Socket 通信有动态反馈的流控机制，会把容量为0的消息反馈给上游发送端，所以上游的 Socket 就不会往下游再发送数据 。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004728.jpg" alt=""></p><p>Task A 持续生产数据，发送端 Socket 的 Send Buffer 很快被打满，所以 Task A 端的 Netty 也会停止往 Socket 写数据。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004740.jpg" alt=""></p><p>接下来，数据会在 Netty 的 Buffer 中缓存数据，但 Netty 的 Buffer 是无界的。但可以设置 Netty 的高水位，即：设置一个 Netty 中 Buffer 的上限。所以每次 ResultSubPartition 向 Netty 中写数据时，都会检测 Netty 是否已经到达高水位，如果达到高水位就不会再往 Netty 中写数据，防止 Netty 的 Buffer 无限制的增长。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004753.jpg" alt=""></p><p>接下来，数据会在 Task A 的 ResultSubPartition 中累积，ResultSubPartition 满了后，会向 LocalBufferPool 申请新的 Buffer 空间，LocalBufferPool 分配给 ResultSubPartition 一些 Buffer。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004807.jpg" alt=""></p><p>持续下去 LocalBufferPool 也会用完，LocalBufferPool 再向 NetWork BufferPool 申请 Buffer。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004820.jpg" alt=""></p><p>然后 NetWork BufferPool 也会用完，或者说 NetWork BufferPool 不能把自己的 Buffer 全分配给 Task A 对应的 LocalBufferPool ，因为 TaskManager 上一般会运行了多个 Task，每个 Task 只能使用 NetWork BufferPool 中的一部分。此时，Task A 已经申请不到任何的 Buffer 了，Task A 的 Record Writer 输出就被 wait ，Task A 不再生产数据。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004831.jpg" alt=""></p><p>通过上述的这个流程，来动态反馈，保障各个 Buffer 都不会因为数据太多导致内存溢出。上面描述了整个阻塞的流程，当下游 Task B 持续消费，Buffer 的可用容量会增加，所有被阻塞的数据通道会被一个个打开，之后 Task A 又可以开始正常的生产数据了。</p><p>之前介绍，Task 之间的数据传输可能存在上游的 Task A 和下游的 Task B 运行在同一台节点的情况，整个流程与上述类似，只不过由于 Task A 和 B 运行在同一个 JVM，所以不需要网络传输的环节，Task B 的 InputChannel 会直接从 Task A 的 ResultSubPartition 读取数据。</p><h4 id="Task-内部，反压如何向上游传播"><a href="#Task-内部，反压如何向上游传播" class="headerlink" title="Task 内部，反压如何向上游传播"></a>Task 内部，反压如何向上游传播</h4><p>假如 Task A 的下游所有 Buffer 都占满了，那么 Task A 的 Record Writer 会被 block，Task A 的 Record Reader、Operator、Record Writer 都属于同一个线程，所以 Task A 的 Record Reader 也会被 block。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004846.jpg" alt=""></p><p>然后可以把这里的 Task A 类比成上面所说的 Task B，Task A 上游持续高速率发送数据到 Task A 就会导致可用的 InputChannel、 LocalBufferPool 和 NetWork BufferPool 都会被用完。然后 Netty 、Socket 同理将压力传输到 Task A 的上游。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004901.jpg" alt=""></p><p>假设 Task A 的上游是 Task X，那么 Task A 将压力反馈给 Task X 的过程与 Task B 将压力反馈给 Task A 的过程是一样的。整个 Flink 的反压是从下游往上游传播的，一直传播到 Source Task，Source Task 有压力后，会降低从外部组件中读取数据的速率，例如：Source Task 会降低从 Kafka 中读取数据的速率，来降低整个 Flink Job 中缓存的数据，从而降低负载。</p><p>所以得出的结论是：Flink 1.5之前并没有特殊的机制来处理反压，因为 Flink 中的数据传输相当于已经提供了应对反压的机制。</p><h2 id="Flink-V1-5-版之前的反压策略存在的问题"><a href="#Flink-V1-5-版之前的反压策略存在的问题" class="headerlink" title="Flink V1.5 版之前的反压策略存在的问题"></a>Flink V1.5 版之前的反压策略存在的问题</h2><p>看着挺完美的反压机制，其实是有问题的。如下图所示，我们的任务有4个 SubTask，SubTask A 是 SubTask B的上游，即 SubTask A 给 SubTask B 发送数据。Job 运行在两个 TaskManager中， TaskManager 1 运行着 SubTask A.1 和 SubTask A.2， TaskManager 2 运行着 SubTask B.3 和 SubTask B.4。现在假如由于CPU共享或者内存紧张或者磁盘IO瓶颈造成 SubTask B.4 遇到瓶颈、处理速率有所下降，但是上游源源不断地生产数据，所以导致 SubTask A.2 与 SubTask B.4 产生反压。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004924.jpg" alt=""></p><p>这里需要明确一点：不同 Job 之间的每个（远程）网络连接将在 Flink 的网络堆栈中获得自己的TCP通道。 但是，如果同一 Task 的不同 SubTask 被安排到同一个TaskManager，则它们与其他 TaskManager 的网络连接将<strong>被多路复用并共享一个TCP信道以减少资源使用</strong>。例如，图中的 A.1 -&gt; B.3、A.1 -&gt; B.4、A.2 -&gt; B.3、A.2 -&gt; B.4 这四条将会多路复用共享一个 TCP 信道。</p><p>现在 SubTask B.3 并没有压力，从上面跨 TaskManager 的反压流程，我们知道当上图中 SubTask A.2 与 SubTask B.4 产生反压时，会把 TaskManager1 端该任务对应 Socket 的 Send Buffer 和 TaskManager2 端该任务对应 Socket 的 Receive Buffer 占满，多路复用的 TCP 通道已经被占住了，会导致 SubTask A.1 和 SubTask A.2 要发送给 SubTask B.3 的数据全被阻塞了，从而导致本来没有压力的 SubTask B.3 现在接收不到数据了。所以，Flink 1.5 版之前的反压机制会存在当一个 Task 出现反压时，可能导致其他正常的 Task 接收不到数据。</p><h2 id="Credit的反压策略实现原理"><a href="#Credit的反压策略实现原理" class="headerlink" title="Credit的反压策略实现原理"></a>Credit的反压策略实现原理</h2><p>Flink 1.5 之后，为了解决上述所描述的问题，引入了基于 Credit 的反压机制。如下图所示，反压机制作用于 Flink 的应用层，即在 ResultSubPartition 和 InputChannel 这一层引入了反压机制。每次上游 SubTask A.2 给下游 SubTask B.4 发送数据时，会把 Buffer 中的数据和上游 ResultSubPartition 堆积的数据量 Backlog size发给下游，下游会接收上游发来的数据，并向上游反馈目前下游现在的 Credit 值，Credit 值表示目前下游可以接收上游的 Buffer 量，1 个Buffer 等价于 1 个 Credit 。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004939.jpg" alt=""></p><p>例如，上游 SubTask A.2 发送完数据后，还有 5 个 Buffer 被积压，那么会把发送数据和 Backlog size = 5 一块发送给下游 SubTask B.4，下游接受到数据后，知道上游积压了 5 个Buffer，于是向 Buffer Pool 申请 Buffer，由于容量有限，下游 InputChannel 目前仅有 2 个 Buffer 空间，所以，SubTask B.4 会向上游 SubTask A.2 反馈 Channel Credit = 2。然后上游下一次最多只给下游发送 2 个 Buffer 的数据，这样每次上游发送的数据都是下游 InputChannel 的 Buffer 可以承受的数据量，所以通过这种反馈策略，保证了不会在公用的 Netty 和 TCP 这一层数据堆积而影响其他 SubTask 通信。</p><p>ResultSubPartition 会把 buffer 和 backlog size 同时发送给下游，下游向上游反馈 credit。再用一个案例来详细地描述一下整个过程。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-004956.jpg" alt=""></p><p>Task A 向 Task B 发送了数据 <8,9> 和 backlog size =3，下游 InputChannel 接受完 <8,9> 后，发现上游目前积压了 3 条数据，但是自己的缓冲区不够，于是向 LocalBufferPool 申请 buffer 空间，申请成功后，向上游反馈 credit = 3，表示下游目前可以接受 3 条记录（实际上是以 Buffer 为单位，而不是记录数，Flink 将真实记录序列化后的二进制数据放到 Buffer 中），然后上游下次最多发送 3 条数据给下游。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-005010.jpg" alt=""></p><p>持续下去，上游生产数据速率比下游消费速率快，所以 LocalBufferPool  和 NetWork BufferPool 都会被申请完，下游的 InputChannel 没有可用的缓冲区了，所以会向上游反馈 credit = 0，然后上游就不会发送数据到 Netty。所以基于  Credit 的反压策略不会导致 Netty 和 Socket 的数据积压。当然上游也不会一直不发送数据到下游，上游会定期地仅发送 backlog size 给下游，直到下游反馈 credit &gt; 0 时，上游就会继续发送真正的数据到下游了。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-010155.jpg" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-005033.jpg" alt=""></p><p>基于 Credit 的反压机制还带来了一个优势：由于我们在发送方和接收方之间缓存较少的数据，可能<strong>会更早地将反压反馈给上游</strong>，缓冲更多数据只是把数据缓冲在内存中，并没有提高处理性能。</p><h2 id="Flink-如何在吞吐量和延迟之间做权衡？"><a href="#Flink-如何在吞吐量和延迟之间做权衡？" class="headerlink" title="Flink 如何在吞吐量和延迟之间做权衡？"></a>Flink 如何在吞吐量和延迟之间做权衡？</h2><p>Flink 天然支持流式处理，即每来一条数据就能处理一条，而不是像 Spark Streaming 一样，完全是微批处理。但是为了提高吞吐量，默认使用的 Flink 并不是每来一条数据就处理一条。那这个到底是怎么控制的呢？</p><p>我们分析了上述的网络传输后，知道每个 SubTask 输出的数据并不是直接输出到下游，而是在 ResultSubPartition 中有一个 Buffer 用来缓存一批数据后，再 Flush 到 Netty 发送到下游 SubTask。那到底哪些情况会触发 Buffer Flush 到 Netty 呢？</p><ol><li><p>Buffer 变满时</p></li><li><p>Buffer timeout 时</p></li><li><p>特殊事件来临时，例如：CheckPoint 的 barrier 来临时</p></li></ol><p>Flink 在数据传输时，会把数据序列化成二进制然后写到 Buffer 中，当 Buffer 满了，需要 Flush（默认为32KiB，通过taskmanager.memory.segment-size设置）。但是当流量低峰或者测试环节，可能1分钟都没有 32 KB的数据，就会导致1分钟内的数据都积攒在 Buffer 中不会发送到下游 Task 去处理，从而导致数据出现延迟，这并不是我们想看到的。所以 Flink 有一个 Buffer timeout 的策略，意思是当数据量比较少，Buffer 一直没有变满时，后台的 Output flusher 线程会强制地将 Buffer 中的数据 Flush 到下游。Flink 中默认 timeout 时间是 100ms，即：Buffer 中的数据要么变满时 Flush，要么最多等 100ms 也会 Flush 来保证数据不会出现很大的延迟。当然这个可以通过 <code>env.setBufferTimeout(timeoutMillis)</code> 来控制超时时间。</p><ul><li>timeoutMillis &gt; 0 表示最长等待 timeoutMillis 时间，就会flush</li><li>timeoutMillis = 0 表示每条数据都会触发 flush，直接将数据发送到下游，相当于没有Buffer了(避免设置为0，可能导致性能下降)</li><li>timeoutMillis = -1 表示只有等到 buffer满了或 CheckPoint的时候，才会flush。相当于取消了 timeout 策略</li></ul><p>严格来讲，Output flusher 不提供任何保证——它只向 Netty 发送通知，而 Netty 线程会按照能力与意愿进行处理。这也意味着如果存在反压，则 Output flusher 是无效的。言外之意，如果反压很严重，下游 Buffer 都满了，当然不能强制一直往下游发数据。</p><p>一些特殊的消息如果通过 RecordWriter 发送，也会触发立即 Flush 缓存的数据。其中最重要的消息包括 Checkpoint barrier 以及 end-of-partition 事件，这些事件应该尽快被发送，而不应该等待 Buffer 被填满或者 Output flusher 的下一次 Flush。当然如果出现反压，CheckPoint barrier 也会等待，不能发送到下游。</p><p>引入 Network buffers 以获得更高的资源利用率和更高的吞吐量，代价是让一些记录在 Buffer 中等待一段时间。虽然可以通过缓冲区超时给出此等待时间的上限，但你可能知道有关这两个维度（延迟和吞吐量）之间权衡的更多信息：显然，无法同时获得这两者。下图是 Flink 官网的博客展示的不同的 buffer timeout 下对应的吞吐量，从0毫秒开始（每个记录都 flush）到100毫秒（默认值），测试在具有 100 个节点每个节点 8 个 Slot 的群集上运行，每个节点运行没有业务逻辑的 Task，因此只用于测试网络协议栈。为了进行比较，还测试了低延迟改进之前的 Flink 1.4 版本。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-005112.jpg" alt=""></p><p>如图，使用 Flink 1.5+，即使是非常低的 Buffer timeout（例如1ms，对于低延迟场景）也提供高达超时默认参数（100ms）75％ 的最大吞吐，但会缓存更少的数据。但是笔者仍然不理解为什么 timeout 设置为0时，吞吐量竟然能比 Flink 1.4 的吞吐量提高那么多。Credit 只是解决了反压的问题，并不能优化低延迟的吞吐量。杨华老师的回答是网络协议栈做了其他优化而且性能测试是在特定场景下做的。笔者后续会继续深入学习研究 Flink 网络通信来解决笔者目前的疑问。</p><p>本文作者：<strong>范磊</strong></p><p>原文链接地址：<a href="">https://www.jianshu.com/p/2779e73abcb8</a></p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><a href="https://flink.apache.org">Flink官网</a></p><p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fflink-china%2Fflink-training-course">flink-china系列课程—-2.7 Flink网络流控及反压剖析</a></p><p>Flink 官网两篇关于 Flink 网络协议栈的博客:</p><p><a href="https://flink.apache.org/2019/06/05/flink-network-stack.html#inflicting-backpressure-1">A Deep-Dive into Flink’s Network Stack</a></p><p><a href="https://flink.apache.org/2019/07/23/flink-network-stack-2.html">Flink Network Stack Vol. 2: Monitoring, Metrics, and that Backpressure Thing</a></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><p>另外你如果感兴趣的话，也可以关注我的公众号。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-06-13-130351.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客。</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;看完本文，你能get到以下知识&lt;ul&gt;
&lt;li&gt;Flink 流处理为什么需要网络流控？&lt;/li&gt;
&lt;li&gt;Flink V1.5 版之前网络流控介绍&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>滴滴实时计算发展之路及平台架构实践</title>
    <link href="http://www.54tianzhisheng.cn/2019/08/25/flink-didi/"/>
    <id>http://www.54tianzhisheng.cn/2019/08/25/flink-didi/</id>
    <published>2019-08-24T16:00:00.000Z</published>
    <updated>2019-12-12T14:29:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>滴滴的核心业务是一个实时在线服务，因此具有丰富的实时数据和实时计算场景。本文将介绍滴滴实时计算发展之路以及平台架构实践。</p><a id="more"></a><h3 id="实时计算演进"><a href="#实时计算演进" class="headerlink" title="实时计算演进"></a>实时计算演进</h3><p>随着滴滴业务的发展，滴滴的实时计算架构也在快速演变。到目前为止大概经历了三个阶段：</p><ul><li><p>业务方自建小集群阶段；</p></li><li><p>集中式大集群、平台化阶段；</p></li><li><p>SQL化阶段。</p></li></ul><p>下图标识了其中重要的里程碑，稍后会给出详细阐述：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-22-065037.jpg" alt=""></p><p>在2017年以前，滴滴并没有统一的实时计算平台，而是各个业务方自建小集群。其中用到的引擎有Storm、JStorm、Spark Streaming、Samza等。业务方自建小集群模式存在如下弊端：</p><ul><li><p>需要预先采购大量机器，由于单个业务独占，资源利用率通常比较低；</p></li><li><p>缺乏有效的监控报警体系；</p></li><li><p>维护难度大，需要牵涉业务方大量精力来保障集群的稳定性；</p></li><li><p>缺乏有效技术支持，且各自沉淀的东西难以共享。</p></li></ul><p>为了有效解决以上问题，滴滴从2017年年初开始构建统一的实时计算集群及平台。</p><p>技术选型上，我们基于滴滴现状选择了内部用大规模数据清洗的Spark Streaming引擎，同时引入On-YARN模式，并利用YARN的多租户体系构建了认证、鉴权、资源隔离、计费等机制。</p><p>相对于离线计算，实时计算任务对于稳定性有着更高的要求，为此我们构建了两层资源隔离体系：</p><ul><li><p>第一层是基于CGroup做进程（Container）级别的CPU及内存隔离；</p></li><li><p>第二层是物理机器级别的隔离。</p></li></ul><p>我们通过改造YARN的FairScheduler使其支持Node Label。达到的效果如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-22-065123.jpg" alt=""></p><p>普通业务的任务混跑在同一个Label机器上，而特殊业务的任务跑在专用Label的机器上。</p><p>通过集中式大集群和平台化建设，基本消除了业务方自建小集群带来的弊端，实时计算也进入了第二阶段。</p><p>伴随着业务的发展，我们发现Spark Streaming的Micro Batch模式在一些低延时的报警业务及在线业务上显得捉襟见肘。于是我们引入了基于Native Streaming模式的Flink作为新一代实时计算引擎。</p><p>Flink不仅延时可以做到毫秒级，而且提供了基于Process Time/Event Time丰富的窗口函数。基于Flink我们联合业务方构架了滴滴流量最大的业务网关监控系统，并快速支持了诸如乘客位置变化通知、轨迹异常检测等多个线上业务。</p><h3 id="实时计算平台架构"><a href="#实时计算平台架构" class="headerlink" title="实时计算平台架构"></a>实时计算平台架构</h3><p>为了最大程度方便业务方开发和管理流计算任务，我们构建了如图所示的实时计算平台：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-22-065202.jpg" alt=""></p><p>在流计算引擎基础上提供了StreamSQL IDE、监控报警、诊断体系、血缘关系、任务管控等能力。各自的作用如下：</p><ul><li><p>StreamSQL IDE。下文会介绍，是一个Web化的SQL IDE；</p></li><li><p>监控报警。提供任务级的存活、延时、流量等监控以及基于监控的报警能力；</p></li><li><p>诊断体系。包括流量曲线、Checkpoint、GC、资源使用等曲线视图，以及实时日志检索能力。</p></li><li><p>血缘关系。我们在流计算引擎中内置了血缘上报能力，进而在平台上呈现流任务与上下游的血缘关系；</p></li><li><p>任务管控。实现了多租户体系下任务提交、启停、资产管理等能力。通过Web化任务提交消除了传统客户机模式，使得平台入口完全可控，内置参数及版本优化得以快速上线。</p></li></ul><h3 id="实时规则匹配服务建设"><a href="#实时规则匹配服务建设" class="headerlink" title="实时规则匹配服务建设"></a>实时规则匹配服务建设</h3><p>在滴滴内部有大量的实时运营场景，比如“某城市乘客冒泡后10秒没有下单”。针对这类检测事件之间依赖关系的场景，用Fink的CEP是非常合适的。</p><p>但是社区版本的CEP不支持描述语言，每个规则需要开发一个应用，同时不支持动态更新规则。为了解决这些问题，滴滴做了大量功能扩展及优化工作。功能扩展方面主要改动有：</p><ul><li><p>支持wait算子。对于刚才例子中的运营规则，社区版本是表达不了的。滴滴通过增加wait算子，实现了这类需求；</p></li><li><p>支持DSL语言。基于Groovy和Aviator解析引擎，我们实现了如下图所示的DSL描述规则能力：</p></li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-22-065305.jpg" alt=""></p><ul><li>单任务多规则及规则动态更新。由于实时运营规则由一线运营同学来配置，所以规则数量，规则内容及规则生命周期会经常发生变化。这种情况每个规则一个应用是不太现实的。为此我们开发了多规则模式且支持了动态更新。</li></ul><p>除了功能拓展之外，为了应对大规模运营规则的挑战，滴滴在CEP性能上也做了大量优化，主要有：</p><ul><li><p>SharedBuffer重构。基于Flink MapState重构SharedBuffer，减少每次数据处理过程中的状态交互。同时剥离规则和用户数据极大降低每次匹配的时候从状态中反序列化的数据量；</p></li><li><p>增加访问缓存（已贡献社区）。缓存SharedBuffer数据中每次处理所需要更新的引用计数，延缓更新；</p></li><li><p>简化event time语义处理。避免key在很分散情况下每次watermark更新时要遍历所有key的数据；</p></li><li><p>复用conditionContext（已贡献社区）。减少条件查询时对partialMatch元素的反复查询。</p></li></ul><p>以上优化将CEP性能提升了多个数量级。配合功能扩展，我们在滴滴内部提供了如图所示的服务模式：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-22-065339.jpg" alt=""></p><p>业务方只需要清洗数据并提供规则列表API即可具备负责规则的实时匹配能力。</p><p>目前滴滴CEP已经在快车个性化运营、实时异常工单检测等业务上落地，取得了良好的效果。</p><h3 id="StreamSQL建设"><a href="#StreamSQL建设" class="headerlink" title="StreamSQL建设"></a>StreamSQL建设</h3><p>正如离线计算中Hive之于MapReduce一样，流式SQL也是必然的发展趋势。通过SQL化可以大幅度降低业务方开发流计算的难度，业务方不再需要学习Java/Scala，也不需要理解引擎执行细节及各类参数调优。</p><p>为此我们在2018年启动了StreamSQL建设项目，在社区Flink SQL基础上拓展了以下能力：</p><p>扩展DDL语法。如下图所示，打通了滴滴内部主流的消息队列以及实时存储系统(StreamSQL内置打通消息队列及实施存储)：</p><ul><li><p>通过内置常见消息格式（如json、binlog、标准日志）的解析能力，使得用户可以轻松写出DDL语法，并避免重复写格式解析语句。</p></li><li><p>拓展UDF。针对滴滴内部常见处理逻辑，内置了大量UDF，包括字符串处理、日期处理、Map对象处理、空间位置处理等。</p></li><li><p>支持分流语法。单个输入源多个输出流在滴滴内部非常常见，为此我们改造了Calcite使其支持分流语义。</p></li><li><p>支持基于TTL的join语义。传统的Window Join因为存在window边界数据突变情况，不能满足滴滴内部的需求。为此我们引入了TTL State，并基于此开发了基于TTL Join的双流join以及维表join。</p></li><li><p>StreamSQL IDE。前文提到平台化之后我们没有提供客户机，而是通过Web提交和管控任务。因此我们也相应开发了StreamSQL IDE，实现Web上开发StreamSQL，同时提供了语法检测、DEBUG、诊断等能力。</p></li></ul><p>目前StreamSQL在滴滴已经成功落地，流计算开发成本得到大幅度降低。预期未来将承担80%的流计算业务量。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>作为一家出行领域的互联网公司，滴滴对实时计算有天然的需求。</p><p>过去的一年多时间里，我们从零构建了集中式实时计算平台，改变了业务方自建小集群的局面。为满足低延时业务的需求，成功落地了Flink Streaming，并基于Flink构建了实时规则匹配（CEP）服务以及StreamSQL，使得流计算开发能力大幅度降低。未来将进一步拓展StreamSQL，并在批流统一、IoT、实时机器学习等领域探索和建设。</p><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;滴滴的核心业务是一个实时在线服务，因此具有丰富的实时数据和实时计算场景。本文将介绍滴滴实时计算发展之路以及平台架构实践。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
</feed>
